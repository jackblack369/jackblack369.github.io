<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>source is the essence</title>
  
  
  <link href="http://yoursite.com/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2023-08-02T06:37:56.628Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>brook</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>flink duduplication</title>
    <link href="http://yoursite.com/2023/08/02/flink%20deduplication/"/>
    <id>http://yoursite.com/2023/08/02/flink%20deduplication/</id>
    <published>2023-08-02T06:37:35.000Z</published>
    <updated>2023-08-02T06:37:56.628Z</updated>
    
    <content type="html"><![CDATA[<p>在 Deduplication 关于是否会出现回撤流</p><ol><li>⭐ Order by 事件时间 DESC：会出现回撤流，因为当前 key 下 <code>可能会有</code> 比当前事件时间还大的数据</li><li>⭐ Order by 事件时间 ASC：会出现回撤流，因为当前 key 下 <code>可能会有</code> 比当前事件时间还小的数据</li><li>⭐ Order by 处理时间 DESC：会出现回撤流，因为当前 key 下 <code>可能会有</code> 比当前处理时间还大的数据</li><li>⭐ Order by 处理时间 ASC：不会出现回撤流，因为当前 key 下 <code>不可能会有</code> 比当前处理时间还小的数据</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 Deduplication 关于是否会出现回撤流&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;⭐ Order by 事件时间 DESC：会出现回撤流，因为当前 key 下 &lt;code&gt;可能会有&lt;/code&gt; 比当前事件时间还大的数据&lt;/li&gt;
&lt;li&gt;⭐ Order by 事件时间 AS</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="去重" scheme="http://yoursite.com/tags/%E5%8E%BB%E9%87%8D/"/>
    
  </entry>
  
  <entry>
    <title>python points</title>
    <link href="http://yoursite.com/2023/07/24/python%20points/"/>
    <id>http://yoursite.com/2023/07/24/python%20points/</id>
    <published>2023-07-24T02:37:43.000Z</published>
    <updated>2023-07-24T05:54:18.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h2><ul><li><p>安装tar.gz，解压之后，执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 setup.py install</span><br></pre></td></tr></table></figure></li><li><p>查看指定依赖版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 show package_name</span><br></pre></td></tr></table></figure></li></ul><h2 id="信创"><a href="#信创" class="headerlink" title="信创"></a>信创</h2><ul><li><p>安装python3-devel</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dnf install python3-devel</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;指令&quot;&gt;&lt;a href=&quot;#指令&quot; class=&quot;headerlink&quot; title=&quot;指令&quot;&gt;&lt;/a&gt;指令&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装tar.gz，解压之后，执行&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;</summary>
      
    
    
    
    <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
    <category term="points" scheme="http://yoursite.com/tags/points/"/>
    
  </entry>
  
  <entry>
    <title>starrocks point</title>
    <link href="http://yoursite.com/2023/07/07/starrocks%20points/"/>
    <id>http://yoursite.com/2023/07/07/starrocks%20points/</id>
    <published>2023-07-07T06:52:04.000Z</published>
    <updated>2023-07-10T06:36:25.372Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><h2 id="注意项"><a href="#注意项" class="headerlink" title="注意项"></a>注意项</h2><ul><li><p>安装前配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export STARROCKS_HOME=xxx</span><br></pre></td></tr></table></figure></li><li><p>启动mysql客户端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h &lt;fe_ip&gt; -P&lt;fe_query_port&gt; -uroot -p # 密码为空，直接回车即可</span><br></pre></td></tr></table></figure></li><li><p>启动FE时</p><ul><li><p>启动FE为LEADER节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./fe/bin/start_fe.sh --daemon</span><br></pre></td></tr></table></figure></li></ul></li><li><p>添加新FE</p><ul><li><p>在mysql command先将实例添加进集群，然后逐个启动实例</p></li><li><p>各个节点的时间一定要同步，不然FE的心跳超过5s时差，就会报错</p></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;安装部署&quot;&gt;&lt;a href=&quot;#安装部署&quot; class=&quot;headerlink&quot; title=&quot;安装部署&quot;&gt;&lt;/a&gt;安装部署&lt;/h1&gt;&lt;h2 id=&quot;注意项&quot;&gt;&lt;a href=&quot;#注意项&quot; class=&quot;headerlink&quot; title=&quot;注意项&quot;&gt;&lt;/a&gt;注意</summary>
      
    
    
    
    <category term="olap" scheme="http://yoursite.com/categories/olap/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>XC point</title>
    <link href="http://yoursite.com/2023/03/13/xc/"/>
    <id>http://yoursite.com/2023/03/13/xc/</id>
    <published>2023-03-13T08:33:47.000Z</published>
    <updated>2023-03-13T08:34:12.630Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h1><ul><li>ARM架构</li></ul><p>​    飞腾CPU、鲲鹏CPU</p><ul><li>X86架构</li></ul><p>​    海光CPU（与AMD合作）</p><p>​    兆芯、龙芯、申威</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;CPU&quot;&gt;&lt;a href=&quot;#CPU&quot; class=&quot;headerlink&quot; title=&quot;CPU&quot;&gt;&lt;/a&gt;CPU&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;ARM架构&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​    飞腾CPU、鲲鹏CPU&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;X86架构&lt;/li&gt;</summary>
      
    
    
    
    <category term="point" scheme="http://yoursite.com/categories/point/"/>
    
    
    <category term="XC" scheme="http://yoursite.com/tags/XC/"/>
    
  </entry>
  
  <entry>
    <title>JVM Command</title>
    <link href="http://yoursite.com/2023/03/06/JVM%20command/"/>
    <id>http://yoursite.com/2023/03/06/JVM%20command/</id>
    <published>2023-03-06T03:23:15.000Z</published>
    <updated>2023-03-06T03:27:33.057Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实践一-查看进程参数"><a href="#实践一-查看进程参数" class="headerlink" title="实践一: 查看进程参数"></a>实践一: 查看进程参数</h1><blockquote><p>查看服务设置的jvm</p><p>jps -v</p><p>查看服务jvm的默认参数</p><p>jinfo -flags PID</p></blockquote><ul><li><p>参考kafka服务的运行参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-XX:+UseG1GC</span><br><span class="line">-XX:MaxGCPauseMillis=20</span><br><span class="line">-XX:InitiatingHeapOccupancyPercent=35</span><br><span class="line">-XX:+ExplicitGCInvokesConcurrent</span><br></pre></td></tr></table></figure><p><strong>-XX:MaxGCPauseMillis=200</strong></p><p>为所需的最长暂停时间设置目标值。默认值是 200 毫秒。这个数值是一个软目标，也就是说JVM会尽一切能力满足这个暂停要求，但是不能保证每次暂停一定在这个要求之内。</p><p>根据测试发现，如果我们将这个值设定成50毫秒或者更低的话，JVM为了达到这个要求会将年轻代内存空间设定的非常小，从而导致youngGC的频率大大增高。所以我们并不设定这个参数。</p><p><strong>-XX:InitiatingHeapOccupancyPercent=45</strong></p><p>设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。就是说当使用内存占到堆总大小的45%的时候，G1将开始<strong>并发标记阶段。</strong>为混合GC做准备，这个数值在测试的时候我想让混合GC晚一些处理所以设定成了70%，经过观察发现如果这个数值设定过大会导致JVM无法启动并发标记，直接进行FullGC处理。</p><p>G1的FullGC是单线程，一个22G的对GC完成需要8S的时间，所以这个值在调优的时候写的45%</p></li></ul><blockquote><p>之前查看ignite，12秒回收了71G</p></blockquote><h1 id="实践二：查看进程加载的类"><a href="#实践二：查看进程加载的类" class="headerlink" title="实践二：查看进程加载的类"></a>实践二：查看进程加载的类</h1><blockquote><p>jcmd命令要使用启动目标进程的用户执行</p></blockquote><ol><li><p>使用dump内存信息到heap.bin文件<br>使用命令<code>jmap -dump:live,format=b,file=heap.bin pid（进程号）</code>将进程pid的堆栈信息输出到heap.bin文件中</p></li><li><p>使用jhat 对heap.bin 文件进行分析<br>命令<code>jhat -J-mx512m heap.bin</code>， 如果解析过程中出现内存不足，需要加大内存如:<code>jhat -J-mx800m heap.bin</code></p></li><li><p>通过浏览器访问 <code>http://ip:7000/</code>即可看到分析结果。点击每个类，可以查看详细信息，包括该类是被哪个类加载器加载。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;实践一-查看进程参数&quot;&gt;&lt;a href=&quot;#实践一-查看进程参数&quot; class=&quot;headerlink&quot; title=&quot;实践一: 查看进程参数&quot;&gt;&lt;/a&gt;实践一: 查看进程参数&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;查看服务设置的jvm&lt;/p&gt;
&lt;p&gt;jps -</summary>
      
    
    
    
    <category term="jvm" scheme="http://yoursite.com/categories/jvm/"/>
    
    
    <category term="command" scheme="http://yoursite.com/tags/command/"/>
    
  </entry>
  
  <entry>
    <title>problems</title>
    <link href="http://yoursite.com/2022/09/27/problems/"/>
    <id>http://yoursite.com/2022/09/27/problems/</id>
    <published>2022-09-27T09:33:47.000Z</published>
    <updated>2022-09-27T09:56:02.191Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DB2"><a href="#DB2" class="headerlink" title="DB2"></a>DB2</h1><h2 id="DB2-SQL-Error-SQLCODE-805-SQLSTATE-51002-SQLERRMC-NULLID-SYSLH2DA-0X5359534C564C3031"><a href="#DB2-SQL-Error-SQLCODE-805-SQLSTATE-51002-SQLERRMC-NULLID-SYSLH2DA-0X5359534C564C3031" class="headerlink" title="DB2 SQL Error: SQLCODE=-805, SQLSTATE=51002, SQLERRMC=NULLID.SYSLH2DA 0X5359534C564C3031"></a>DB2 SQL Error: SQLCODE=-805, SQLSTATE=51002, SQLERRMC=NULLID.SYSLH2DA 0X5359534C564C3031</h2><ul><li><p>分析</p><p>the problem was a list of operations made with the same PreparedStatement, which was never closed.</p><p>许多操作使用同一个PreparedStatement，但是重来没有关闭</p></li><li><p>参考</p><p><a href="https://cloud.tencent.com/developer/article/1837198">https://cloud.tencent.com/developer/article/1837198</a></p></li></ul><h1 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h1><h2 id="lambda是否可打日志"><a href="#lambda是否可打日志" class="headerlink" title="lambda是否可打日志"></a>lambda是否可打日志</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DB2&quot;&gt;&lt;a href=&quot;#DB2&quot; class=&quot;headerlink&quot; title=&quot;DB2&quot;&gt;&lt;/a&gt;DB2&lt;/h1&gt;&lt;h2 id=&quot;DB2-SQL-Error-SQLCODE-805-SQLSTATE-51002-SQLERRMC-NULLID-SYSL</summary>
      
    
    
    
    <category term="problems" scheme="http://yoursite.com/categories/problems/"/>
    
    
    <category term="points" scheme="http://yoursite.com/tags/points/"/>
    
  </entry>
  
  <entry>
    <title>antlr point</title>
    <link href="http://yoursite.com/2022/04/20/antlr%20point/"/>
    <id>http://yoursite.com/2022/04/20/antlr%20point/</id>
    <published>2022-04-20T02:46:03.000Z</published>
    <updated>2022-04-20T02:46:15.949Z</updated>
    
    <content type="html"><![CDATA[<hr><p><a href="https://wizardforcel.gitbooks.io/antlr4-short-course/content/getting-started.html">简明教程</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://wizardforcel.gitbooks.io/antlr4-short-course/content/getting-started.html&quot;&gt;简明教程&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>java dynamic compile</title>
    <link href="http://yoursite.com/2022/04/07/java%20dynamic%20compile/"/>
    <id>http://yoursite.com/2022/04/07/java%20dynamic%20compile/</id>
    <published>2022-04-07T06:52:06.000Z</published>
    <updated>2022-04-07T06:56:26.908Z</updated>
    
    <content type="html"><![CDATA[<p>静态编译：编译时就把所有用到的Java代码全都编译成字节码，是一次性编译。</p><p>动态编译：在Java程序运行时才把需要的Java代码的编译成字节码，是按需编译。</p><p>从JDK1.6开始，引入了Java代码重写过的编译器接口，使得我们可以在运行时编译Java源代码，然后再通过类加载器将编译好的类加载进JVM,这种在运行时编译代码的操作就叫做动态编译。</p><hr><p><a href="https://blog.nowcoder.net/n/d2a7554ea2ec4e4b978cf4a74c3c41b2">【Java动态编译】动态编译的应用_牛客博客</a></p><p><a href="https://segmentfault.com/a/1190000016842546">Java动态性(1) - 动态编译(DynamicCompile)</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;静态编译：编译时就把所有用到的Java代码全都编译成字节码，是一次性编译。&lt;/p&gt;
&lt;p&gt;动态编译：在Java程序运行时才把需要的Java代码的编译成字节码，是按需编译。&lt;/p&gt;
&lt;p&gt;从JDK1.6开始，引入了Java代码重写过的编译器接口，使得我们可以在运行时编译Jav</summary>
      
    
    
    
    <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>hbase point</title>
    <link href="http://yoursite.com/2022/04/01/hbase%20point/"/>
    <id>http://yoursite.com/2022/04/01/hbase%20point/</id>
    <published>2022-04-01T02:01:30.000Z</published>
    <updated>2022-04-20T02:50:55.101Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>节点</th><th>端口号</th><th>协议</th><th>使用</th><th>说明</th></tr></thead><tbody><tr><td>zookeeper</td><td>2181</td><td></td><td>zkCli.sh -server zookeeper1:2181</td><td>客户端接入</td></tr><tr><td>2888,3888</td><td></td><td>N/A</td><td>集群内部通讯</td><td></td></tr><tr><td>HDFS Namenode</td><td>9000</td><td>HDFS</td><td>hdfs dfs -ls hdfs://namenode1:9000/</td><td>客户端接入</td></tr><tr><td>50070</td><td>HTTP</td><td><a href="http://namenode1:50070/">http://namenode1:50070/</a></td><td>集群监控</td><td></td></tr><tr><td>HDFS SecondaryNamenode</td><td>50090</td><td>HTTP</td><td><a href="http://namenode1:50090/">http://namenode1:50090/</a></td><td>secondary监控</td></tr><tr><td>HDFS Datanode</td><td>50010</td><td></td><td>N/A</td><td>客户端接入/其他节点接入</td></tr><tr><td>50020</td><td></td><td>N/A</td><td></td><td></td></tr><tr><td>50075</td><td>HTTP</td><td><a href="http://datanode1:50075/">http://datanode1:50075/</a></td><td>节点监控</td><td></td></tr><tr><td>HBase Master</td><td>16000</td><td></td><td>hbase-client-1.x.x.jar</td><td>RegionServer接入</td></tr><tr><td>16010</td><td>HTTP</td><td><a href="http://namenode1:16010/">http://namenode1:16010/</a></td><td>集群监控</td><td></td></tr><tr><td>HBase RegionServer</td><td>16020</td><td></td><td>N/A</td><td>客户端接入</td></tr><tr><td>16030</td><td>HTTP</td><td><a href="http://datanode1:16030/">http://datanode1:16030/</a></td><td>节点监控</td><td></td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;节点&lt;/th&gt;
&lt;th&gt;端口号&lt;/th&gt;
&lt;th&gt;协议&lt;/th&gt;
&lt;th&gt;使用&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;zookeeper&lt;/td&gt;
&lt;td&gt;2181&lt;/td</summary>
      
    
    
    
    <category term="hbase" scheme="http://yoursite.com/categories/hbase/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>flink module</title>
    <link href="http://yoursite.com/2022/02/16/flink%20module/"/>
    <id>http://yoursite.com/2022/02/16/flink%20module/</id>
    <published>2022-02-15T16:59:01.425Z</published>
    <updated>2022-02-16T07:11:46.943Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><ul><li>flink-annotations: Flink自定义的一些注解，用于配置、控制编译等功能。</li><li>flink-clients: Flink客户端，用于向Flink集群提交任务、查询状态等。其中org.apache.flink.client.cli.CliFrontend就是执行./flink run的入口。</li><li>flink-connectors: Flink连接器，相当于Flink读写外部系统的客户端。这些连接器指定了外部存储如何作为Flink的source或sink。例如对于kafka来说，flink-connector-kafka-xx定义了FlinkKafkaConsumer和FlinkKafkaProducer类分别作为Flink的source和sink，实现了对kafka消费和生产的功能。从图二可以看出，flink 1.9目前支持的外部存储有Cassandra、ES、Kafka、Hive等一些开源外部存储。</li><li>flink-container: Flink对docker和kubernetes的支持。</li><li>flink-contrib: 社区开发者提供的一些新特性。</li><li>flink-core: Flink核心的API、类型的定义，包括底层的算子、状态、时间的实现，是Flink最重要的部分。Flink内部的各种参数配置也都定义在这个模块的configuration中。（这部分代码还没怎么看过，就不细讲了）。</li><li>flink-dist: Flink编译好之后的jar包会放在这个文件夹下，也就是网上下载的可执行的版本。其中也包括集群启动、终止的脚本，集群的配置文件等。</li><li>flink-docs: 这个模块并不是Flink的文档，而是Flink文档生成的代码。其中org.apache.flink.docs.configuration.ConfigOptionsDocGenerator是配置文档的生成器，修改相关配置的key或者默认值，重新运行这个类就会更新doc文件夹下的html文件。同样org.apache.flink.docs.rest.RestAPIDocGenerator是Flink RestAPI文档的生成器。</li><li>flink-fliesystems: Flink对各种文件系统的支持，包括HDFS、Azure、AWS S3、阿里云OSS等分布式文件系统。</li><li>flink-formats: Flink对各种格式的数据输入输出的支持。包括Json、CSV、Avro等常用的格式。</li><li>flink-java: Flink java的API，就是写flink应用时用到的map、window、keyBy、State等类或函数的实现。</li><li>flink-jepsen: 对Flink分布式系统正确性的测试，主要验证Flink的容错机制。</li><li>flink-libraries: Flink的高级API，包括CEP（复杂事件处理）、Gelly图处理库等。</li><li>flink-mesos: Flink对mesos集群管理的支持。</li><li>flink-metrics: Flink监控上报。支持上报到influxdb、prometheus等监控系统。具体的使用配置可以在flink-core模块的org.apache.flink.configuration.MetricOptions中找到。</li><li>flink-python: Flink对python的支持，目前还比较弱。</li><li>flink-queryable-state: Flink对可查询状态的支持，其中flink-queryable-state-runtime子模块实现了StateClientProxy和StateServer。这两部分都运行在TaskManager上，StateClientProxy负责接收外部请求，StateServe负责管理内部的queryable state。flink-queryable-state-client-java子模块实现了QueryableStateClient，作为外部系统访问queryable state的客户端。</li><li>flink-runtime: flink运行时核心代码，在第二节细说。</li><li>flink-runtime-web: Flink Web Dashboard的实现。默认启动standalone集群后，访问<a href="http://localhost:8081/">http://localhost:8081</a> 出现的界面。</li><li>flink-scala: Flink scala的API。</li><li>flink-scala-shell: Flink提供的scala命令行交互接口。</li><li>flink-state-backends: flink状态存储的方式，目前这个模块中只有RocksDBStateBackend，未来可能会支持更多种的状态存储，以适应不同的业务场景。MemoryStateBackend和FsStateBackend的实现并不在这个目录下，而是在flink-runtime目录下。</li><li>flink-streaming-java: Flink Streaming的java API。</li><li>flink-streaming-scala: Flink Streaming的scala API。</li><li>flink-table: Flink Table API，在第三小节中细说。</li><li>flink-yarn: Flink对yarn集群管理的支持。</li></ul><hr><ul><li><p>flink-runtime模块是Flink最核心的模块之一，实现了Flink的运行时框架，如JobManager、TaskManager、ResourceManager、Scheduler、Checkpoint Coordinator</p></li><li><p>flink-table模块属于Flink的上层API，包括java和scala版本的table-api，以及SQL的解析和SQL的执行。</p><blockquote><p>随着Flink SQL越来越受重视，flink-table从flink-libraries中移了出来，成为了独立的一级目录。Flink 1.9中，阿里把blink-planner开源了出来，这样整个flink-table中就有了2个planner。从长期来看，流批的统一是一个趋势，因此blink-planner只使用了StreamTableEnvironment中相关的API，而没有使用BatchTableEnvironment，将批当做一个有限的流来处理，希望通过这种方式实现流和批的统一。由于blink-table-planner更好的支持流批统一，且性能更好，在未来的版本中，很有可能完全替代flink-table-planner的功能，而flink-table-planner可能将会被移除。</p></blockquote></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录结构&quot;&gt;&lt;a href=&quot;#目录结构&quot; class=&quot;headerlink&quot; title=&quot;目录结构&quot;&gt;&lt;/a&gt;目录结构&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;flink-annotations: Flink自定义的一些注解，用于配置、控制编译等功能。&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>mysql HA &amp; keepalived</title>
    <link href="http://yoursite.com/2022/01/19/mysql%20HA/"/>
    <id>http://yoursite.com/2022/01/19/mysql%20HA/</id>
    <published>2022-01-19T07:54:47.000Z</published>
    <updated>2022-04-20T02:54:47.397Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mysql数据备份"><a href="#mysql数据备份" class="headerlink" title="mysql数据备份"></a>mysql数据备份</h1><h2 id="方案二：双主机HA部署"><a href="#方案二：双主机HA部署" class="headerlink" title="方案二：双主机HA部署"></a>方案二：双主机HA部署</h2><p><strong>前提</strong>：准备两个机器master1（172.20.3.113）和master2（172.20.3.114），且分别安装了mysql，其中IP地址根据生产具体ip进行替换</p><h3 id="一、配置my-cnf信息"><a href="#一、配置my-cnf信息" class="headerlink" title="一、配置my.cnf信息"></a>一、配置my.cnf信息</h3><ul><li><p>配置/etc/my.cnf文件（从mysql5.7开始不会自动生成my.cnf文件，所以需要手动创建）my.cnf文件内容大致如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[mysql]</span><br><span class="line">default-character-set=utf8         #设置mysql客户端默认字符集</span><br><span class="line">[mysqld]</span><br><span class="line">port = 3306  #可自行更改端口</span><br><span class="line">basedir=/usr/local/mysql</span><br><span class="line">datadir=/usr/local/mysql/data</span><br><span class="line">max_connections = 500              #最大连接数</span><br><span class="line">log_bin=mysql-bin</span><br><span class="line">server_id = 1                            #机器1设置为1，机器2设置为2</span><br><span class="line">binlog_format=ROW</span><br><span class="line">auto-increment-increment = 2            #字段变化增量值</span><br><span class="line">auto-increment-offset = 1               #机器1设置为1，机器2设置为2</span><br><span class="line">slave-skip-errors = all                 #忽略所有复制产生的错误</span><br><span class="line">gtid_mode=ON</span><br><span class="line">enforce-gtid-consistency=ON</span><br><span class="line"></span><br><span class="line">character-set-server = utf8</span><br><span class="line">default-storage-engine = INNODB</span><br><span class="line">lower_case_table_names = 1</span><br></pre></td></tr></table></figure><ul><li><p>[mysql]代表我们使用mysql命令登录mysql数据库时的默认设置 </p></li><li><p>[mysqld]代表数据库自身的默认设置</p><blockquote><p>注意：机器1和机器2只有server-id不同和auto-increment-offset不同,其他必须相同。</p><p>部分配置项解释如下：</p><p>binlog_format= ROW：指定mysql的binlog日志的格式，日志中会记录成每一行数据被修改的形式，然后在 slave 端再对相同的数据进行修改。</p><p>auto-increment-increment= 2：表示自增长字段每次递增的量，其默认值是1。它的值应设为整个结构中服务器的总数，本案例用到两台服务器，所以值设为2。</p><p>auto-increment-offset= 2：用来设定数据库中自动增长的起点(即初始值)，因为这两能服务器都设定了一次自动增长值2，所以它们的起点必须得不同，这样才能避免两台服务器数据同步时出现主键冲突。</p><p>注：另外还可以在my.cnf配置文件中，添加“binlog_do_db=数据库名”配置项（可以添加多个）来指定要同步的数据库。如果配置了这个配置项，如果没添加在该配置项后面的数据库，则binlog不记录它的事件。</p></blockquote></li></ul></li><li><p>切换到datacanvas用户进行mysql启动服务 （建议）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/mysql/support-files/mysql.server start</span><br></pre></td></tr></table></figure><p>或者在已经创建软连接的前提下，切换到root用户，并启动mysql服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mysql restart</span><br></pre></td></tr></table></figure></li><li><p>客户端登录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/mysql/bin/mysql -uroot -p</span><br></pre></td></tr></table></figure><p>  设置可远程登录root用户</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;123456&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><blockquote><p>注意：上面的密码’123456’修改成真实的root密码</p></blockquote></li></ul><h4 id="开始设置双主备份"><a href="#开始设置双主备份" class="headerlink" title="开始设置双主备份"></a>开始设置双主备份</h4><ul><li><p>在master1上操作</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">先在master2上执行，</span><br><span class="line"><span class="keyword">show</span> master status;（获取master_log_file和master_log_pos信息）</span><br><span class="line"></span><br><span class="line">在master1上执行</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;172.20.3.114&#x27;</span>,master_port<span class="operator">=</span><span class="number">3306</span>,master_user<span class="operator">=</span><span class="string">&#x27;rt&#x27;</span>,master_password<span class="operator">=</span><span class="string">&#x27;rt123&#x27;</span>,master_log_file<span class="operator">=</span><span class="string">&#x27;mysql-bin.000003&#x27;</span>,master_log_pos<span class="operator">=</span><span class="number">194</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">start</span> slave;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> slave status\G</span><br></pre></td></tr></table></figure></li><li><p>在master2上操作</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">先在master1上执行，</span><br><span class="line"><span class="keyword">show</span> master status;（获取master_log_file和master_log_pos信息）</span><br><span class="line">在master2上执行</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;172.20.3.113&#x27;</span>,master_port<span class="operator">=</span><span class="number">3306</span>,master_user<span class="operator">=</span><span class="string">&#x27;rt&#x27;</span>,master_password<span class="operator">=</span><span class="string">&#x27;rt123&#x27;</span>,master_log_file<span class="operator">=</span><span class="string">&#x27;mysql-bin.000004&#x27;</span>,master_log_pos<span class="operator">=</span><span class="number">194</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">start</span> slave;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> slave status\G</span><br></pre></td></tr></table></figure></li></ul><hr><h3 id="二、keepalived安装配置"><a href="#二、keepalived安装配置" class="headerlink" title="二、keepalived安装配置"></a>二、keepalived安装配置</h3><p>需要在master1和master2的机器上安装keepalived服务，安装过程大致如下：</p><ul><li><p>通过地址<a href="https://pkgs.org/download/keepalived%E4%B8%8B%E8%BD%BD%E7%9B%B8%E5%BA%94%E7%9A%84%E5%AE%89%E8%A3%85%E7%89%88%E6%9C%AC%EF%BC%8C%E7%84%B6%E5%90%8E%E8%A7%A3%E5%8E%8B%E7%9A%84%E7%9B%B8%E5%85%B3%E7%9B%AE%E5%BD%95%E3%80%82">https://pkgs.org/download/keepalived下载相应的安装版本，然后解压的相关目录。</a></p></li><li><p>源码的安装一般由3个步骤组成：配置（configure）、编译（make）、安装( make install）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/local/keepalived</span><br></pre></td></tr></table></figure><p> 如果提示错误信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">configure: error: </span><br><span class="line">  !!! OpenSSL is not properly installed on your system. !!!</span><br><span class="line">  !!! Can not include OpenSSL headers files.            !!!</span><br></pre></td></tr></table></figure><p>需要安装yum install openssl openssl-devel（RedHat系统），<br>再次执行./configure –prefix=/usr/local/keepalived</p></li><li><p>在安装目录执行<code>make &amp;&amp; make install</code>进行编译安装</p></li><li><p>keepalived配置文件，默认情况下keepalived启动时会去/etc/keepalived目录下加载配置文件keepalived.conf</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File forkeepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">notification_email &#123;</span><br><span class="line">[email protected]</span><br><span class="line"> &#125;</span><br><span class="line">notification_email_from  [email protected]</span><br><span class="line">smtp_server 127.0.0.1</span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line">router_id MYSQL_HA      #标识，双主相同</span><br><span class="line"> &#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"> state BACKUP           #两台都设置BACKUP</span><br><span class="line"> interface eth0         #网卡名称</span><br><span class="line"> virtual_router_id 51       #主备相同</span><br><span class="line"> priority 100   #优先级，另一台改为90    </span><br><span class="line"> advert_int 1    </span><br><span class="line"> nopreempt  #不抢占，只在优先级高的机器上设置即可，优先级低的机器不设置    </span><br><span class="line"> authentication &#123;</span><br><span class="line"> auth_type PASS    #鉴权，默认通过</span><br><span class="line"> auth_pass 1111    # 鉴权访问密码</span><br><span class="line"> &#125;</span><br><span class="line"> virtual_ipaddress &#123;</span><br><span class="line">  172.20.3.200    #虚拟ip</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 172.20.3.200 3306 &#123;    </span><br><span class="line">     delay_loop 2   #每个2秒检查一次real_server状态    </span><br><span class="line">     lb_algo wrr   #LVS算法    </span><br><span class="line">     lb_kind DR    #LVS模式    </span><br><span class="line">     persistence_timeout 60   #会话保持时间    </span><br><span class="line">     protocol TCP    </span><br><span class="line">     real_server 172.20.3.113 3306 &#123;    </span><br><span class="line">         weight 1    #指定了当前主机的权重    </span><br><span class="line">         notify_down /usr/local/keepalived/kill_keepalived.sh  #检测到服务down后执行的脚本    </span><br><span class="line">         TCP_CHECK &#123;    </span><br><span class="line">             connect_timeout 10    #连接超时时间</span><br><span class="line">             delay_before_retry 3   #重连间隔时间    </span><br><span class="line">             connect_port 3306   #健康检查端口  </span><br><span class="line">         &#125;  </span><br><span class="line">     &#125;</span><br><span class="line">     real_server 172.20.3.114 3306 &#123;</span><br><span class="line">        weight 2</span><br><span class="line">        notify_down /usr/local/keepalived/kill_keepalived.sh  #检测到服务down后执行的脚本</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 10</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 3306</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：参数priority两个服务器配置不同，其中virtual_ipaddress是虚拟ip，之后项目可通过访问 172.20.3.200:3306进行访问双主mysql机群。</p><p>上述配置中会涉及/usr/local/keepalived/kill_keepalived.sh，分别在两台服务器上编写kill_keepalived.sh脚本内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">pkill keepalived</span><br></pre></td></tr></table></figure><p>   然后给脚本加权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x /usr/local/keepalived/kill_keepalived.sh</span><br></pre></td></tr></table></figure><ul><li>启动keepalived服务<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service keepalived start</span><br></pre></td></tr></table></figure>如果启动失败，尝试输入<code>pkill -9 keepalived</code>，然后再尝试重启</li></ul><hr><h3 id="三、访问双主mysql集群"><a href="#三、访问双主mysql集群" class="headerlink" title="三、访问双主mysql集群"></a>三、访问双主mysql集群</h3><p>两台机器的mysql和keepalived配置完成之后，即可在项目中，通过访问虚拟ip地址（172.20.3.200:3306）进行mysql集群的访问。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;mysql数据备份&quot;&gt;&lt;a href=&quot;#mysql数据备份&quot; class=&quot;headerlink&quot; title=&quot;mysql数据备份&quot;&gt;&lt;/a&gt;mysql数据备份&lt;/h1&gt;&lt;h2 id=&quot;方案二：双主机HA部署&quot;&gt;&lt;a href=&quot;#方案二：双主机HA部署&quot; c</summary>
      
    
    
    
    <category term="mysql" scheme="http://yoursite.com/categories/mysql/"/>
    
    
    <category term="HA" scheme="http://yoursite.com/tags/HA/"/>
    
  </entry>
  
  <entry>
    <title>mysql backup plan</title>
    <link href="http://yoursite.com/2022/01/19/mysql%20backup%20A/"/>
    <id>http://yoursite.com/2022/01/19/mysql%20backup%20A/</id>
    <published>2022-01-19T06:54:47.000Z</published>
    <updated>2022-04-20T02:54:42.521Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mysql数据备份"><a href="#mysql数据备份" class="headerlink" title="mysql数据备份"></a>mysql数据备份</h1><h2 id="方案一：定期备份数据库数据文件"><a href="#方案一：定期备份数据库数据文件" class="headerlink" title="方案一：定期备份数据库数据文件"></a>方案一：定期备份数据库数据文件</h2><h3 id="一、编写shell脚本"><a href="#一、编写shell脚本" class="headerlink" title="一、编写shell脚本"></a>一、编写shell脚本</h3><p>脚本文件<strong>backup_mysql.sh</strong>信息如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">用户名</span></span><br><span class="line">username=root</span><br><span class="line"><span class="meta">#</span><span class="bash">密码</span></span><br><span class="line">password=填写密码</span><br><span class="line"><span class="meta">#</span><span class="bash">将要备份的数据库</span></span><br><span class="line">database_name=填写需要备份的数据库</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">保存备份文件最多个数</span></span><br><span class="line">count=30</span><br><span class="line"><span class="meta">#</span><span class="bash">备份保存路径</span></span><br><span class="line">backup_path=/data/mysql_backup</span><br><span class="line"><span class="meta">#</span><span class="bash">日期</span></span><br><span class="line">date_time=`date +%Y-%m-%d-%H-%M`</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">如果文件夹不存在则创建</span></span><br><span class="line">if [ ! -d $backup_path ]; </span><br><span class="line">then     </span><br><span class="line">    mkdir -p $backup_path; </span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span><span class="bash">开始备份</span></span><br><span class="line">mysqldump -u $username -p$password $database_name &gt; $backup_path/$database_name-$date_time.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">开始压缩</span></span><br><span class="line">cd $backup_path</span><br><span class="line">tar -zcvf $database_name-$date_time.tar.gz $database_name-$date_time.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">删除源文件</span></span><br><span class="line">rm -rf $backup_path/$database_name-$date_time.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">更新备份日志</span></span><br><span class="line">echo &quot;create $backup_path/$database_name-$date_time.tar.gz&quot; &gt;&gt; $backup_path/dump.log</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">找出需要删除的备份</span></span><br><span class="line">delfile=`ls -l -crt $backup_path/*.tar.gz | awk &#x27;&#123;print $9 &#125;&#x27; | head -1`</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">判断现在的备份数量是否大于阈值</span></span><br><span class="line">number=`ls -l -crt  $backup_path/*.tar.gz | awk &#x27;&#123;print $9 &#125;&#x27; | wc -l`</span><br><span class="line"></span><br><span class="line">if [ $number -gt $count ]</span><br><span class="line">then</span><br><span class="line"><span class="meta">  #</span><span class="bash">删除最早生成的备份，只保留count数量的备份</span></span><br><span class="line">  rm $delfile</span><br><span class="line"><span class="meta">  #</span><span class="bash">更新删除文件日志</span></span><br><span class="line">  echo &quot;delete $delfile&quot; &gt;&gt; $backup_path/dump.log</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>该脚本实现的功能：备份指定数据库的数据信息到指定目录，并只保存指定数量的最新文件。</p><p>注意：脚本中需要补全脚本中的<strong>password</strong>和<strong>database_name</strong>信息，可修改备份保存路径<strong>backup_path</strong>，以及最多保存的备份文件数量<strong>count</strong>。</p><p>编写完脚本信息之后，需要给脚本赋予可执行权限 <code>chmod +x backup_mysql.sh</code></p><h3 id="二、设定定时任务crontab"><a href="#二、设定定时任务crontab" class="headerlink" title="二、设定定时任务crontab"></a>二、设定定时任务crontab</h3><p>运行crontab -e命令，打开一个可编辑的文本，输入<code>0 1 * * * /path/to/backup_mysql.sh</code>  保本并退出即添加完成。</p><p>注意：其中<code>0 1 * * *</code>，表示每天凌晨1点进行备份操作，可自行修改1的值（范围0～23）</p><p>其中路径信息<code>/path/to/backup_mysql.sh</code>需要修改为实际的脚本路径。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;mysql数据备份&quot;&gt;&lt;a href=&quot;#mysql数据备份&quot; class=&quot;headerlink&quot; title=&quot;mysql数据备份&quot;&gt;&lt;/a&gt;mysql数据备份&lt;/h1&gt;&lt;h2 id=&quot;方案一：定期备份数据库数据文件&quot;&gt;&lt;a href=&quot;#方案一：定期备份数据</summary>
      
    
    
    
    <category term="mysql" scheme="http://yoursite.com/categories/mysql/"/>
    
    
    <category term="backup" scheme="http://yoursite.com/tags/backup/"/>
    
  </entry>
  
  <entry>
    <title>flink cdc</title>
    <link href="http://yoursite.com/2022/01/15/flink%20cdc/"/>
    <id>http://yoursite.com/2022/01/15/flink%20cdc/</id>
    <published>2022-01-15T08:24:07.000Z</published>
    <updated>2022-04-20T02:59:22.144Z</updated>
    
    <content type="html"><![CDATA[<p>reference</p><p><a href="https://developer.aliyun.com/article/848448?spm=a2c6h.12873639.0.d102020001.6a5a2de1EwwX6V&utm_content=g_1000316418">Flink Forward Aisa 系列专刊｜Flink CDC 新一代数据集成框架 - 技术原理、入门与生产实践-阿里云开发者社区</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;reference&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://developer.aliyun.com/article/848448?spm=a2c6h.12873639.0.d102020001.6a5a2de1EwwX6V&amp;utm_content=g_100031</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="cdc" scheme="http://yoursite.com/tags/cdc/"/>
    
  </entry>
  
  <entry>
    <title>flink cep</title>
    <link href="http://yoursite.com/2022/01/14/flink%20cep/"/>
    <id>http://yoursite.com/2022/01/14/flink%20cep/</id>
    <published>2022-01-14T08:24:07.000Z</published>
    <updated>2022-02-11T06:45:12.698Z</updated>
    
    <content type="html"><![CDATA[<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>风险控制<br>对用户异常行为模式进行实时检测，当一个用户发生了不该发生的行为，判定这个用户是不是有违规操作的嫌疑。</p><p>策略营销<br>用预先定义好的规则对用户的行为轨迹进行实时跟踪，对行为轨迹匹配预定义规则的用户实时发送相应策略的推广。</p><p>运维监控<br>灵活配置多指标、多依赖来实现更复杂的监控模式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;headerlink&quot; title=&quot;应用场景&quot;&gt;&lt;/a&gt;应用场景&lt;/h3&gt;&lt;p&gt;风险控制&lt;br&gt;对用户异常行为模式进行实时检测，当一个用户发生了不该发生的行为，判定这个用户是不是有违规操作的嫌疑。&lt;/p&gt;</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="cep" scheme="http://yoursite.com/tags/cep/"/>
    
  </entry>
  
  <entry>
    <title>flink watermark</title>
    <link href="http://yoursite.com/2022/01/11/flink%20watermark/"/>
    <id>http://yoursite.com/2022/01/11/flink%20watermark/</id>
    <published>2022-01-11T10:42:32.000Z</published>
    <updated>2022-05-16T05:22:21.991Z</updated>
    
    <content type="html"><![CDATA[<p>Watermark是Apache Flink为了处理EventTime 窗口计算提出的一种机制,本质上也是一种时间戳。</p><p>由Apache Flink Source或者自定义的Watermark生成器按照需求Punctuated或者Periodic两种方式生成的一种系统Event，与普通数据流Event一样流转到对应的下游算子，接收到Watermark Event的算子以此不断调整自己管理的EventTime clock。</p><p>Apache Flink 框架保证Watermark单调递增，算子接收到一个Watermark时候，框架知道不会再有任何小于该Watermark的时间戳的数据元素到来了，所以Watermark可以看做是告诉Apache Flink框架数据流已经处理到什么位置(时间维度)的方式。</p><p>Watermark的产生和Apache Flink内部处理逻辑如下图所示:</p><p><img src="/images/flink/flink_watermark.png"></p><h3 id="产生方式"><a href="#产生方式" class="headerlink" title="产生方式"></a>产生方式</h3><ul><li><p>Punctuated - 数据流中每一个递增的EventTime都会产生一个Watermark。 在实际的生产中Punctuated方式在TPS很高的场景下会产生大量的Watermark在一定程度上对下游算子造成压力，所以只有在实时性要求非常高的场景才会选择Punctuated的方式进行Watermark的生成。</p></li><li><p>Periodic - 周期性的（一定时间间隔或者达到一定的记录条数）产生一个Watermark。在实际的生产中Periodic的方式必须结合时间和积累条数两个维度继续周期性产生Watermark，否则在极端情况下会有很大的延时。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Watermark是Apache Flink为了处理EventTime 窗口计算提出的一种机制,本质上也是一种时间戳。&lt;/p&gt;
&lt;p&gt;由Apache Flink Source或者自定义的Watermark生成器按照需求Punctuated或者Periodic两种方式生成的一</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>flink state</title>
    <link href="http://yoursite.com/2022/01/11/flink%20state/"/>
    <id>http://yoursite.com/2022/01/11/flink%20state/</id>
    <published>2022-01-11T06:32:39.000Z</published>
    <updated>2022-02-19T05:47:13.406Z</updated>
    
    <content type="html"><![CDATA[<h3 id="what"><a href="#what" class="headerlink" title="what ?"></a>what ?</h3><p>State是指流计算过程中计算节点的中间计算结果或元数据属性，比如 在aggregation过程中要在state中记录中间聚合结果，比如 Apache Kafka 作为数据源时候，我们也要记录已经读取记录的offset，这些State数据在计算过程中会进行持久化(插入或更新)。所以Apache Flink中的State就是与时间相关的，Apache Flink任务的内部数据（计算数据和元数据属性）的快照。</p><h3 id="why"><a href="#why" class="headerlink" title="why ?"></a>why ?</h3><p>与批计算相比，State是流计算特有的，批计算没有failover机制，要么成功，要么重新计算。流计算在 大多数场景 下是增量计算，数据逐条处理（大多数场景)，每次计算是在上一次计算结果之上进行处理的，这样的机制势必要将上一次的计算结果进行存储（生产模式要持久化），另外由于 机器，网络，脏数据等原因导致的程序错误，在重启job时候需要从成功的检查点(checkpoint，后面篇章会专门介绍)进行state的恢复。增量计算，Failover这些机制都需要state的支撑。</p><h3 id="how"><a href="#how" class="headerlink" title="how ?"></a>how ?</h3><h4 id="存储实现"><a href="#存储实现" class="headerlink" title="存储实现"></a>存储实现</h4><ul><li><p>基于内存的HeapStateBackend - 在debug模式使用，不 建议在生产模式下应用；</p></li><li><p>基于HDFS的FsStateBackend - 分布式文件持久化，每次读写都产生网络IO，整体性能不佳；</p></li><li><p>基于RocksDB的RocksDBStateBackend - 本地文件+异步HDFS持久化；</p><blockquote><p>Apache Flink版本选择用RocksDB+HDFS的方式进行State的存储，State存储分两个阶段，首先本地存储到RocksDB，然后异步的同步到远程的HDFS。 这样而设计既消除了HeapStateBackend的局限（内存大小，机器坏掉丢失等），也减少了纯分布式存储的网络IO开销。</p></blockquote></li><li><p>还有一个是基于Niagara(Alibaba内部实现)NiagaraStateBackend - 分布式持久化- 在Alibaba生产环境应用；</p></li></ul><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>通过算子和数据层面划分</p><ul><li><p>算子类state</p><p>KeyedState - 这里面的key是我们在SQL语句中对应的GroupBy/PartitioneBy里面的字段，key的值就是groupby/PartitionBy字段组成的Row的字节数组，每一个key都有一个属于自己的State，key与key之间的State是不可见的</p></li><li><p>数据类state</p><p>OperatorState - Apache Flink内部的Source Connector的实现中就会用OperatorState来记录source数据读取的offset。</p></li></ul><h3 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h3><p>checkpoint是使Flink 能从故障恢复的一种内部机制。检查点是 Flink 应用状态的一个一致性副本，包括了输入的读取位点。在发生故障时，Flink 通过从检查点加载应用程序状态来恢复，并从恢复的读取位点继续处理，就好像什么事情都没发生一样。Flink的状态存储在Flink的内部,这样做的好处就是不再依赖外部系统,降低了对外部系统的依赖,在Flink的内部,通过自身的进程去访问状态变量.同时会定期的做checkpoint持久化,把checkpoint存储在一个分布式的持久化系统中,如果发生故障,就会从最近的一次checkpoint中将整个流的状态进行恢复.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;what&quot;&gt;&lt;a href=&quot;#what&quot; class=&quot;headerlink&quot; title=&quot;what ?&quot;&gt;&lt;/a&gt;what ?&lt;/h3&gt;&lt;p&gt;State是指流计算过程中计算节点的中间计算结果或元数据属性，比如 在aggregation过程中要在state中记</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>flink streaming warehouse</title>
    <link href="http://yoursite.com/2022/01/11/flink%20streaming%20warehouse/"/>
    <id>http://yoursite.com/2022/01/11/flink%20streaming%20warehouse/</id>
    <published>2022-01-11T02:57:26.000Z</published>
    <updated>2022-03-07T13:09:14.847Z</updated>
    
    <content type="html"><![CDATA[<p>流式数仓（Streaming Warehouse）更准确地说，其实是“make data warehouse streaming”，就是让整个数仓的数据全实时地流动起来，且是以纯流的方式而不是微批（mini-batch）的方式流动。</p><p>目标是实现一个具备端到端实时性的纯流服务（Streaming Service），用一套 API 分析所有流动中的数据，当源头数据发生变化，比如捕捉到在线服务的 Log 或数据库的 Binlog 以后，就按照提前定义好的 Query 逻辑或数据处理逻辑，对数据进行分析，分析后的数据落到数仓的某一个分层，再从第一个分层向下一个分层流动，然后数仓所有分层会全部流动起来，最终流到一个在线系统里，用户可以看到整个数仓的全实时流动效果。</p><p>在这个过程中，数据是主动的，而查询是被动的，分析由数据的变化来驱动。同时在垂直方向上，对每一个数据明细层，用户都可以执行 Query 进行主动查询，并且能实时获得查询结果。此外，它还能兼容离线分析场景，API 依然是同一套，实现真正的一体化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;流式数仓（Streaming Warehouse）更准确地说，其实是“make data warehouse streaming”，就是让整个数仓的数据全实时地流动起来，且是以纯流的方式而不是微批（mini-batch）的方式流动。&lt;/p&gt;
&lt;p&gt;目标是实现一个具备端到端实</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="warehouse" scheme="http://yoursite.com/tags/warehouse/"/>
    
  </entry>
  
  <entry>
    <title>macos command</title>
    <link href="http://yoursite.com/2022/01/07/mac%20command/"/>
    <id>http://yoursite.com/2022/01/07/mac%20command/</id>
    <published>2022-01-07T06:03:15.000Z</published>
    <updated>2022-05-16T03:56:23.524Z</updated>
    
    <content type="html"><![CDATA[<ul><li>解压带有中文名称的zip包</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ditto -V -x -k --sequesterRsrc filename.zip destination</span><br></pre></td></tr></table></figure><ul><li>查看目录下文件夹大小<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">du -d 1 -h    命令查看当前目录下所有文件夹的大小 -d 指深度，后面加一个数值</span><br><span class="line">或</span><br><span class="line">du -hd1</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;解压带有中文名称的zip包&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/</summary>
      
    
    
    
    <category term="macos" scheme="http://yoursite.com/categories/macos/"/>
    
    
    <category term="command" scheme="http://yoursite.com/tags/command/"/>
    
  </entry>
  
  <entry>
    <title>fabric8 &amp; docker-maven-plugin</title>
    <link href="http://yoursite.com/2022/01/07/fabric8(docker-maven-plugin)/"/>
    <id>http://yoursite.com/2022/01/07/fabric8(docker-maven-plugin)/</id>
    <published>2022-01-07T05:59:21.000Z</published>
    <updated>2022-04-20T03:01:02.879Z</updated>
    
    <content type="html"><![CDATA[<h2 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;todo&quot;&gt;&lt;a href=&quot;#todo&quot; class=&quot;headerlink&quot; title=&quot;todo&quot;&gt;&lt;/a&gt;todo&lt;/h2&gt;</summary>
      
    
    
    
    <category term="docker" scheme="http://yoursite.com/categories/docker/"/>
    
    
    <category term="plugin" scheme="http://yoursite.com/tags/plugin/"/>
    
  </entry>
  
  <entry>
    <title>file system</title>
    <link href="http://yoursite.com/2022/01/07/file%20system/"/>
    <id>http://yoursite.com/2022/01/07/file%20system/</id>
    <published>2022-01-07T05:59:21.000Z</published>
    <updated>2022-01-07T06:23:11.573Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h1><p><img src="/images/fileSystemType.jpeg" alt="fileSystemType.jpeg"></p><ul><li><p>Mac 默认可以读 Windows 的 NTFS 格式，但不能写。</p></li><li><p>Windows 无法识别 Mac 的 HFS+ 或 APFS 格式。</p></li><li><p>Mac 和 Windows 都能正常读写 FAT32 和 ExFAT 格式</p></li><li><p>linux</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Linux：存在几十个文件系统类型：ext2，ext3，ext4，xfs，brtfs，zfs（man 5 fs可以取得全部文件系统的介绍）</span><br><span class="line"></span><br><span class="line">不同文件系统采用不同的方法来管理磁盘空间，各有优劣；文件系统是具体到分区的，所以格式化针对的是分区，分区格式化是指采用指定的文件系统类型对分区空间进行登记、索引并建立相应的管理表格的过程。</span><br><span class="line"></span><br><span class="line">ext2具有极快的速度和极小的CPU占用率，可用于硬盘和移动存储设备</span><br><span class="line">ext3增加日志功能，可回溯追踪</span><br><span class="line">ext4日志式文件系统，支持1EB（1024*1024TB），最大单文件16TB，支持连续写入可减少文件碎片。rhel6默认文件系统</span><br><span class="line">xfs可以管理500T的硬盘。rhel7默认文件系统</span><br><span class="line">brtfs文件系统针对固态盘做优化，</span><br></pre></td></tr></table></figure></li><li><p>windows</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FAT16：MS—DOS和win95采用的磁盘分区格式，采用16位的文件分配表，只支持2GB的磁盘分区，最大单文件2GB，且磁盘利用率低</span><br><span class="line">FAT32：（即Vfat）采用32位的文件分配表，支持最大分区128GB，最大文件4GB</span><br><span class="line">NTFS：支持最大分区2TB，最大文件2TB，安全性和稳定性非常好，不易出现文件碎片。</span><br></pre></td></tr></table></figure></li></ul><hr><p>reference</p><p><a href="https://www.yinxiang.com/everhub/note/0312ed71-61f5-4c75-9c77-3db0ffdeb613">https://www.yinxiang.com/everhub/note/0312ed71-61f5-4c75-9c77-3db0ffdeb613</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;文件系统&quot;&gt;&lt;a href=&quot;#文件系统&quot; class=&quot;headerlink&quot; title=&quot;文件系统&quot;&gt;&lt;/a&gt;文件系统&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/images/fileSystemType.jpeg&quot; alt=&quot;fileSystemType.jpe</summary>
      
    
    
    
    <category term="file system" scheme="http://yoursite.com/categories/file-system/"/>
    
    
    <category term="snippet" scheme="http://yoursite.com/tags/snippet/"/>
    
  </entry>
  
</feed>
