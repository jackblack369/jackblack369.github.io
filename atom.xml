<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>source is the essence</title>
  
  
  <link href="http://yoursite.com/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2022-04-20T02:46:15.949Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>brook</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>antlr point</title>
    <link href="http://yoursite.com/2022/04/20/antlr%20point/"/>
    <id>http://yoursite.com/2022/04/20/antlr%20point/</id>
    <published>2022-04-20T02:46:03.000Z</published>
    <updated>2022-04-20T02:46:15.949Z</updated>
    
    <content type="html"><![CDATA[<hr><p><a href="https://wizardforcel.gitbooks.io/antlr4-short-course/content/getting-started.html">简明教程</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://wizardforcel.gitbooks.io/antlr4-short-course/content/getting-started.html&quot;&gt;简明教程&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>java dynamic compile</title>
    <link href="http://yoursite.com/2022/04/07/java%20dynamic%20compile/"/>
    <id>http://yoursite.com/2022/04/07/java%20dynamic%20compile/</id>
    <published>2022-04-07T06:52:06.000Z</published>
    <updated>2022-04-07T06:56:26.908Z</updated>
    
    <content type="html"><![CDATA[<p>静态编译：编译时就把所有用到的Java代码全都编译成字节码，是一次性编译。</p><p>动态编译：在Java程序运行时才把需要的Java代码的编译成字节码，是按需编译。</p><p>从JDK1.6开始，引入了Java代码重写过的编译器接口，使得我们可以在运行时编译Java源代码，然后再通过类加载器将编译好的类加载进JVM,这种在运行时编译代码的操作就叫做动态编译。</p><hr><p><a href="https://blog.nowcoder.net/n/d2a7554ea2ec4e4b978cf4a74c3c41b2">【Java动态编译】动态编译的应用_牛客博客</a></p><p><a href="https://segmentfault.com/a/1190000016842546">Java动态性(1) - 动态编译(DynamicCompile)</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;静态编译：编译时就把所有用到的Java代码全都编译成字节码，是一次性编译。&lt;/p&gt;
&lt;p&gt;动态编译：在Java程序运行时才把需要的Java代码的编译成字节码，是按需编译。&lt;/p&gt;
&lt;p&gt;从JDK1.6开始，引入了Java代码重写过的编译器接口，使得我们可以在运行时编译Jav</summary>
      
    
    
    
    <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>hbase point</title>
    <link href="http://yoursite.com/2022/04/01/hbase%20point/"/>
    <id>http://yoursite.com/2022/04/01/hbase%20point/</id>
    <published>2022-04-01T02:01:30.000Z</published>
    <updated>2022-04-20T02:50:55.101Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>节点</th><th>端口号</th><th>协议</th><th>使用</th><th>说明</th></tr></thead><tbody><tr><td>zookeeper</td><td>2181</td><td></td><td>zkCli.sh -server zookeeper1:2181</td><td>客户端接入</td></tr><tr><td>2888,3888</td><td></td><td>N/A</td><td>集群内部通讯</td><td></td></tr><tr><td>HDFS Namenode</td><td>9000</td><td>HDFS</td><td>hdfs dfs -ls hdfs://namenode1:9000/</td><td>客户端接入</td></tr><tr><td>50070</td><td>HTTP</td><td><a href="http://namenode1:50070/">http://namenode1:50070/</a></td><td>集群监控</td><td></td></tr><tr><td>HDFS SecondaryNamenode</td><td>50090</td><td>HTTP</td><td><a href="http://namenode1:50090/">http://namenode1:50090/</a></td><td>secondary监控</td></tr><tr><td>HDFS Datanode</td><td>50010</td><td></td><td>N/A</td><td>客户端接入/其他节点接入</td></tr><tr><td>50020</td><td></td><td>N/A</td><td></td><td></td></tr><tr><td>50075</td><td>HTTP</td><td><a href="http://datanode1:50075/">http://datanode1:50075/</a></td><td>节点监控</td><td></td></tr><tr><td>HBase Master</td><td>16000</td><td></td><td>hbase-client-1.x.x.jar</td><td>RegionServer接入</td></tr><tr><td>16010</td><td>HTTP</td><td><a href="http://namenode1:16010/">http://namenode1:16010/</a></td><td>集群监控</td><td></td></tr><tr><td>HBase RegionServer</td><td>16020</td><td></td><td>N/A</td><td>客户端接入</td></tr><tr><td>16030</td><td>HTTP</td><td><a href="http://datanode1:16030/">http://datanode1:16030/</a></td><td>节点监控</td><td></td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;节点&lt;/th&gt;
&lt;th&gt;端口号&lt;/th&gt;
&lt;th&gt;协议&lt;/th&gt;
&lt;th&gt;使用&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;zookeeper&lt;/td&gt;
&lt;td&gt;2181&lt;/td</summary>
      
    
    
    
    <category term="hbase" scheme="http://yoursite.com/categories/hbase/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>flink module</title>
    <link href="http://yoursite.com/2022/02/16/flink%20module/"/>
    <id>http://yoursite.com/2022/02/16/flink%20module/</id>
    <published>2022-02-15T16:59:01.425Z</published>
    <updated>2022-02-16T07:11:46.943Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><ul><li>flink-annotations: Flink自定义的一些注解，用于配置、控制编译等功能。</li><li>flink-clients: Flink客户端，用于向Flink集群提交任务、查询状态等。其中org.apache.flink.client.cli.CliFrontend就是执行./flink run的入口。</li><li>flink-connectors: Flink连接器，相当于Flink读写外部系统的客户端。这些连接器指定了外部存储如何作为Flink的source或sink。例如对于kafka来说，flink-connector-kafka-xx定义了FlinkKafkaConsumer和FlinkKafkaProducer类分别作为Flink的source和sink，实现了对kafka消费和生产的功能。从图二可以看出，flink 1.9目前支持的外部存储有Cassandra、ES、Kafka、Hive等一些开源外部存储。</li><li>flink-container: Flink对docker和kubernetes的支持。</li><li>flink-contrib: 社区开发者提供的一些新特性。</li><li>flink-core: Flink核心的API、类型的定义，包括底层的算子、状态、时间的实现，是Flink最重要的部分。Flink内部的各种参数配置也都定义在这个模块的configuration中。（这部分代码还没怎么看过，就不细讲了）。</li><li>flink-dist: Flink编译好之后的jar包会放在这个文件夹下，也就是网上下载的可执行的版本。其中也包括集群启动、终止的脚本，集群的配置文件等。</li><li>flink-docs: 这个模块并不是Flink的文档，而是Flink文档生成的代码。其中org.apache.flink.docs.configuration.ConfigOptionsDocGenerator是配置文档的生成器，修改相关配置的key或者默认值，重新运行这个类就会更新doc文件夹下的html文件。同样org.apache.flink.docs.rest.RestAPIDocGenerator是Flink RestAPI文档的生成器。</li><li>flink-fliesystems: Flink对各种文件系统的支持，包括HDFS、Azure、AWS S3、阿里云OSS等分布式文件系统。</li><li>flink-formats: Flink对各种格式的数据输入输出的支持。包括Json、CSV、Avro等常用的格式。</li><li>flink-java: Flink java的API，就是写flink应用时用到的map、window、keyBy、State等类或函数的实现。</li><li>flink-jepsen: 对Flink分布式系统正确性的测试，主要验证Flink的容错机制。</li><li>flink-libraries: Flink的高级API，包括CEP（复杂事件处理）、Gelly图处理库等。</li><li>flink-mesos: Flink对mesos集群管理的支持。</li><li>flink-metrics: Flink监控上报。支持上报到influxdb、prometheus等监控系统。具体的使用配置可以在flink-core模块的org.apache.flink.configuration.MetricOptions中找到。</li><li>flink-python: Flink对python的支持，目前还比较弱。</li><li>flink-queryable-state: Flink对可查询状态的支持，其中flink-queryable-state-runtime子模块实现了StateClientProxy和StateServer。这两部分都运行在TaskManager上，StateClientProxy负责接收外部请求，StateServe负责管理内部的queryable state。flink-queryable-state-client-java子模块实现了QueryableStateClient，作为外部系统访问queryable state的客户端。</li><li>flink-runtime: flink运行时核心代码，在第二节细说。</li><li>flink-runtime-web: Flink Web Dashboard的实现。默认启动standalone集群后，访问<a href="http://localhost:8081/">http://localhost:8081</a> 出现的界面。</li><li>flink-scala: Flink scala的API。</li><li>flink-scala-shell: Flink提供的scala命令行交互接口。</li><li>flink-state-backends: flink状态存储的方式，目前这个模块中只有RocksDBStateBackend，未来可能会支持更多种的状态存储，以适应不同的业务场景。MemoryStateBackend和FsStateBackend的实现并不在这个目录下，而是在flink-runtime目录下。</li><li>flink-streaming-java: Flink Streaming的java API。</li><li>flink-streaming-scala: Flink Streaming的scala API。</li><li>flink-table: Flink Table API，在第三小节中细说。</li><li>flink-yarn: Flink对yarn集群管理的支持。</li></ul><hr><ul><li><p>flink-runtime模块是Flink最核心的模块之一，实现了Flink的运行时框架，如JobManager、TaskManager、ResourceManager、Scheduler、Checkpoint Coordinator</p></li><li><p>flink-table模块属于Flink的上层API，包括java和scala版本的table-api，以及SQL的解析和SQL的执行。</p><blockquote><p>随着Flink SQL越来越受重视，flink-table从flink-libraries中移了出来，成为了独立的一级目录。Flink 1.9中，阿里把blink-planner开源了出来，这样整个flink-table中就有了2个planner。从长期来看，流批的统一是一个趋势，因此blink-planner只使用了StreamTableEnvironment中相关的API，而没有使用BatchTableEnvironment，将批当做一个有限的流来处理，希望通过这种方式实现流和批的统一。由于blink-table-planner更好的支持流批统一，且性能更好，在未来的版本中，很有可能完全替代flink-table-planner的功能，而flink-table-planner可能将会被移除。</p></blockquote></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;目录结构&quot;&gt;&lt;a href=&quot;#目录结构&quot; class=&quot;headerlink&quot; title=&quot;目录结构&quot;&gt;&lt;/a&gt;目录结构&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;flink-annotations: Flink自定义的一些注解，用于配置、控制编译等功能。&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>mysql HA &amp; keepalived</title>
    <link href="http://yoursite.com/2022/01/19/mysql%20HA/"/>
    <id>http://yoursite.com/2022/01/19/mysql%20HA/</id>
    <published>2022-01-19T07:54:47.000Z</published>
    <updated>2022-04-20T02:54:47.397Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mysql数据备份"><a href="#mysql数据备份" class="headerlink" title="mysql数据备份"></a>mysql数据备份</h1><h2 id="方案二：双主机HA部署"><a href="#方案二：双主机HA部署" class="headerlink" title="方案二：双主机HA部署"></a>方案二：双主机HA部署</h2><p><strong>前提</strong>：准备两个机器master1（172.20.3.113）和master2（172.20.3.114），且分别安装了mysql，其中IP地址根据生产具体ip进行替换</p><h3 id="一、配置my-cnf信息"><a href="#一、配置my-cnf信息" class="headerlink" title="一、配置my.cnf信息"></a>一、配置my.cnf信息</h3><ul><li><p>配置/etc/my.cnf文件（从mysql5.7开始不会自动生成my.cnf文件，所以需要手动创建）my.cnf文件内容大致如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[mysql]</span><br><span class="line">default-character-set=utf8         #设置mysql客户端默认字符集</span><br><span class="line">[mysqld]</span><br><span class="line">port = 3306  #可自行更改端口</span><br><span class="line">basedir=/usr/local/mysql</span><br><span class="line">datadir=/usr/local/mysql/data</span><br><span class="line">max_connections = 500              #最大连接数</span><br><span class="line">log_bin=mysql-bin</span><br><span class="line">server_id = 1                            #机器1设置为1，机器2设置为2</span><br><span class="line">binlog_format=ROW</span><br><span class="line">auto-increment-increment = 2            #字段变化增量值</span><br><span class="line">auto-increment-offset = 1               #机器1设置为1，机器2设置为2</span><br><span class="line">slave-skip-errors = all                 #忽略所有复制产生的错误</span><br><span class="line">gtid_mode=ON</span><br><span class="line">enforce-gtid-consistency=ON</span><br><span class="line"></span><br><span class="line">character-set-server = utf8</span><br><span class="line">default-storage-engine = INNODB</span><br><span class="line">lower_case_table_names = 1</span><br></pre></td></tr></table></figure><ul><li><p>[mysql]代表我们使用mysql命令登录mysql数据库时的默认设置 </p></li><li><p>[mysqld]代表数据库自身的默认设置</p><blockquote><p>注意：机器1和机器2只有server-id不同和auto-increment-offset不同,其他必须相同。</p><p>部分配置项解释如下：</p><p>binlog_format= ROW：指定mysql的binlog日志的格式，日志中会记录成每一行数据被修改的形式，然后在 slave 端再对相同的数据进行修改。</p><p>auto-increment-increment= 2：表示自增长字段每次递增的量，其默认值是1。它的值应设为整个结构中服务器的总数，本案例用到两台服务器，所以值设为2。</p><p>auto-increment-offset= 2：用来设定数据库中自动增长的起点(即初始值)，因为这两能服务器都设定了一次自动增长值2，所以它们的起点必须得不同，这样才能避免两台服务器数据同步时出现主键冲突。</p><p>注：另外还可以在my.cnf配置文件中，添加“binlog_do_db=数据库名”配置项（可以添加多个）来指定要同步的数据库。如果配置了这个配置项，如果没添加在该配置项后面的数据库，则binlog不记录它的事件。</p></blockquote></li></ul></li><li><p>切换到datacanvas用户进行mysql启动服务 （建议）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/mysql/support-files/mysql.server start</span><br></pre></td></tr></table></figure><p>或者在已经创建软连接的前提下，切换到root用户，并启动mysql服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mysql restart</span><br></pre></td></tr></table></figure></li><li><p>客户端登录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/mysql/bin/mysql -uroot -p</span><br></pre></td></tr></table></figure><p>  设置可远程登录root用户</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;123456&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><blockquote><p>注意：上面的密码’123456’修改成真实的root密码</p></blockquote></li></ul><h4 id="开始设置双主备份"><a href="#开始设置双主备份" class="headerlink" title="开始设置双主备份"></a>开始设置双主备份</h4><ul><li><p>在master1上操作</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">先在master2上执行，</span><br><span class="line"><span class="keyword">show</span> master status;（获取master_log_file和master_log_pos信息）</span><br><span class="line"></span><br><span class="line">在master1上执行</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;172.20.3.114&#x27;</span>,master_port<span class="operator">=</span><span class="number">3306</span>,master_user<span class="operator">=</span><span class="string">&#x27;rt&#x27;</span>,master_password<span class="operator">=</span><span class="string">&#x27;rt123&#x27;</span>,master_log_file<span class="operator">=</span><span class="string">&#x27;mysql-bin.000003&#x27;</span>,master_log_pos<span class="operator">=</span><span class="number">194</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">start</span> slave;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> slave status\G</span><br></pre></td></tr></table></figure></li><li><p>在master2上操作</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">先在master1上执行，</span><br><span class="line"><span class="keyword">show</span> master status;（获取master_log_file和master_log_pos信息）</span><br><span class="line">在master2上执行</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;172.20.3.113&#x27;</span>,master_port<span class="operator">=</span><span class="number">3306</span>,master_user<span class="operator">=</span><span class="string">&#x27;rt&#x27;</span>,master_password<span class="operator">=</span><span class="string">&#x27;rt123&#x27;</span>,master_log_file<span class="operator">=</span><span class="string">&#x27;mysql-bin.000004&#x27;</span>,master_log_pos<span class="operator">=</span><span class="number">194</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">start</span> slave;</span><br><span class="line"></span><br><span class="line"><span class="keyword">show</span> slave status\G</span><br></pre></td></tr></table></figure></li></ul><hr><h3 id="二、keepalived安装配置"><a href="#二、keepalived安装配置" class="headerlink" title="二、keepalived安装配置"></a>二、keepalived安装配置</h3><p>需要在master1和master2的机器上安装keepalived服务，安装过程大致如下：</p><ul><li><p>通过地址<a href="https://pkgs.org/download/keepalived%E4%B8%8B%E8%BD%BD%E7%9B%B8%E5%BA%94%E7%9A%84%E5%AE%89%E8%A3%85%E7%89%88%E6%9C%AC%EF%BC%8C%E7%84%B6%E5%90%8E%E8%A7%A3%E5%8E%8B%E7%9A%84%E7%9B%B8%E5%85%B3%E7%9B%AE%E5%BD%95%E3%80%82">https://pkgs.org/download/keepalived下载相应的安装版本，然后解压的相关目录。</a></p></li><li><p>源码的安装一般由3个步骤组成：配置（configure）、编译（make）、安装( make install）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/local/keepalived</span><br></pre></td></tr></table></figure><p> 如果提示错误信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">configure: error: </span><br><span class="line">  !!! OpenSSL is not properly installed on your system. !!!</span><br><span class="line">  !!! Can not include OpenSSL headers files.            !!!</span><br></pre></td></tr></table></figure><p>需要安装yum install openssl openssl-devel（RedHat系统），<br>再次执行./configure –prefix=/usr/local/keepalived</p></li><li><p>在安装目录执行<code>make &amp;&amp; make install</code>进行编译安装</p></li><li><p>keepalived配置文件，默认情况下keepalived启动时会去/etc/keepalived目录下加载配置文件keepalived.conf</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File forkeepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">notification_email &#123;</span><br><span class="line">[email protected]</span><br><span class="line"> &#125;</span><br><span class="line">notification_email_from  [email protected]</span><br><span class="line">smtp_server 127.0.0.1</span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line">router_id MYSQL_HA      #标识，双主相同</span><br><span class="line"> &#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"> state BACKUP           #两台都设置BACKUP</span><br><span class="line"> interface eth0         #网卡名称</span><br><span class="line"> virtual_router_id 51       #主备相同</span><br><span class="line"> priority 100   #优先级，另一台改为90    </span><br><span class="line"> advert_int 1    </span><br><span class="line"> nopreempt  #不抢占，只在优先级高的机器上设置即可，优先级低的机器不设置    </span><br><span class="line"> authentication &#123;</span><br><span class="line"> auth_type PASS    #鉴权，默认通过</span><br><span class="line"> auth_pass 1111    # 鉴权访问密码</span><br><span class="line"> &#125;</span><br><span class="line"> virtual_ipaddress &#123;</span><br><span class="line">  172.20.3.200    #虚拟ip</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 172.20.3.200 3306 &#123;    </span><br><span class="line">     delay_loop 2   #每个2秒检查一次real_server状态    </span><br><span class="line">     lb_algo wrr   #LVS算法    </span><br><span class="line">     lb_kind DR    #LVS模式    </span><br><span class="line">     persistence_timeout 60   #会话保持时间    </span><br><span class="line">     protocol TCP    </span><br><span class="line">     real_server 172.20.3.113 3306 &#123;    </span><br><span class="line">         weight 1    #指定了当前主机的权重    </span><br><span class="line">         notify_down /usr/local/keepalived/kill_keepalived.sh  #检测到服务down后执行的脚本    </span><br><span class="line">         TCP_CHECK &#123;    </span><br><span class="line">             connect_timeout 10    #连接超时时间</span><br><span class="line">             delay_before_retry 3   #重连间隔时间    </span><br><span class="line">             connect_port 3306   #健康检查端口  </span><br><span class="line">         &#125;  </span><br><span class="line">     &#125;</span><br><span class="line">     real_server 172.20.3.114 3306 &#123;</span><br><span class="line">        weight 2</span><br><span class="line">        notify_down /usr/local/keepalived/kill_keepalived.sh  #检测到服务down后执行的脚本</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 10</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 3306</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：参数priority两个服务器配置不同，其中virtual_ipaddress是虚拟ip，之后项目可通过访问 172.20.3.200:3306进行访问双主mysql机群。</p><p>上述配置中会涉及/usr/local/keepalived/kill_keepalived.sh，分别在两台服务器上编写kill_keepalived.sh脚本内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">pkill keepalived</span><br></pre></td></tr></table></figure><p>   然后给脚本加权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x /usr/local/keepalived/kill_keepalived.sh</span><br></pre></td></tr></table></figure><ul><li>启动keepalived服务<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service keepalived start</span><br></pre></td></tr></table></figure>如果启动失败，尝试输入<code>pkill -9 keepalived</code>，然后再尝试重启</li></ul><hr><h3 id="三、访问双主mysql集群"><a href="#三、访问双主mysql集群" class="headerlink" title="三、访问双主mysql集群"></a>三、访问双主mysql集群</h3><p>两台机器的mysql和keepalived配置完成之后，即可在项目中，通过访问虚拟ip地址（172.20.3.200:3306）进行mysql集群的访问。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;mysql数据备份&quot;&gt;&lt;a href=&quot;#mysql数据备份&quot; class=&quot;headerlink&quot; title=&quot;mysql数据备份&quot;&gt;&lt;/a&gt;mysql数据备份&lt;/h1&gt;&lt;h2 id=&quot;方案二：双主机HA部署&quot;&gt;&lt;a href=&quot;#方案二：双主机HA部署&quot; c</summary>
      
    
    
    
    <category term="mysql" scheme="http://yoursite.com/categories/mysql/"/>
    
    
    <category term="HA" scheme="http://yoursite.com/tags/HA/"/>
    
  </entry>
  
  <entry>
    <title>mysql backup plan</title>
    <link href="http://yoursite.com/2022/01/19/mysql%20backup%20A/"/>
    <id>http://yoursite.com/2022/01/19/mysql%20backup%20A/</id>
    <published>2022-01-19T06:54:47.000Z</published>
    <updated>2022-04-20T02:54:42.521Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mysql数据备份"><a href="#mysql数据备份" class="headerlink" title="mysql数据备份"></a>mysql数据备份</h1><h2 id="方案一：定期备份数据库数据文件"><a href="#方案一：定期备份数据库数据文件" class="headerlink" title="方案一：定期备份数据库数据文件"></a>方案一：定期备份数据库数据文件</h2><h3 id="一、编写shell脚本"><a href="#一、编写shell脚本" class="headerlink" title="一、编写shell脚本"></a>一、编写shell脚本</h3><p>脚本文件<strong>backup_mysql.sh</strong>信息如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">用户名</span></span><br><span class="line">username=root</span><br><span class="line"><span class="meta">#</span><span class="bash">密码</span></span><br><span class="line">password=填写密码</span><br><span class="line"><span class="meta">#</span><span class="bash">将要备份的数据库</span></span><br><span class="line">database_name=填写需要备份的数据库</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">保存备份文件最多个数</span></span><br><span class="line">count=30</span><br><span class="line"><span class="meta">#</span><span class="bash">备份保存路径</span></span><br><span class="line">backup_path=/data/mysql_backup</span><br><span class="line"><span class="meta">#</span><span class="bash">日期</span></span><br><span class="line">date_time=`date +%Y-%m-%d-%H-%M`</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">如果文件夹不存在则创建</span></span><br><span class="line">if [ ! -d $backup_path ]; </span><br><span class="line">then     </span><br><span class="line">    mkdir -p $backup_path; </span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span><span class="bash">开始备份</span></span><br><span class="line">mysqldump -u $username -p$password $database_name &gt; $backup_path/$database_name-$date_time.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">开始压缩</span></span><br><span class="line">cd $backup_path</span><br><span class="line">tar -zcvf $database_name-$date_time.tar.gz $database_name-$date_time.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">删除源文件</span></span><br><span class="line">rm -rf $backup_path/$database_name-$date_time.sql</span><br><span class="line"><span class="meta">#</span><span class="bash">更新备份日志</span></span><br><span class="line">echo &quot;create $backup_path/$database_name-$date_time.tar.gz&quot; &gt;&gt; $backup_path/dump.log</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">找出需要删除的备份</span></span><br><span class="line">delfile=`ls -l -crt $backup_path/*.tar.gz | awk &#x27;&#123;print $9 &#125;&#x27; | head -1`</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">判断现在的备份数量是否大于阈值</span></span><br><span class="line">number=`ls -l -crt  $backup_path/*.tar.gz | awk &#x27;&#123;print $9 &#125;&#x27; | wc -l`</span><br><span class="line"></span><br><span class="line">if [ $number -gt $count ]</span><br><span class="line">then</span><br><span class="line"><span class="meta">  #</span><span class="bash">删除最早生成的备份，只保留count数量的备份</span></span><br><span class="line">  rm $delfile</span><br><span class="line"><span class="meta">  #</span><span class="bash">更新删除文件日志</span></span><br><span class="line">  echo &quot;delete $delfile&quot; &gt;&gt; $backup_path/dump.log</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>该脚本实现的功能：备份指定数据库的数据信息到指定目录，并只保存指定数量的最新文件。</p><p>注意：脚本中需要补全脚本中的<strong>password</strong>和<strong>database_name</strong>信息，可修改备份保存路径<strong>backup_path</strong>，以及最多保存的备份文件数量<strong>count</strong>。</p><p>编写完脚本信息之后，需要给脚本赋予可执行权限 <code>chmod +x backup_mysql.sh</code></p><h3 id="二、设定定时任务crontab"><a href="#二、设定定时任务crontab" class="headerlink" title="二、设定定时任务crontab"></a>二、设定定时任务crontab</h3><p>运行crontab -e命令，打开一个可编辑的文本，输入<code>0 1 * * * /path/to/backup_mysql.sh</code>  保本并退出即添加完成。</p><p>注意：其中<code>0 1 * * *</code>，表示每天凌晨1点进行备份操作，可自行修改1的值（范围0～23）</p><p>其中路径信息<code>/path/to/backup_mysql.sh</code>需要修改为实际的脚本路径。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;mysql数据备份&quot;&gt;&lt;a href=&quot;#mysql数据备份&quot; class=&quot;headerlink&quot; title=&quot;mysql数据备份&quot;&gt;&lt;/a&gt;mysql数据备份&lt;/h1&gt;&lt;h2 id=&quot;方案一：定期备份数据库数据文件&quot;&gt;&lt;a href=&quot;#方案一：定期备份数据</summary>
      
    
    
    
    <category term="mysql" scheme="http://yoursite.com/categories/mysql/"/>
    
    
    <category term="backup" scheme="http://yoursite.com/tags/backup/"/>
    
  </entry>
  
  <entry>
    <title>flink cdc</title>
    <link href="http://yoursite.com/2022/01/15/flink%20cdc/"/>
    <id>http://yoursite.com/2022/01/15/flink%20cdc/</id>
    <published>2022-01-15T08:24:07.000Z</published>
    <updated>2022-04-20T02:59:22.144Z</updated>
    
    <content type="html"><![CDATA[<p>reference</p><p><a href="https://developer.aliyun.com/article/848448?spm=a2c6h.12873639.0.d102020001.6a5a2de1EwwX6V&utm_content=g_1000316418">Flink Forward Aisa 系列专刊｜Flink CDC 新一代数据集成框架 - 技术原理、入门与生产实践-阿里云开发者社区</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;reference&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://developer.aliyun.com/article/848448?spm=a2c6h.12873639.0.d102020001.6a5a2de1EwwX6V&amp;utm_content=g_100031</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="cdc" scheme="http://yoursite.com/tags/cdc/"/>
    
  </entry>
  
  <entry>
    <title>flink cep</title>
    <link href="http://yoursite.com/2022/01/14/flink%20cep/"/>
    <id>http://yoursite.com/2022/01/14/flink%20cep/</id>
    <published>2022-01-14T08:24:07.000Z</published>
    <updated>2022-02-11T06:45:12.698Z</updated>
    
    <content type="html"><![CDATA[<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>风险控制<br>对用户异常行为模式进行实时检测，当一个用户发生了不该发生的行为，判定这个用户是不是有违规操作的嫌疑。</p><p>策略营销<br>用预先定义好的规则对用户的行为轨迹进行实时跟踪，对行为轨迹匹配预定义规则的用户实时发送相应策略的推广。</p><p>运维监控<br>灵活配置多指标、多依赖来实现更复杂的监控模式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;headerlink&quot; title=&quot;应用场景&quot;&gt;&lt;/a&gt;应用场景&lt;/h3&gt;&lt;p&gt;风险控制&lt;br&gt;对用户异常行为模式进行实时检测，当一个用户发生了不该发生的行为，判定这个用户是不是有违规操作的嫌疑。&lt;/p&gt;</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="cep" scheme="http://yoursite.com/tags/cep/"/>
    
  </entry>
  
  <entry>
    <title>flink watermark</title>
    <link href="http://yoursite.com/2022/01/11/flink%20watermark/"/>
    <id>http://yoursite.com/2022/01/11/flink%20watermark/</id>
    <published>2022-01-11T10:42:32.000Z</published>
    <updated>2022-01-11T10:44:03.586Z</updated>
    
    <content type="html"><![CDATA[<p>Watermark是Apache Flink为了处理EventTime 窗口计算提出的一种机制,本质上也是一种时间戳。</p><p>由Apache Flink Source或者自定义的Watermark生成器按照需求Punctuated或者Periodic两种方式生成的一种系统Event，与普通数据流Event一样流转到对应的下游算子，接收到Watermark Event的算子以此不断调整自己管理的EventTime clock。</p><p>Apache Flink 框架保证Watermark单调递增，算子接收到一个Watermark时候，框架知道不会再有任何小于该Watermark的时间戳的数据元素到来了，所以Watermark可以看做是告诉Apache Flink框架数据流已经处理到什么位置(时间维度)的方式。</p><p>Watermark的产生和Apache Flink内部处理逻辑如下图所示:</p><p><img src="/images/flink/flink_watermark.png"></p><h3 id="产生方式"><a href="#产生方式" class="headerlink" title="产生方式"></a>产生方式</h3><ul><li><p>Punctuated - 数据流中每一个递增的EventTime都会产生一个Watermark。 在实际的生产中Punctuated方式在TPS很高的场景下会产生大量的Watermark在一定程度上对下游算子造成压力，所以只有在实时性要求非常高的场景才会选择Punctuated的方式进行Watermark的生成。</p></li><li><p>Periodic - 周期性的（一定时间间隔或者达到一定的记录条数）产生一个Watermark。在实际的生产中Periodic的方式必须结合时间和积累条数两个维度继续周期性产生Watermark，否则在极端情况下会有很大的延时。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Watermark是Apache Flink为了处理EventTime 窗口计算提出的一种机制,本质上也是一种时间戳。&lt;/p&gt;
&lt;p&gt;由Apache Flink Source或者自定义的Watermark生成器按照需求Punctuated或者Periodic两种方式生成的一</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>flink state</title>
    <link href="http://yoursite.com/2022/01/11/flink%20state/"/>
    <id>http://yoursite.com/2022/01/11/flink%20state/</id>
    <published>2022-01-11T06:32:39.000Z</published>
    <updated>2022-02-19T05:47:13.406Z</updated>
    
    <content type="html"><![CDATA[<h3 id="what"><a href="#what" class="headerlink" title="what ?"></a>what ?</h3><p>State是指流计算过程中计算节点的中间计算结果或元数据属性，比如 在aggregation过程中要在state中记录中间聚合结果，比如 Apache Kafka 作为数据源时候，我们也要记录已经读取记录的offset，这些State数据在计算过程中会进行持久化(插入或更新)。所以Apache Flink中的State就是与时间相关的，Apache Flink任务的内部数据（计算数据和元数据属性）的快照。</p><h3 id="why"><a href="#why" class="headerlink" title="why ?"></a>why ?</h3><p>与批计算相比，State是流计算特有的，批计算没有failover机制，要么成功，要么重新计算。流计算在 大多数场景 下是增量计算，数据逐条处理（大多数场景)，每次计算是在上一次计算结果之上进行处理的，这样的机制势必要将上一次的计算结果进行存储（生产模式要持久化），另外由于 机器，网络，脏数据等原因导致的程序错误，在重启job时候需要从成功的检查点(checkpoint，后面篇章会专门介绍)进行state的恢复。增量计算，Failover这些机制都需要state的支撑。</p><h3 id="how"><a href="#how" class="headerlink" title="how ?"></a>how ?</h3><h4 id="存储实现"><a href="#存储实现" class="headerlink" title="存储实现"></a>存储实现</h4><ul><li><p>基于内存的HeapStateBackend - 在debug模式使用，不 建议在生产模式下应用；</p></li><li><p>基于HDFS的FsStateBackend - 分布式文件持久化，每次读写都产生网络IO，整体性能不佳；</p></li><li><p>基于RocksDB的RocksDBStateBackend - 本地文件+异步HDFS持久化；</p><blockquote><p>Apache Flink版本选择用RocksDB+HDFS的方式进行State的存储，State存储分两个阶段，首先本地存储到RocksDB，然后异步的同步到远程的HDFS。 这样而设计既消除了HeapStateBackend的局限（内存大小，机器坏掉丢失等），也减少了纯分布式存储的网络IO开销。</p></blockquote></li><li><p>还有一个是基于Niagara(Alibaba内部实现)NiagaraStateBackend - 分布式持久化- 在Alibaba生产环境应用；</p></li></ul><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>通过算子和数据层面划分</p><ul><li><p>算子类state</p><p>KeyedState - 这里面的key是我们在SQL语句中对应的GroupBy/PartitioneBy里面的字段，key的值就是groupby/PartitionBy字段组成的Row的字节数组，每一个key都有一个属于自己的State，key与key之间的State是不可见的</p></li><li><p>数据类state</p><p>OperatorState - Apache Flink内部的Source Connector的实现中就会用OperatorState来记录source数据读取的offset。</p></li></ul><h3 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h3><p>checkpoint是使Flink 能从故障恢复的一种内部机制。检查点是 Flink 应用状态的一个一致性副本，包括了输入的读取位点。在发生故障时，Flink 通过从检查点加载应用程序状态来恢复，并从恢复的读取位点继续处理，就好像什么事情都没发生一样。Flink的状态存储在Flink的内部,这样做的好处就是不再依赖外部系统,降低了对外部系统的依赖,在Flink的内部,通过自身的进程去访问状态变量.同时会定期的做checkpoint持久化,把checkpoint存储在一个分布式的持久化系统中,如果发生故障,就会从最近的一次checkpoint中将整个流的状态进行恢复.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;what&quot;&gt;&lt;a href=&quot;#what&quot; class=&quot;headerlink&quot; title=&quot;what ?&quot;&gt;&lt;/a&gt;what ?&lt;/h3&gt;&lt;p&gt;State是指流计算过程中计算节点的中间计算结果或元数据属性，比如 在aggregation过程中要在state中记</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>flink streaming warehouse</title>
    <link href="http://yoursite.com/2022/01/11/flink%20streaming%20warehouse/"/>
    <id>http://yoursite.com/2022/01/11/flink%20streaming%20warehouse/</id>
    <published>2022-01-11T02:57:26.000Z</published>
    <updated>2022-03-07T13:09:14.847Z</updated>
    
    <content type="html"><![CDATA[<p>流式数仓（Streaming Warehouse）更准确地说，其实是“make data warehouse streaming”，就是让整个数仓的数据全实时地流动起来，且是以纯流的方式而不是微批（mini-batch）的方式流动。</p><p>目标是实现一个具备端到端实时性的纯流服务（Streaming Service），用一套 API 分析所有流动中的数据，当源头数据发生变化，比如捕捉到在线服务的 Log 或数据库的 Binlog 以后，就按照提前定义好的 Query 逻辑或数据处理逻辑，对数据进行分析，分析后的数据落到数仓的某一个分层，再从第一个分层向下一个分层流动，然后数仓所有分层会全部流动起来，最终流到一个在线系统里，用户可以看到整个数仓的全实时流动效果。</p><p>在这个过程中，数据是主动的，而查询是被动的，分析由数据的变化来驱动。同时在垂直方向上，对每一个数据明细层，用户都可以执行 Query 进行主动查询，并且能实时获得查询结果。此外，它还能兼容离线分析场景，API 依然是同一套，实现真正的一体化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;流式数仓（Streaming Warehouse）更准确地说，其实是“make data warehouse streaming”，就是让整个数仓的数据全实时地流动起来，且是以纯流的方式而不是微批（mini-batch）的方式流动。&lt;/p&gt;
&lt;p&gt;目标是实现一个具备端到端实</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="warehouse" scheme="http://yoursite.com/tags/warehouse/"/>
    
  </entry>
  
  <entry>
    <title>macos command</title>
    <link href="http://yoursite.com/2022/01/07/mac%20command/"/>
    <id>http://yoursite.com/2022/01/07/mac%20command/</id>
    <published>2022-01-07T06:03:15.000Z</published>
    <updated>2022-04-19T01:26:52.262Z</updated>
    
    <content type="html"><![CDATA[<ul><li>解压带有中文名称的zip包</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ditto -V -x -k --sequesterRsrc filename.zip destination</span><br></pre></td></tr></table></figure><ul><li>查看目录下文件夹大小<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -d 1 -h    命令查看当前目录下所有文件夹的大小 -d 指深度，后面加一个数值</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;解压带有中文名称的zip包&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/</summary>
      
    
    
    
    <category term="macos" scheme="http://yoursite.com/categories/macos/"/>
    
    
    <category term="command" scheme="http://yoursite.com/tags/command/"/>
    
  </entry>
  
  <entry>
    <title>fabric8 &amp; docker-maven-plugin</title>
    <link href="http://yoursite.com/2022/01/07/fabric8(docker-maven-plugin)/"/>
    <id>http://yoursite.com/2022/01/07/fabric8(docker-maven-plugin)/</id>
    <published>2022-01-07T05:59:21.000Z</published>
    <updated>2022-04-20T03:01:02.879Z</updated>
    
    <content type="html"><![CDATA[<h2 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;todo&quot;&gt;&lt;a href=&quot;#todo&quot; class=&quot;headerlink&quot; title=&quot;todo&quot;&gt;&lt;/a&gt;todo&lt;/h2&gt;</summary>
      
    
    
    
    <category term="docker" scheme="http://yoursite.com/categories/docker/"/>
    
    
    <category term="plugin" scheme="http://yoursite.com/tags/plugin/"/>
    
  </entry>
  
  <entry>
    <title>file system</title>
    <link href="http://yoursite.com/2022/01/07/file%20system/"/>
    <id>http://yoursite.com/2022/01/07/file%20system/</id>
    <published>2022-01-07T05:59:21.000Z</published>
    <updated>2022-01-07T06:23:11.573Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h1><p><img src="/images/fileSystemType.jpeg" alt="fileSystemType.jpeg"></p><ul><li><p>Mac 默认可以读 Windows 的 NTFS 格式，但不能写。</p></li><li><p>Windows 无法识别 Mac 的 HFS+ 或 APFS 格式。</p></li><li><p>Mac 和 Windows 都能正常读写 FAT32 和 ExFAT 格式</p></li><li><p>linux</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Linux：存在几十个文件系统类型：ext2，ext3，ext4，xfs，brtfs，zfs（man 5 fs可以取得全部文件系统的介绍）</span><br><span class="line"></span><br><span class="line">不同文件系统采用不同的方法来管理磁盘空间，各有优劣；文件系统是具体到分区的，所以格式化针对的是分区，分区格式化是指采用指定的文件系统类型对分区空间进行登记、索引并建立相应的管理表格的过程。</span><br><span class="line"></span><br><span class="line">ext2具有极快的速度和极小的CPU占用率，可用于硬盘和移动存储设备</span><br><span class="line">ext3增加日志功能，可回溯追踪</span><br><span class="line">ext4日志式文件系统，支持1EB（1024*1024TB），最大单文件16TB，支持连续写入可减少文件碎片。rhel6默认文件系统</span><br><span class="line">xfs可以管理500T的硬盘。rhel7默认文件系统</span><br><span class="line">brtfs文件系统针对固态盘做优化，</span><br></pre></td></tr></table></figure></li><li><p>windows</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FAT16：MS—DOS和win95采用的磁盘分区格式，采用16位的文件分配表，只支持2GB的磁盘分区，最大单文件2GB，且磁盘利用率低</span><br><span class="line">FAT32：（即Vfat）采用32位的文件分配表，支持最大分区128GB，最大文件4GB</span><br><span class="line">NTFS：支持最大分区2TB，最大文件2TB，安全性和稳定性非常好，不易出现文件碎片。</span><br></pre></td></tr></table></figure></li></ul><hr><p>reference</p><p><a href="https://www.yinxiang.com/everhub/note/0312ed71-61f5-4c75-9c77-3db0ffdeb613">https://www.yinxiang.com/everhub/note/0312ed71-61f5-4c75-9c77-3db0ffdeb613</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;文件系统&quot;&gt;&lt;a href=&quot;#文件系统&quot; class=&quot;headerlink&quot; title=&quot;文件系统&quot;&gt;&lt;/a&gt;文件系统&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/images/fileSystemType.jpeg&quot; alt=&quot;fileSystemType.jpe</summary>
      
    
    
    
    <category term="file system" scheme="http://yoursite.com/categories/file-system/"/>
    
    
    <category term="snippet" scheme="http://yoursite.com/tags/snippet/"/>
    
  </entry>
  
  <entry>
    <title>flink join</title>
    <link href="http://yoursite.com/2022/01/05/flink%20join/"/>
    <id>http://yoursite.com/2022/01/05/flink%20join/</id>
    <published>2022-01-05T08:52:01.000Z</published>
    <updated>2022-02-09T09:45:09.832Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>使用 SQL 进行数据分析的过程中，join 是经常要使用的操作。</p><p>在离线场景中，join 的数据集是有边界的，可以缓存数据有边界的数据集进行查询，有Nested Loop/Hash Join/Sort Merge Join 等多表 join；</p><p>而在实时场景中，join 两侧的数据都是无边界的数据流，所以缓存数据集对长时间 job 来说，存储和查询压力很大，另外双流的到达时间可能不一致，造成 join 计算结果准确度不够；因此，Flink SQL 提供了多种 join 方法，来帮助用户应对各种 join 场景。</p></blockquote><h3 id="regular-join"><a href="#regular-join" class="headerlink" title="regular join"></a>regular join</h3><blockquote><p>regular join 是最通用的 join 类型，不支持时间窗口以及时间属性，任何一侧数据流有更改都是可见的，直接影响整个 join 结果。如果有一侧数据流增加一个新纪录，那么它将会把另一侧的所有的过去和将来的数据合并在一起，因为 regular join 没有剔除策略，这就影响最新输出的结果; 正因为历史数据不会被清理，所以 regular join 支持数据流的任何更新操作。</p><p>对于 regular join 来说，更适合用于离线场景和小数据量场景。</p></blockquote><ul><li>语法<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> columns</span><br><span class="line"><span class="keyword">FROM</span> t1  [<span class="keyword">AS</span> <span class="operator">&lt;</span>alias1<span class="operator">&gt;</span>]</span><br><span class="line">[<span class="keyword">LEFT</span><span class="operator">/</span><span class="keyword">INNER</span><span class="operator">/</span><span class="keyword">FULL</span> <span class="keyword">OUTER</span>] <span class="keyword">JOIN</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.column1 <span class="operator">=</span> t2.key<span class="operator">-</span>name1</span><br></pre></td></tr></table></figure></li></ul><h3 id="interval-join"><a href="#interval-join" class="headerlink" title="interval join"></a>interval join</h3><blockquote><p>相对于 regular join，interval Join 则利用窗口的给两个输入表设定一个 Join 的时间界限，超出时间范围的数据则对 join 不可见并可以被清理掉，这样就能修正 regular join 因为没有剔除数据策略带来 join 结果的误差以及需要大量的资源。</p><p>但是使用interval join，需要定义好时间属性字段，可以是计算发生的 Processing Time，也可以是根据数据本身提取的 Event Time；如果是定义的是 Processing Time，则Flink 框架本身根据系统划分的时间窗口定时清理数据；如果定义的是 Event Time，Flink 框架分配 Event Time 窗口并根据设置的 watermark 来清理数据。</p></blockquote><ul><li><p>语法1</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> columns</span><br><span class="line"><span class="keyword">FROM</span> t1  [<span class="keyword">AS</span> <span class="operator">&lt;</span>alias1<span class="operator">&gt;</span>]</span><br><span class="line">[<span class="keyword">LEFT</span><span class="operator">/</span><span class="keyword">INNER</span><span class="operator">/</span><span class="keyword">FULL</span> <span class="keyword">OUTER</span>] <span class="keyword">JOIN</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.column1 <span class="operator">=</span> t2.key<span class="operator">-</span>name1 <span class="keyword">AND</span> t1.timestamp <span class="keyword">BETWEEN</span> t2.timestamp  <span class="keyword">AND</span>  <span class="keyword">BETWEEN</span> t2.timestamp <span class="operator">+</span> <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>;</span><br></pre></td></tr></table></figure></li><li><p>语法2</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> columns</span><br><span class="line"><span class="keyword">FROM</span> t1  [<span class="keyword">AS</span> <span class="operator">&lt;</span>alias1<span class="operator">&gt;</span>]</span><br><span class="line">[<span class="keyword">LEFT</span><span class="operator">/</span><span class="keyword">INNER</span><span class="operator">/</span><span class="keyword">FULL</span> <span class="keyword">OUTER</span>] <span class="keyword">JOIN</span> t2</span><br><span class="line"><span class="keyword">ON</span> t1.column1 <span class="operator">=</span> t2.key<span class="operator">-</span>name1 <span class="keyword">AND</span> t2.timestamp <span class="operator">&lt;=</span> t1.timestamp <span class="keyword">and</span> t1.timestamp <span class="operator">&lt;=</span>  t2.timestamp <span class="operator">+</span> <span class="operator">+</span> <span class="type">INTERVAL</span> ’<span class="number">10</span><span class="string">&#x27; MINUTE ;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="temproal-table-join"><a href="#temproal-table-join" class="headerlink" title="temproal table join"></a>temproal table join</h3><blockquote><p>interval Join 提供了剔除数据的策略，解决资源问题以及计算更加准确，这是有个前提：join 的两个流需要时间属性，需要明确时间的下界，来方便剔除数据；</p><p>显然，这种场景不适合维度表的 join，因为维度表没有时间界限，对于这种场景，Flink 提供了 temproal table join 来覆盖此类场景。</p><p>在 regular join和interval join中，join 两侧的表是平等的，任意的一个表的更新，都会去和另外的历史纪录进行匹配，temproal table 的更新对另一表在该时间节点以前的记录是不可见的。</p></blockquote><ul><li>语法<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> columns</span><br><span class="line"><span class="keyword">FROM</span> t1  [<span class="keyword">AS</span> <span class="operator">&lt;</span>alias1<span class="operator">&gt;</span>]</span><br><span class="line">[<span class="keyword">LEFT</span>] <span class="keyword">JOIN</span> t2 <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> t1.proctime [<span class="keyword">AS</span> <span class="operator">&lt;</span>alias2<span class="operator">&gt;</span>]</span><br><span class="line"><span class="keyword">ON</span> t1.column1 <span class="operator">=</span> t2.key<span class="operator">-</span>name1</span><br></pre></td></tr></table></figure></li></ul><hr><p>reference:</p><p><a href="https://developer.aliyun.com/article/780048?accounttraceid=dd5fdbf3eed04f6185ed6461d8a33012zihq">Flink SQL 实战：双流 join 场景应用-阿里云开发者社区</a></p><p><a href="https://www.liangzl.com/get-article-detail-114889.html">Flink SQL 功能解密系列 —— 维表 JOIN 与异步优化</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;使用 SQL 进行数据分析的过程中，join 是经常要使用的操作。&lt;/p&gt;
&lt;p&gt;在离线场景中，join 的数据集是有边界的，可以缓存数据有边界的数据集进行查询，有Nested Loop/Hash Join/Sort Merge Join 等多表 </summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="learn" scheme="http://yoursite.com/tags/learn/"/>
    
  </entry>
  
  <entry>
    <title>flink sql</title>
    <link href="http://yoursite.com/2022/01/04/flink%20sql/"/>
    <id>http://yoursite.com/2022/01/04/flink%20sql/</id>
    <published>2022-01-04T09:55:24.000Z</published>
    <updated>2022-01-05T03:02:49.900Z</updated>
    
    <content type="html"><![CDATA[<ul><li>NOT ENFORCED</li></ul><blockquote><p>If you know that the data conforms to these constraints, you can use the NOT ENFORCED capability to help achieve two goals:</p><ul><li>Improve performance, primarily in insert, update, and delete operations on the table</li><li>Reduce space requirements that are associated with enforcing a primary key or unique constraint</li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;NOT ENFORCED&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;If you know that the data conforms to these constraints, you can use the NOT ENFORCED capab</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>flink on yarn</title>
    <link href="http://yoursite.com/2022/01/04/flink%20on%20yarn/"/>
    <id>http://yoursite.com/2022/01/04/flink%20on%20yarn/</id>
    <published>2022-01-03T16:27:40.000Z</published>
    <updated>2022-04-20T02:58:53.733Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Flink提供了两种在yarn上运行的模式，分别为Session-Cluster和Per-Job-Cluster模式，本文分析两种模式及启动流程。</strong></p><h2 id="interaction"><a href="#interaction" class="headerlink" title="interaction"></a>interaction</h2><p><img src="/images/flinkOnYarn/flink_on_yarn.png"> </p><h2 id="two-way-to-submit-job-on-yarn"><a href="#two-way-to-submit-job-on-yarn" class="headerlink" title="two way to submit job on yarn"></a>two way to submit job on yarn</h2><p><img src="/images/flinkOnYarn/submit_job.png"></p><h3 id="first-way：yarn-session"><a href="#first-way：yarn-session" class="headerlink" title="first way：yarn session"></a>first way：yarn session</h3><blockquote><p>(Start a long-running Flink cluster on YARN)这种方式需要先启动集群，然后在提交作业，接着会向yarn申请一块空间后，资源永远保持不变。如果资源满了，下一个作业就无法提交，只能等到yarn中的其中一个作业执行完成后，释放了资源，那下一个作业才会正常提交.</p><p>ps:所有作业共享Dispatcher和ResourceManager；共享资源；适合规模小执行时间短的作业.适用于本地测试或者开发</p></blockquote><h4 id="mode-one-客户端模式"><a href="#mode-one-客户端模式" class="headerlink" title="mode one: 客户端模式"></a>mode one: 客户端模式</h4><blockquote><p>可以启动多个yarn session，一个yarn session模式对应一个JobManager,并按照需求提交作业，同一个Session中可以提交多个Flink作业。如果想要停止Flink Yarn Application，需要通过yarn application -kill命令来停止.</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/yarn-session.sh -n 2 -jm 1024 -tm 4096 -s 6</span><br></pre></td></tr></table></figure><ul><li><p>YarnSessionClusterEntrypoint进程</p><p>代表本节点可以命令方式提交job，而且可以不用指定-m参数。</p><ul><li><p>本节点提交任务</p><p><code>bin/flink run ~/flink-demo-wordcount.jar</code></p></li><li><p>如果需要在其他主机节点提交任务</p><p><code>bin/flink run -m vmhome10.com:43258 examples/batch/WordCount.jar</code></p></li></ul></li><li><p>FlinkYarnSessionCli进程</p><p>代表yarn-session集群入口，实际就是jobmanager节点，也是yarn的ApplicationMaster节点。</p></li></ul><h4 id="mode-two-分离式模式"><a href="#mode-two-分离式模式" class="headerlink" title="mode two: 分离式模式"></a>mode two: 分离式模式</h4><blockquote><p>JobManager的个数只能是一个，同一个Session中可以提交多个Flink作业。如果想要停止Flink Yarn Application，需要通过yarn application -kill命令来停止。通过-d指定分离模式.</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/yarn-session.sh -nm test3 -d</span><br></pre></td></tr></table></figure><blockquote><p>在所有的节点只会出现一个 YarnSessionClusterEntrypoint进程</p></blockquote><h3 id="second-way-flink-run"><a href="#second-way-flink-run" class="headerlink" title="second way: flink run"></a>second way: flink run</h3><blockquote><p>直接在YARN上提交运行Flink作业(Run a Flink job on YARN)，这种方式的好处是一个任务会对应一个job,即没提交一个作业会根据自身的情况，向yarn申请资源，直到作业执行完成，并不会影响下一个作业的正常运行，除非是yarn上面没有任何资源的情况下。</p><p>ps:适用于生产环境，可启动多个yarn session （bin/yarn-session.sh -nm ipOrHostName）</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run -m addressOfJobmanager -yn 1 -yjm 1024 -ytm 1024 ./examples/batch/WordCount.jar</span><br></pre></td></tr></table></figure><p>注意使用参数-m yarn-cluster提交到yarn集群。</p><ul><li>运行到指定的yarn session可以指定 -yid,–yarnapplicationId <arg> Attach to running YARN session来附加到到特定的yarn session上运行</li></ul><hr><p>reference</p><p><a href="https://www.jianshu.com/p/1b05202c4fb6">Flink on yarn部署模式 - 简书</a></p><p><a href="https://www.cnblogs.com/asker009/p/11327533.html">flink on yarn模式下两种提交job方式 - 我是属车的 - 博客园</a></p><p><a href="https://blog.csdn.net/u013411339/article/details/95421500?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164455981216780357293300%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=164455981216780357293300&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-21-95421500.nonecase&utm_term=%E2%80%9Cflink+cep%E2%80%9D&spm=1018.2226.3001.4450">Flink-On-Yarn的部署模式</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Flink提供了两种在yarn上运行的模式，分别为Session-Cluster和Per-Job-Cluster模式，本文分析两种模式及启动流程。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;interaction&quot;&gt;&lt;a href=&quot;#interaction</summary>
      
    
    
    
    <category term="flink" scheme="http://yoursite.com/categories/flink/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
  <entry>
    <title>hive snippet</title>
    <link href="http://yoursite.com/2022/01/04/hive%20snippet/"/>
    <id>http://yoursite.com/2022/01/04/hive%20snippet/</id>
    <published>2022-01-03T16:10:30.000Z</published>
    <updated>2022-01-03T16:17:06.874Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Hive-site里面的配置！！！</p></blockquote><h3 id="get-started"><a href="#get-started" class="headerlink" title="get started"></a>get started</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup hive --service metastore &amp;</span><br><span class="line">nohup hive --service hiveserver2 &amp;</span><br></pre></td></tr></table></figure><h3 id="beeline"><a href="#beeline" class="headerlink" title="beeline"></a>beeline</h3><p>1）metadata ：hive元数据，即hive定义的表名，字段名，类型，分区，用户这些数据。一般存储关系型书库mysql中，在测试阶段也可以用hive内置Derby数据库。</p><p>（2）metastore ：hivestore服务端。主要提供将DDL，DML等语句转换为MapReduce，提交到hdfs中。</p><p>（3）hiveserver2：hive服务端。提供hive服务。客户端可以通过beeline，jdbc（即用java代码链接）等多种方式链接到hive。</p><p>（4）beeline：hive客户端链接到hive的一个工具。可以理解成mysql的客户端。如：navite cat 等。</p><p><img src="https://img-blog.csdnimg.cn/20191122115956341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NDQwMDQw,size_16,color_FFFFFF,t_70"></p><p>2 连接hive：<br>（1）./bin/hive<br>通过 ./bin/hive 启动的hive服务，第一步会先启动metastore服务，然后在启动一个客户端连接到metastore。此时metastore服务端和客户端都在一台机器上，别的机器无法连接到metastore，所以也无法连接到hive。这种方式不常用，一直只用于调试环节。</p><p>（2） ./bin/hive  –service metastore<br><strong>通过hive –service metastore 会启动一个 hive metastore服务默认的端口号为：9083。metastore服务里面配置metadata相关的配置。此时可以有多个hive客户端在hive-site.xml配置hive.metastore.uris=thrift://ipxxx:9083  的方式链接到hive。motestore 虽然能使hive服务端和客户端分别部署到不同的节点，客户端不需要关注metadata的相关配置。但是metastore只能通过只能通过配置hive.metastore.uris的方式连接，无法通过jdbc的方式访问。</strong></p><p>（3）./bin/hiveserver2<br>hiveserver2 会启动一个hive服务端默认端口为：10000，可以通过beeline，jdbc，odbc的方式链接到hive。<strong>hiveserver2启动的时候会先检查有没有配置hive.metastore.uris，如果没有会先启动一个metastore服务，然后在启动hiveserver2。如果有配置hive.metastore.uris。会连接到远程的metastore服务。这种方式是最常用的。</strong>部署在图如下：</p><ul><li>登录bin/beeline，可以启动客户端链接到hiveserver2。执行beeline后在控制输入 !connect jdbc:hive2://localhost:10000/default root 123 就可以链接到 hiveserver2了；default表示链接到default database， root 和123 分别为密码。注意这里的密码不是mysql的密码，是hive中的用户</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">连接库</span><br><span class="line">!connect jdbc:hive2://localhost:10000/default root 123</span><br></pre></td></tr></table></figure><h1 id="hive中几种分割符"><a href="#hive中几种分割符" class="headerlink" title="hive中几种分割符"></a>hive中几种分割符</h1><p><strong>分隔符</strong></p><p>\n    每行一条记录<br>^A    分隔列（八进制 \001）<br>^B    分隔ARRAY或者STRUCT中的元素，或者MAP中多个键值对之间分隔（八进制 \002）<br>^C    分隔MAP中键值对的“键”和“值”（八进制 \003）</p><p><strong>用到了系统默认分隔符。通常下面2中情况我们需要需要用到分隔符</strong></p><p>1，制作table的输入文件，有时候我们需要输入一些特殊的分隔符</p><p>2，把hive表格导出到本地时，系统默认的分隔符是^A，这个是特殊字符，直接cat或者vim是看不到的</p><p><strong>分隔符在HIVE中的用途</strong></p><table><thead><tr><th>分隔符</th><th>描述</th></tr></thead><tbody><tr><td>\n</td><td>对于文本文件来说，每行都是一条记录，因此换行符可以分隔记录</td></tr><tr><td>^A(Ctrl+A)</td><td>用于分隔字段(列)。在CREATE TABLE语句中可以使用八进制编码\001表示</td></tr><tr><td>^B(Ctrl+B)</td><td>用于分隔ARRAY或者STRUCT中的元素，或用于MAP中键-值对之间的分隔。在CREATE TABLE语句中可以使用八进制编码\002表示</td></tr><tr><td>^C(Ctrl+C)</td><td>用于MAP中键和值之间的分隔。在CREATE TABLE语句中可以使用八进制编码\003表示</td></tr></tbody></table><blockquote><p>Hive 中没有定义专门的数据格式，数据格式可以由用户指定，用户定义数据格式需要指定三个属性：列分隔符（通常为空格、”\t”、”\x001″）、行分隔符（”\n”）以及读取文件数据的方法。由于在加载数据的过程中，不需要从用户数据格式到 Hive 定义的数据格式的转换，因此，Hive 在加载的过程中不会对数据本身进行任何修改，而只是将数据内容复制或者移动到相应的 HDFS 目录中。</p></blockquote><p>我们可以在create表格的时候，选择如下，表格加载input的文件的时候就会按照下面格式匹配</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">row format delimited </span><br><span class="line">fields terminated by &#x27;\001&#x27; </span><br><span class="line">collection items terminated by &#x27;\002&#x27; </span><br><span class="line">map keys terminated by &#x27;\003&#x27;</span><br><span class="line">lines terminated by &#x27;\n&#x27; </span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure><h3 id="如何查看和修改分割符，特殊符号"><a href="#如何查看和修改分割符，特殊符号" class="headerlink" title="如何查看和修改分割符，特殊符号"></a>如何查看和修改分割符，特殊符号</h3><ol><li>查看隐藏字符的方法</li></ol><p>1.1，cat -A filename</p><p><img src="http://image.okcode.net/26FFE1BCC5620E19E94B26122C71BA2E.png" alt="img"></p><p>1.2，vim filename后 命令模式下输入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set list显示特殊符号</span><br><span class="line">set nolist 取消显示特殊符号</span><br></pre></td></tr></table></figure><ol start="2"><li>修改隐藏字符的方法</li></ol><p>首先按照1.2打开显示特殊符号。进入INSERT模式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ctrl + V 可以输入 ^符号</span><br><span class="line">ctrl + a 可以输入A---&#x27;\001&#x27;</span><br><span class="line">ctrl + b 可以输入A---&#x27;\002&#x27;</span><br><span class="line">ctrl + c 可以输入A---&#x27;\003&#x27;</span><br></pre></td></tr></table></figure><p> 注意：虽然键盘上你能找到^和A但直接输入时不行的，必须按照上面的方法输入。</p><p>第一行是特殊符号颜色蓝色，第二行直接输入不是特殊符号。</p><p><img src="http://image.okcode.net/DD9ED976ABB6F4313B8F0F7C2DD5C33E.png" alt="img"></p><p>特殊号直接cat是不可以看见的，但是第二行是可见的，所以不是特殊符号。</p><p><img src="http://image.okcode.net/75D96F800A1815F7A84A8CF543BD7063.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ROW FORMAT DELIMITED </span><br><span class="line">FIELDS TERMINATED BY &#x27;\u0001&#x27; </span><br><span class="line">COLLECTION ITEMS TERMINATED BY &#x27;\u0002&#x27; </span><br><span class="line">MAP KEYS TERMINATED BY &#x27;\u0003&#x27;</span><br><span class="line">\u0001是ASCII编码值，对应java代码中的&quot;\001&quot;</span><br></pre></td></tr></table></figure><p>意义如下：</p><p>（1）FIELDS，字段之间的分隔符是’\u0001’</p><p>（2）COLLECTION ITEMS，多个集合之间的分隔符是’\u0002’，例如（kv1，kv2，kv3）这种多个键值对之间的分隔符就是’\u0002’</p><p>（3）MAP KEYS，单个map的k和v之间的分隔符是\u0003\，例如kv1里，k \u0003 v</p><h3 id="查看orc文件"><a href="#查看orc文件" class="headerlink" title="查看orc文件"></a>查看orc文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive --orcfiledump &lt;hdfs-location-of-orc-file&gt;</span><br></pre></td></tr></table></figure><h3 id="修改字段类型"><a href="#修改字段类型" class="headerlink" title="修改字段类型"></a>修改字段类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="operator">&lt;</span><span class="keyword">table</span><span class="operator">-</span>name<span class="operator">&gt;</span> CHANGE <span class="operator">&lt;</span><span class="keyword">old</span><span class="operator">-</span>col<span class="operator">-</span>name<span class="operator">&gt;</span> <span class="operator">&lt;</span><span class="keyword">new</span><span class="operator">-</span>col<span class="operator">-</span>name<span class="operator">&gt;</span> <span class="operator">&lt;</span>data<span class="operator">-</span>type<span class="operator">&gt;</span>;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employee CHANGE e_id e_id <span class="type">INT</span>;</span><br></pre></td></tr></table></figure><h3 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h3><ul><li><p>Create ORC table</p></li><li><p>Login to the web console</p></li><li><p>Launch Hive by typing <code>hive</code> in the web console. Run the below commands in Hive.</p></li><li><p>Use your database by using the below command. <code>$&#123;env:USER&#125;</code> gets replaced by your username automatically:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use $&#123;env:USER&#125;;</span><br></pre></td></tr></table></figure></li><li><p>To create an ORC file format:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE orc_table (</span><br><span class="line">    first_name STRING, </span><br><span class="line">    last_name STRING</span><br><span class="line"> ) </span><br><span class="line"> STORED AS ORC;</span><br></pre></td></tr></table></figure></li><li><p>To insert values in the table:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO orc_table VALUES (&#x27;John&#x27;,&#x27;Gill&#x27;);</span><br></pre></td></tr></table></figure></li><li><p>To retrieve all the values in the table:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM orc_table;</span><br></pre></td></tr></table></figure></li></ul><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>查看hive进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps -ml  | grep Hive</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Hive-site里面的配置！！！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;get-started&quot;&gt;&lt;a href=&quot;#get-started&quot; class=&quot;headerlink&quot; title=&quot;get started&quot;&gt;&lt;/a&gt;g</summary>
      
    
    
    
    <category term="hive" scheme="http://yoursite.com/categories/hive/"/>
    
    
    <category term="snippet" scheme="http://yoursite.com/tags/snippet/"/>
    
  </entry>
  
  <entry>
    <title>TOP command</title>
    <link href="http://yoursite.com/2022/01/03/top%20command/"/>
    <id>http://yoursite.com/2022/01/03/top%20command/</id>
    <published>2022-01-03T09:18:01.000Z</published>
    <updated>2022-01-03T10:28:12.172Z</updated>
    
    <content type="html"><![CDATA[<h3 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h3><p>us：用户态使用的cpu时间比<br>sy：系统态使用的cpu时间比<br>ni：用做nice加权的进程分配的用户态cpu时间比<br>id：空闲的cpu时间比<br>wa：cpu等待磁盘写入完成时间<br>hi：硬中断消耗时间<br>si：软中断消耗时间<br>st：虚拟机偷取时间</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;cpu&quot;&gt;&lt;a href=&quot;#cpu&quot; class=&quot;headerlink&quot; title=&quot;cpu&quot;&gt;&lt;/a&gt;cpu&lt;/h3&gt;&lt;p&gt;us：用户态使用的cpu时间比&lt;br&gt;sy：系统态使用的cpu时间比&lt;br&gt;ni：用做nice加权的进程分配的用户态cpu时间比&lt;b</summary>
      
    
    
    
    <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
    <category term="command" scheme="http://yoursite.com/tags/command/"/>
    
  </entry>
  
  <entry>
    <title>yarn point</title>
    <link href="http://yoursite.com/2021/12/31/yarn%20snippet/"/>
    <id>http://yoursite.com/2021/12/31/yarn%20snippet/</id>
    <published>2021-12-30T18:01:13.000Z</published>
    <updated>2022-01-03T16:17:18.804Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Yet Another Resource Negotiator</strong></p><p>YARN 看做一个云操作系统，它负责为应用程序启 动 ApplicationMaster（相当于主线程），然后再由 ApplicationMaster 负责数据切分、任务分配、 启动和监控等工作，而由 ApplicationMaster 启动的各个 Task（相当于子线程）仅负责自己的计 算任务。当所有任务计算完成后，ApplicationMaster 认为应用程序运行完成，然后退出。</p><p><img src="/images/yarn/yarn_construct.gif"></p><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><h4 id="contrainer"><a href="#contrainer" class="headerlink" title="contrainer"></a>contrainer</h4><blockquote><p>容器（Container）这个东西是 Yarn 对资源做的一层抽象。就像我们平时开发过程中，经常需要对底层一些东西进行封装，只提供给上层一个调用接口一样，Yarn 对资源的管理也是用到了这种思想。</p></blockquote><p><img src="/images/yarn/contrainer.jpeg"></p><blockquote><p>Yarn 将CPU核数，内存这些计算资源都封装成为一个个的容器（Container）。    </p></blockquote><ul><li>容器由 NodeManager 启动和管理，并被它所监控。</li><li>容器被 ResourceManager 进行调度。</li></ul><h4 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h4><blockquote><p>负责资源管理的，整个系统有且只有一个 RM ，来负责资源的调度。它也包含了两个主要的组件：定时调用器(Scheduler)以及应用管理器(ApplicationManager)。</p></blockquote><ol><li>定时调度器(Scheduler)：从本质上来说，定时调度器就是一种策略，或者说一种算法。当 Client 提交一个任务的时候，它会根据所需要的资源以及当前集群的资源状况进行分配。注意，它只负责向应用程序分配资源，并不做监控以及应用程序的状态跟踪。</li><li>应用管理器(ApplicationManager)：同样，听名字就能大概知道它是干嘛的。应用管理器就是负责管理 Client 用户提交的应用。上面不是说到定时调度器（Scheduler）不对用户提交的程序监控嘛，其实啊，监控应用的工作正是由应用管理器（ApplicationManager）完成的。</li></ol><h4 id="ApplicationMaster"><a href="#ApplicationMaster" class="headerlink" title="ApplicationMaster"></a>ApplicationMaster</h4><blockquote><p>每当 Client 提交一个 Application 时候，就会新建一个 ApplicationMaster 。由这个 ApplicationMaster 去与 ResourceManager 申请容器资源，获得资源后会将要运行的程序发送到容器上启动，然后进行分布式计算。</p><p>ps: 大数据分布式计算的思想，大数据难以移动（海量数据移动成本太大，时间太长），那就把容易移动的应用程序发布到各个节点进行计算。</p></blockquote><h4 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h4><blockquote><p>NodeManager 是 ResourceManager 在每台机器的上代理，负责容器的管理，并监控他们的资源使用情况（cpu，内存，磁盘及网络等），以及向 ResourceManager/Scheduler 提供这些资源使用报告。</p></blockquote><h2 id="submit-application-to-yarn"><a href="#submit-application-to-yarn" class="headerlink" title="submit application to yarn"></a>submit application to yarn</h2><p><img src="/images/yarn/submit_app_flow.jpeg"></p><ol><li>Client 向 Yarn 提交 Application，这里我们假设是一个 MapReduce 作业。</li><li>ResourceManager 向 NodeManager 通信，为该 Application 分配第一个容器。并在这个容器中运行这个应用程序对应的 ApplicationMaster。</li><li>ApplicationMaster 启动以后，对 作业（也就是 Application） 进行拆分，拆分 task 出来，这些 task 可以运行在一个或多个容器中。然后向 ResourceManager 申请要运行程序的容器，并定时向 ResourceManager 发送心跳。</li><li>申请到容器后，ApplicationMaster 会去和容器对应的 NodeManager 通信，而后将作业分发到对应的 NodeManager 中的容器去运行，这里会将拆分后的 MapReduce 进行分发，对应容器中运行的可能是 Map 任务，也可能是 Reduce 任务。</li><li>容器中运行的任务会向 ApplicationMaster 发送心跳，汇报自身情况。当程序运行完成后， ApplicationMaster 再向 ResourceManager 注销并释放容器资源。</li></ol><hr><p>reference:</p><p><a href="https://zhuanlan.zhihu.com/p/54192454">https://zhuanlan.zhihu.com/p/54192454</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Yet Another Resource Negotiator&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;YARN 看做一个云操作系统，它负责为应用程序启 动 ApplicationMaster（相当于主线程），然后再由 ApplicationMaster 负责数据切</summary>
      
    
    
    
    <category term="yarn" scheme="http://yoursite.com/categories/yarn/"/>
    
    
    <category term="point" scheme="http://yoursite.com/tags/point/"/>
    
  </entry>
  
</feed>
