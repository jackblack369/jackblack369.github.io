<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Discipline &amp; Reflect</title>
  
  
  <link href="https://www.willshirley.top/atom.xml" rel="self"/>
  
  <link href="https://www.willshirley.top/"/>
  <updated>2025-06-08T09:31:55.465Z</updated>
  <id>https://www.willshirley.top/</id>
  
  <author>
    <name>brook</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>github snippet</title>
    <link href="https://www.willshirley.top/2025/10/22/github/"/>
    <id>https://www.willshirley.top/2025/10/22/github/</id>
    <published>2025-10-22T03:07:23.000Z</published>
    <updated>2025-06-08T09:31:55.465Z</updated>
    
    <content type="html"><![CDATA[<h1 id="github-cli"><a href="#github-cli" class="headerlink" title="github cli"></a>github cli</h1><p><strong>install</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> centos/rocky</span></span><br><span class="line">sudo dnf install &#x27;dnf-command(config-manager)&#x27;</span><br><span class="line">sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo</span><br><span class="line">sudo dnf install gh --repo gh-cli</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ubuntu</span></span><br><span class="line">sudo apt install gh</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> æˆ– ç›´æ¥ä¸‹è½½äºŒè¿›åˆ¶æ–‡ä»¶è¿›è¡Œå®‰è£…</span></span><br><span class="line">https://github.com/cli/cli/releases</span><br></pre></td></tr></table></figure><p><strong>security</strong></p><ul><li><p>create/check gh_token</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> githubç½‘ç«™è®¾ç½®</span></span><br><span class="line">settings/Developer Settings/Personal access tokens (classic)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>senario</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> senario 1 åœ¨git pushçš„æ—¶å€™ï¼Œè¾“å…¥passwordçš„æ—¶å€™ï¼Œç›´æ¥å¤åˆ¶ä¸Šé¢çš„tokenså³å¯</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> senario 2 åœ¨workflowä¸­ä½¿ç”¨</span></span><br><span class="line">gh secret set SECRET_NAME</span><br><span class="line"><span class="meta">#</span><span class="bash"> or</span></span><br><span class="line">gh secret set SECRET_NAME &lt; secret.txt</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>use</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> login</span></span><br><span class="line">gh auth login</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span></span></span><br><span class="line">gh secret set DOCKERHUB_USERNAME</span><br><span class="line">gh secret set DOCKERHUB_TOKEN </span><br><span class="line">gh secret set GH_TOKEN </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> check</span></span><br><span class="line">gh secret list</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>Scenario</th><th>Secrets available?</th><th>Notes</th></tr></thead><tbody><tr><td>PR from fork triggers workflow (<code>pull_request</code> event)</td><td>No</td><td>Secrets are blocked for security. Causes your login error. (fork ä»“åº“çš„PRæ— æ³•ä¼ è¾“è‡ªå·±ä»“åº“è®¾ç½®çš„secretç»™è¿œç¨‹ä¸»ä»“åº“)</td></tr><tr><td>Workflow runs on push to original repo (after merge)</td><td>Yes</td><td>Full access to secrets, can push to Docker Hub.</td></tr><tr><td>Workflow runs in forked repo itself</td><td>Only forkâ€™s own secrets</td><td>Forkâ€™s secrets are independent, not shared with original repo.</td></tr></tbody></table><h1 id="workflow"><a href="#workflow" class="headerlink" title="workflow"></a>workflow</h1><blockquote><p>GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline.</p></blockquote><ul><li><a href="https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners#supported-runners-and-hardware-resources">runner host</a></li></ul><h2 id="runner-user"><a href="#runner-user" class="headerlink" title="runner user"></a><strong>runner</strong> user</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">username: runner</span><br><span class="line">group: docker adm users systemd-journal</span><br><span class="line">Current directory: /home/runner/work/test-dingofs/test-dingofs</span><br></pre></td></tr></table></figure><h2 id="home"><a href="#home" class="headerlink" title="home"></a>home</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> æƒ…å†µä¸€</span></span><br><span class="line">runs-on: ubuntu-latest</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash">HOME=/home/runner/work/&lt;projectName&gt;/&lt;projectName&gt;</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> æƒ…å†µäºŒ</span></span><br><span class="line">runs-on: ubuntu-latest</span><br><span class="line">container: dingodatabase/dingo-eureka:rocky9</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash">HOME=/__w/&lt;projectName&gt;/&lt;projectName&gt;</span></span><br></pre></td></tr></table></figure><h2 id="disk-usage"><a href="#disk-usage" class="headerlink" title="disk usage"></a>disk usage</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> æƒ…å†µä¸€ï¼š<span class="keyword">in</span> virtual host</span></span><br><span class="line">runs-on: ubuntu-latest</span><br><span class="line"></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/root        72G   47G   26G  65% /</span><br><span class="line">tmpfs           3.9G   84K  3.9G   1% /dev/shm</span><br><span class="line">tmpfs           1.6G  1.1M  1.6G   1% /run</span><br><span class="line">tmpfs           5.0M     0  5.0M   0% /run/lock</span><br><span class="line">/dev/sda16      881M   59M  761M   8% /boot</span><br><span class="line">/dev/sda15      105M  6.1M   99M   6% /boot/efi</span><br><span class="line">tmpfs           794M   12K  794M   1% /run/user/1001</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> æƒ…å†µäºŒï¼šinit container</span> </span><br><span class="line">runs-on: ubuntu-latest</span><br><span class="line">container: dingodatabase/dingo-eureka:rocky9</span><br><span class="line"></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/root        72G   48G   25G  66% /</span><br><span class="line">tmpfs           7.9G   84K  7.9G   1% /dev/shm</span><br><span class="line">tmpfs           3.2G  1.1M  3.2G   1% /run</span><br><span class="line">tmpfs           5.0M     0  5.0M   0% /run/lock</span><br><span class="line">/dev/sda16      881M   60M  760M   8% /boot</span><br><span class="line">/dev/sda15      105M  6.2M   99M   6% /boot/efi</span><br><span class="line">/dev/sdb1        74G  4.1G   66G   6% /mnt  # ğŸš¨ new mount point</span><br><span class="line">tmpfs           1.6G   12K  1.6G   1% /run/user/1001</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># change data root directory</span></span></span><br><span class="line">    - name: Configure Docker data-root</span><br><span class="line">      run: |</span><br><span class="line">        sudo systemctl stop docker</span><br><span class="line">        sudo systemctl stop docker.socket</span><br><span class="line">        sudo mkdir -p /mnt/docker</span><br><span class="line">        echo &#x27;&#123; &quot;data-root&quot;: &quot;/mnt/docker&quot; &#125;&#x27; | sudo tee /etc/docker/daemon.json</span><br><span class="line">        if [ -d /var/lib/docker ]; then</span><br><span class="line">          sudo mv /var/lib/docker /mnt/docker || true</span><br><span class="line">        fi</span><br><span class="line">        sudo systemctl start docker.socket</span><br><span class="line">        sudo systemctl start docker</span><br><span class="line">        docker info | grep &quot;Docker Root Dir&quot;</span><br><span class="line">        echo &quot;check /mnt/docker/&quot;</span><br><span class="line">        sudo ls -la /mnt/docker</span><br></pre></td></tr></table></figure><h2 id="event"><a href="#event" class="headerlink" title="event"></a>event</h2><h2 id="env"><a href="#env" class="headerlink" title="env"></a>env</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GITHUB_OUTPUT</span><br><span class="line">GITHUB_STATE</span><br><span class="line">GITHUB_ENV</span><br></pre></td></tr></table></figure><p><a href="https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/passing-information-between-jobs">Passing information between jobs</a></p><h2 id="action"><a href="#action" class="headerlink" title="action"></a>action</h2><ul><li><strong>docker/metadata-action</strong></li></ul><blockquote><p>åˆ¶ä½œé•œåƒtag</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Docker</span> <span class="string">meta</span></span><br><span class="line">      <span class="attr">if:</span> <span class="string">steps.check-event.outputs.continue</span> <span class="string">==</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">      <span class="attr">id:</span> <span class="string">meta</span></span><br><span class="line">      <span class="attr">uses:</span> <span class="string">docker/metadata-action@v5</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">images:</span> <span class="string">dingodatabase/dingofs</span></span><br><span class="line">        <span class="attr">tags:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          type=raw,enable=$&#123;&#123; env.EVENT == &#x27;tag&#x27; &#125;&#125;,value=$&#123;&#123; env.TAG_NAME &#125;&#125;</span></span><br><span class="line"><span class="string">          type=raw,value=latest,enable=&#123;&#123;is_default_branch&#125;&#125;</span></span><br><span class="line"><span class="string">          type=sha,prefix=,format=long</span></span><br><span class="line"><span class="string"></span><span class="string">ä»¥ä¸Šé…ç½®ä¼šè¿›è¡Œ</span></span><br><span class="line"><span class="number">1</span><span class="string">.å¦‚æœæ˜¯push</span> <span class="string">tag</span> <span class="string">eventï¼Œè¿›è¡Œæ¨é€</span> <span class="string">tag</span> <span class="string">é•œåƒ</span></span><br><span class="line"><span class="number">2</span><span class="string">.ä¸€ç›´ä¼šæ¨é€</span> <span class="string">latest</span> <span class="string">é•œåƒ</span></span><br><span class="line"><span class="number">3</span><span class="string">.ä¸€ç›´ä¼šæ¨é€commitIdé•œåƒ</span></span><br></pre></td></tr></table></figure><p>å¦‚æœä¿®æ”¹å†…å®¹ä¸ºï¼š</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">        <span class="attr">tags:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          type=raw,enable=$&#123;&#123; env.EVENT == &#x27;tag&#x27; &#125;&#125;,value=$&#123;&#123; env.TAG_NAME &#125;&#125;</span></span><br><span class="line"><span class="string">          type=raw,value=latest,enable=$&#123;&#123;github.ref == &#x27;refs/heads/main&#x27; &amp;&amp; env.EVENT != &#x27;tag&#x27;&#125;&#125;</span></span><br><span class="line"><span class="string">          type=sha,prefix=,format=long,enable=$&#123;&#123;env.EVENT != &#x27;tag&#x27;&#125;&#125;</span></span><br><span class="line"><span class="string"></span><span class="string">ä»¥ä¸Šé…ç½®ä¼šè¿›è¡Œ</span></span><br><span class="line"><span class="number">1</span><span class="string">.å¦‚æœæ˜¯</span> <span class="string">push</span> <span class="string">tag</span> <span class="string">eventï¼Œè¿›è¡Œæ¨é€</span> <span class="string">tag</span> <span class="string">é•œåƒ</span></span><br><span class="line"><span class="number">2</span><span class="string">.å¦‚æœæ˜¯mainåˆ†æ”¯ï¼Œå¹¶ä¸”étag</span> <span class="string">eventï¼Œæ‰ä¼šæ¨é€</span> <span class="string">latest</span> <span class="string">é•œåƒ</span></span><br><span class="line"><span class="number">3</span><span class="string">.étag</span> <span class="string">eventæ‰ä¼šæ¨é€commitIdé•œåƒ</span></span><br></pre></td></tr></table></figure><p>é€‚é…mainå’Œå…¶ä»–åˆ†æ”¯</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tags:</span> <span class="string">|</span></span><br><span class="line"><span class="string">  type=raw,enable=$&#123;&#123; env.EVENT == &#x27;tag&#x27; &#125;&#125;,value=$&#123;&#123; env.TAG_NAME &#125;&#125;</span></span><br><span class="line"><span class="string">  type=raw,value=latest,enable=$&#123;&#123; env.BRANCH_NAME == &#x27;main&#x27; &amp;&amp; env.EVENT != &#x27;tag&#x27;&#125;&#125;</span></span><br><span class="line"><span class="string">  type=sha,prefix=,format=short,enable=$&#123;&#123; env.EVENT != &#x27;tag&#x27; &amp;&amp; env.BRANCH_NAME == &#x27;main&#x27; &#125;&#125;</span></span><br><span class="line"><span class="string">  type=sha,prefix=$&#123;&#123; env.BRANCH_NAME &#125;&#125;-,format=short,enable=$&#123;&#123; env.EVENT != &#x27;tag&#x27; &amp;&amp; env.BRANCH_NAME != &#x27;main&#x27; &#125;&#125;</span></span><br></pre></td></tr></table></figure><ul><li><p><strong>softprops/action-gh-release@v2</strong></p><p>é™åˆ¶æœ€å¤§ä¸Šä¼ 2Gæ–‡ä»¶ï¼Œå¦åˆ™ä¼šæŠ¥é”™</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;resource&quot;:&quot;ReleaseAsset&quot;,&quot;code&quot;:&quot;custom&quot;,&quot;field&quot;:&quot;size&quot;,&quot;message&quot;:&quot;size must be less than or equal to 2147483648&quot;&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="best-practices"><a href="#best-practices" class="headerlink" title="best practices"></a>best practices</h1><h2 id="https"><a href="#https" class="headerlink" title="https"></a>https</h2><ul><li>ä½¿ç”¨ https åè®®æ‹‰å–é¡¹ç›®ä»£ç </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git config credential.helper cache</span><br><span class="line">git config credential.helper store</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> global (optional)</span></span><br><span class="line">git config --global credential.helper cache</span><br><span class="line">git config --global credential.helper store</span><br></pre></td></tr></table></figure><h2 id="ISSUES"><a href="#ISSUES" class="headerlink" title="ISSUES"></a>ISSUES</h2><ul><li>search</li></ul><p><code>searchKeyWord is:issue is:closed repo:Alamofire/Alamofire</code>Â </p><p>è¿™æ¡æœç´¢ï¼ŒsearchKeyWordæ˜¯æœç´¢å…³é”®å­—,Â <code>is:issue</code>Â è¡¨ç¤ºæˆ‘ä»¬è¦æœç´¢ issueï¼ŒÂ <code>is:closed</code>Â è¡¨ç¤ºå·²ç»å…³é—­çš„ issueï¼ŒÂ <code>repo:Alamofire/Alamofire</code>Â è¡¨ç¤ºæˆ‘ä»¬åªæœç´¢è¿™ä¸ªä»“åº“èŒƒå›´çš„ issue</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;github-cli&quot;&gt;&lt;a href=&quot;#github-cli&quot; class=&quot;headerlink&quot; title=&quot;github cli&quot;&gt;&lt;/a&gt;github cli&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;install&lt;/strong&gt;&lt;/p&gt;
&lt;figure c</summary>
      
    
    
    
    <category term="github" scheme="https://www.willshirley.top/categories/github/"/>
    
    
    <category term="ci" scheme="https://www.willshirley.top/tags/ci/"/>
    
  </entry>
  
  <entry>
    <title>cmake learn</title>
    <link href="https://www.willshirley.top/2025/06/17/cmake%20learn/"/>
    <id>https://www.willshirley.top/2025/06/17/cmake%20learn/</id>
    <published>2025-06-17T07:09:24.000Z</published>
    <updated>2025-06-18T11:23:26.075Z</updated>
    
    <content type="html"><![CDATA[<h1 id="default"><a href="#default" class="headerlink" title="default"></a>default</h1><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CMAKE_CURRENT_SOURCE_DIR</span><br><span class="line">PROJECT_SOURCE_DIR</span><br></pre></td></tr></table></figure><p>**CMAKE_CURRENT_SOURCE_DIR **</p><p>The path to the source directory currently being processed.</p><p>This is the full path to the source directory that is currently being processed by cmake.</p><p><strong>PROJECT_SOURCE_DIR</strong></p><p>This is the source directory of the last call to the project() command made in the current directory scope or one of its parents. Note, it is not affected by calls to project() made within a child directory scope (i.e. from within a call to add_subdirectory()  from the current scope).</p><ul><li>When run in <a href="https://cmake.org/cmake/help/v3.31/manual/cmake.1.html#cmdoption-cmake-P"><code>cmake -P</code></a> script mode, CMake sets the variables <code>CMAKE_BINARY_DIR</code>, <code>CMAKE_SOURCE_DIR</code>, <code>CMAKE_CURRENT_BINARY_DIR</code> and <code>CMAKE_CURRENT_SOURCE_DIR</code> to the current working directory.</li></ul><h1 id="scope"><a href="#scope" class="headerlink" title="scope"></a>scope</h1><p><strong><code>PUBLIC</code></strong></p><p>Populates both properties for <a href="https://cmake.org/cmake/help/v3.31/manual/cmake-buildsystem.7.html#target-build-specification">building</a> and properties for <a href="https://cmake.org/cmake/help/v3.31/manual/cmake-buildsystem.7.html#target-usage-requirements">using</a> a target.</p><p><strong><code>PRIVATE</code></strong></p><p>Populates only properties for <a href="https://cmake.org/cmake/help/v3.31/manual/cmake-buildsystem.7.html#target-build-specification">building</a> a target.</p><p><strong><code>INTERFACE</code></strong></p><p>Populates only properties for <a href="https://cmake.org/cmake/help/v3.31/manual/cmake-buildsystem.7.html#target-usage-requirements">using</a> a target.</p><ul><li>Remember <code>INTERFACE</code> means things that consumers require but the producer doesnâ€™t.</li></ul><h1 id="syntax"><a href="#syntax" class="headerlink" title="syntax"></a>syntax</h1><h2 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_executable</span>()</span><br><span class="line"><span class="keyword">cmake_minimum_required</span>()</span><br><span class="line"><span class="keyword">project</span>()</span><br></pre></td></tr></table></figure><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.10</span>)</span><br><span class="line"><span class="keyword">project</span>(Tutorial VERSION <span class="number">2.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the variable</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">11</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tells CMake to create an executable using the specified source code files</span></span><br><span class="line"><span class="keyword">add_executable</span>(Tutorial tutorial.cxx)</span><br></pre></td></tr></table></figure><h3 id="configure-file"><a href="#configure-file" class="headerlink" title="configure_file"></a>configure_file</h3><blockquote><p>copy the input file with the specified CMake variables replaced</p></blockquote><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copies an &lt;input&gt; file to an &lt;output&gt; file </span></span><br><span class="line"><span class="keyword">configure_file</span>(&lt;input&gt; &lt;output&gt;)</span><br></pre></td></tr></table></figure><h3 id="target-include-directories"><a href="#target-include-directories" class="headerlink" title="target_include_directories"></a>target_include_directories</h3><blockquote><p>specify where the executable target should look for include files</p></blockquote><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">target_include_directories</span>(Tutorial PUBLIC <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="Adding-a-Library"><a href="#Adding-a-Library" class="headerlink" title="Adding a Library"></a>Adding a Library</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_library</span>()</span><br><span class="line"><span class="keyword">add_subdirectory</span>()</span><br><span class="line"><span class="keyword">target_include_directories</span>()</span><br><span class="line"><span class="keyword">target_link_libraries</span>()</span><br></pre></td></tr></table></figure><h3 id="add-library"><a href="#add-library" class="headerlink" title="add_library"></a>add_library</h3><blockquote><p>Add a library target called <code>&lt;name&gt;</code> to be built from the source files listed in the command invocation</p></blockquote><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_library</span>(MathFunctions MathFunctions.cxx mysqrt.cxx)</span><br></pre></td></tr></table></figure><h3 id="add-subdirectory"><a href="#add-subdirectory" class="headerlink" title="add_subdirectory"></a>add_subdirectory</h3><blockquote><p>make use of the new library call</p></blockquote><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_subdirectory</span>(MathFunctions)</span><br></pre></td></tr></table></figure><h2 id="Adding-Usage-Requirements-for-a-Library"><a href="#Adding-Usage-Requirements-for-a-Library" class="headerlink" title="Adding Usage Requirements for a Library"></a>Adding Usage Requirements for a Library</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">target_compile_definitions</span>()</span><br><span class="line"><span class="keyword">target_compile_options</span>()</span><br><span class="line"><span class="keyword">target_include_directories</span>()</span><br><span class="line"><span class="keyword">target_link_directories</span>()</span><br><span class="line"><span class="keyword">target_link_options</span>()</span><br><span class="line">target_precompile_headers()</span><br><span class="line"><span class="keyword">target_sources</span>()</span><br><span class="line"><span class="keyword">add_library</span>()</span><br><span class="line"><span class="keyword">target_compile_features</span>()</span><br><span class="line"><span class="keyword">target_link_libraries</span>()</span><br></pre></td></tr></table></figure><h2 id="Adding-Generator-Expressions"><a href="#Adding-Generator-Expressions" class="headerlink" title="Adding Generator Expressions"></a>Adding Generator Expressions</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cmake-generator-expressions(<span class="number">7</span>)</span><br><span class="line"><span class="keyword">cmake_minimum_required</span>()</span><br><span class="line"><span class="keyword">set</span>()</span><br><span class="line"><span class="keyword">target_compile_options</span>()</span><br></pre></td></tr></table></figure><h2 id="Installing-and-Testing"><a href="#Installing-and-Testing" class="headerlink" title="Installing and Testing"></a>Installing and Testing</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">install</span>()</span><br></pre></td></tr></table></figure><h2 id="Adding-System-Introspection"><a href="#Adding-System-Introspection" class="headerlink" title="Adding System Introspection"></a>Adding System Introspection</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Packaging-an-Installer"><a href="#Packaging-an-Installer" class="headerlink" title="Packaging an Installer"></a>Packaging an Installer</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cpack</span><br></pre></td></tr></table></figure><h2 id="Selecting-Static-or-Shared-Libraries"><a href="#Selecting-Static-or-Shared-Libraries" class="headerlink" title="Selecting Static or Shared Libraries"></a>Selecting Static or Shared Libraries</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">option</span>(BUILD_SHARED_LIBS <span class="string">&quot;Build using shared libraries&quot;</span> <span class="keyword">ON</span>)</span><br></pre></td></tr></table></figure><h2 id="Adding-Export-Configuration"><a href="#Adding-Export-Configuration" class="headerlink" title="Adding Export Configuration"></a>Adding Export Configuration</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;default&quot;&gt;&lt;a href=&quot;#default&quot; class=&quot;headerlink&quot; title=&quot;default&quot;&gt;&lt;/a&gt;default&lt;/h1&gt;&lt;figure class=&quot;highlight cmake&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=</summary>
      
    
    
    
    <category term="cmake" scheme="https://www.willshirley.top/categories/cmake/"/>
    
    
    <category term="tool" scheme="https://www.willshirley.top/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>c++ tools</title>
    <link href="https://www.willshirley.top/2025/06/06/c++%20summary/"/>
    <id>https://www.willshirley.top/2025/06/06/c++%20summary/</id>
    <published>2025-06-06T03:14:58.000Z</published>
    <updated>2025-06-19T02:28:54.485Z</updated>
    
    <content type="html"><![CDATA[<h1 id="å‡½æ•°"><a href="#å‡½æ•°" class="headerlink" title="å‡½æ•°"></a>å‡½æ•°</h1><p>C++ é‡Œç±»çš„å››å¤§å‡½æ•°ï¼šæ„é€ å‡½æ•°ã€ææ„å‡½æ•°ã€æ‹·è´æ„é€ å‡½æ•°ã€æ‹·è´èµ‹å€¼å‡½æ•°ã€‚C++11 å› ä¸ºå¼•å…¥äº†å³å€¼ï¼ˆRvalueï¼‰å’Œè½¬ç§»ï¼ˆMoveï¼‰ï¼Œåˆå¤šå‡ºäº†ä¸¤å¤§å‡½æ•°ï¼šè½¬ç§»æ„é€ å‡½æ•°å’Œè½¬ç§»èµ‹å€¼å‡½æ•°ã€‚</p><p>æ‰€ä»¥ï¼Œåœ¨ç°ä»£ C++ é‡Œï¼Œä¸€ä¸ªç±»æ€»æ˜¯ä¼šæœ‰å…­å¤§åŸºæœ¬å‡½æ•°ï¼šä¸‰ä¸ªæ„é€ ã€ä¸¤ä¸ªèµ‹å€¼ã€ä¸€ä¸ªææ„ã€‚</p><ul><li>åœ¨ C/C++ é‡Œï¼Œæ‰€æœ‰çš„å‡½æ•°éƒ½æ˜¯å…¨å±€çš„ï¼Œæ²¡æœ‰ç”Ÿå­˜å‘¨æœŸçš„æ¦‚å¿µï¼ˆstaticã€åå­—ç©ºé—´çš„ä½œç”¨å¾ˆå¼±ï¼Œåªæ˜¯ç®€å•é™åˆ¶äº†åº”ç”¨èŒƒå›´ï¼Œé¿å…åå­—å†²çªï¼‰ã€‚è€Œä¸”å‡½æ•°ä¹Ÿéƒ½æ˜¯å¹³çº§çš„ï¼Œä¸èƒ½åœ¨å‡½æ•°é‡Œå†å®šä¹‰å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯ä¸å…è®¸å®šä¹‰åµŒå¥—å‡½æ•°ã€å‡½æ•°å¥—å‡½æ•°ã€‚</li></ul><h2 id="æ„é€ å‡½æ•°"><a href="#æ„é€ å‡½æ•°" class="headerlink" title="æ„é€ å‡½æ•°"></a>æ„é€ å‡½æ•°</h2><h3 id="skill"><a href="#skill" class="headerlink" title="skill"></a>skill</h3><h4 id="â€œå§”æ‰˜æ„é€ â€ï¼ˆdelegating-constructorï¼‰"><a href="#â€œå§”æ‰˜æ„é€ â€ï¼ˆdelegating-constructorï¼‰" class="headerlink" title="â€œå§”æ‰˜æ„é€ â€ï¼ˆdelegating constructorï¼‰"></a>â€œå§”æ‰˜æ„é€ â€ï¼ˆdelegating constructorï¼‰</h4><blockquote><p>ä½¿ç”¨â€œå§”æ‰˜æ„é€ â€çš„æ–°ç‰¹æ€§ï¼Œä¸€ä¸ªæ„é€ å‡½æ•°ç›´æ¥è°ƒç”¨å¦ä¸€ä¸ªæ„é€ å‡½æ•°ï¼ŒæŠŠæ„é€ å·¥ä½œâ€œå§”æ‰˜â€å‡ºå»ï¼Œæ—¢ç®€å•åˆé«˜æ•ˆã€‚</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoDelegating</span> <span class="keyword">final</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> a; <span class="comment">// æˆå‘˜å˜é‡</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">DemoDelegating</span>(<span class="keyword">int</span> x) : <span class="built_in">a</span>(x) <span class="comment">// åŸºæœ¬çš„æ„é€ å‡½æ•°</span></span><br><span class="line">    &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">DemoDelegating</span>() : <span class="comment">// æ— å‚æ•°çš„æ„é€ å‡½æ•°</span></span><br><span class="line">        <span class="built_in">DemoDelegating</span>(<span class="number">0</span>) <span class="comment">// ç»™å‡ºé»˜è®¤å€¼ï¼Œå§”æ‰˜ç»™ç¬¬ä¸€ä¸ªæ„é€ å‡½æ•°</span></span><br><span class="line">    &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">DemoDelegating</span>(<span class="keyword">const</span> string&amp; s) : <span class="comment">// å­—ç¬¦ä¸²å‚æ•°æ„é€ å‡½æ•°</span></span><br><span class="line">        <span class="built_in">DemoDelegating</span>(<span class="built_in">stoi</span>(s)) <span class="comment">// è½¬æ¢æˆæ•´æ•°ï¼Œå†å§”æ‰˜ç»™ç¬¬ä¸€ä¸ªæ„é€ å‡½æ•°</span></span><br><span class="line">    &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="â€œæˆå‘˜å˜é‡åˆå§‹åŒ–â€ï¼ˆIn-class-member-initializerï¼‰"><a href="#â€œæˆå‘˜å˜é‡åˆå§‹åŒ–â€ï¼ˆIn-class-member-initializerï¼‰" class="headerlink" title="â€œæˆå‘˜å˜é‡åˆå§‹åŒ–â€ï¼ˆIn-class member initializerï¼‰"></a>â€œæˆå‘˜å˜é‡åˆå§‹åŒ–â€ï¼ˆIn-class member initializerï¼‰</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DemoInit</span> <span class="keyword">final</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span>                 a = <span class="number">0</span>;</span><br><span class="line">    std::string         s = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt;    v&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">DemoInit</span>() = <span class="keyword">default</span>;</span><br><span class="line">   ~<span class="built_in">DemoInit</span>() = <span class="keyword">default</span>;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">DemoInit</span>(<span class="keyword">int</span> x) : <span class="built_in">a</span>(x) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="â€œç±»å‹åˆ«åâ€ï¼ˆType-Aliasï¼‰"><a href="#â€œç±»å‹åˆ«åâ€ï¼ˆType-Aliasï¼‰" class="headerlink" title="â€œç±»å‹åˆ«åâ€ï¼ˆType Aliasï¼‰"></a>â€œç±»å‹åˆ«åâ€ï¼ˆType Aliasï¼‰</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">uint_t</span> = <span class="keyword">unsigned</span> <span class="keyword">int</span>; <span class="comment">// usingåˆ«å</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="keyword">uint_t</span>ï¼› <span class="comment">// ç­‰ä»·çš„typedef</span></span><br></pre></td></tr></table></figure><h2 id="lambda"><a href="#lambda" class="headerlink" title="lambda"></a>lambda</h2><blockquote><p>C++ æ²¡æœ‰ä¸º lambda è¡¨è¾¾å¼å¼•å…¥æ–°çš„å…³é”®å­—ï¼Œå¹¶æ²¡æœ‰â€œlambdaâ€è¿™æ ·çš„è¯æ±‡ï¼Œè€Œæ˜¯ç”¨äº†ä¸€ä¸ªç‰¹æ®Šçš„å½¢å¼â€œ[]â€ï¼Œæœ¯è¯­å«â€œlambda å¼•å‡ºç¬¦â€ï¼ˆlambda introducerï¼‰ã€‚</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> lambda è¡¨è¾¾å¼ç¤ºä¾‹</span></span><br><span class="line">auto f1 = [](&lt;å…¥å£å‚æ•°&gt;)&#123;å‡½æ•°ä½“&#125;; </span><br></pre></td></tr></table></figure><ul><li>lambdaè¡¨è¾¾å¼èµ‹å€¼å¿…é¡»ç”¨autoï¼ˆä½†autoä¸èƒ½ç”¨åœ¨ç±»æˆå‘˜åˆå§‹åŒ–ï¼‰</li><li>lambda è¡¨è¾¾å¼æ˜¯ä¸€ä¸ªé—­åŒ…ï¼Œèƒ½å¤Ÿåƒå‡½æ•°ä¸€æ ·è¢«è°ƒç”¨ï¼Œåƒå˜é‡ä¸€æ ·è¢«ä¼ é€’</li><li>æ•è·å¼•ç”¨æ—¶å¿…é¡»è¦æ³¨æ„å¤–éƒ¨å˜é‡çš„ç”Ÿå‘½å‘¨æœŸï¼Œé˜²æ­¢å˜é‡å¤±æ•ˆ</li></ul><p><strong>å˜é‡æ•è·</strong></p><ul><li><code>[=]</code>è¡¨ç¤ºæŒ‰å€¼æ•è·æ‰€æœ‰å¤–éƒ¨å˜é‡ï¼Œè¡¨è¾¾å¼å†…éƒ¨æ˜¯å€¼çš„æ‹·è´ï¼Œå¹¶ä¸”ä¸èƒ½ä¿®æ”¹</li><li><code>[&amp;]</code>æ˜¯æŒ‰å¼•ç”¨æ•è·æ‰€æœ‰å¤–éƒ¨å˜é‡ï¼Œå†…éƒ¨ä»¥å¼•ç”¨çš„æ–¹å¼ä½¿ç”¨ï¼Œå¯ä»¥ä¿®æ”¹</li></ul><h1 id="æ™ºèƒ½æŒ‡é’ˆ"><a href="#æ™ºèƒ½æŒ‡é’ˆ" class="headerlink" title="æ™ºèƒ½æŒ‡é’ˆ"></a>æ™ºèƒ½æŒ‡é’ˆ</h1><blockquote><p>å°½é‡ä¸è¦å†ä½¿ç”¨è£¸æŒ‡é’ˆã€new å’Œ delete æ¥æ“ä½œå†…å­˜</p></blockquote><h2 id="unique-ptr"><a href="#unique-ptr" class="headerlink" title="unique_ptr"></a>unique_ptr</h2><ul><li>å°½é‡ä¸è¦å¯¹ unique_ptr æ‰§è¡Œèµ‹å€¼æ“ä½œå°±å¥½äº†ï¼Œè®©å®ƒâ€œè‡ªç”Ÿè‡ªç­â€ï¼Œå®Œå…¨è‡ªåŠ¨åŒ–ç®¡ç†ã€‚</li></ul><h2 id="shared-ptr"><a href="#shared-ptr" class="headerlink" title="shared_ptr"></a>shared_ptr</h2><ul><li>shared_ptr æ”¯æŒå®‰å…¨å…±äº«çš„ç§˜å¯†åœ¨äºå†…éƒ¨ä½¿ç”¨äº†â€œå¼•ç”¨è®¡æ•°â€</li><li>å› ä¸º shared_ptr å…·æœ‰å®Œæ•´çš„â€œå€¼è¯­ä¹‰â€ï¼ˆå³å¯ä»¥æ‹·è´èµ‹å€¼ï¼‰ï¼Œæ‰€ä»¥ï¼Œå®ƒå¯ä»¥åœ¨ä»»ä½•åœºåˆæ›¿ä»£åŸå§‹æŒ‡é’ˆï¼Œè€Œä¸ç”¨å†æ‹…å¿ƒèµ„æºå›æ”¶çš„é—®é¢˜ï¼Œæ¯”å¦‚ç”¨äºå®¹å™¨å­˜å‚¨æŒ‡é’ˆã€ç”¨äºå‡½æ•°å®‰å…¨è¿”å›åŠ¨æ€åˆ›å»ºçš„å¯¹è±¡ï¼Œç­‰ç­‰</li></ul><h1 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h1><ul><li><p>C++ é‡Œä¹Ÿæ˜¯æœ‰åƒåœ¾å›æ”¶çš„ï¼Œä¸è¿‡ä¸æ˜¯ Javaã€Go é‚£ç§ä¸¥æ ¼æ„ä¹‰ä¸Šçš„åƒåœ¾å›æ”¶ï¼Œè€Œæ˜¯å¹¿ä¹‰ä¸Šçš„åƒåœ¾å›æ”¶ï¼Œè¿™å°±æ˜¯æ„é€  / ææ„å‡½æ•°å’Œ <code>RAII</code> æƒ¯ç”¨æ³•ï¼ˆResource Acquisition Is Initializationï¼‰</p></li><li><p><code>noexcept</code> ä¸“é—¨ç”¨æ¥ä¿®é¥°å‡½æ•°ï¼Œå‘Šè¯‰ç¼–è¯‘å™¨ï¼šè¿™ä¸ªå‡½æ•°ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ã€‚ç¼–è¯‘å™¨çœ‹åˆ°<code>noexcept</code>ï¼Œå°±å¾—åˆ°äº†ä¸€ä¸ªâ€œä¿è¯â€ï¼Œå°±å¯ä»¥å¯¹å‡½æ•°åšä¼˜åŒ–ï¼Œä¸å»åŠ é‚£äº›æ ˆå±•å¼€çš„é¢å¤–ä»£ç ï¼Œæ¶ˆé™¤å¼‚å¸¸å¤„ç†çš„æˆæœ¬ã€‚</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;å‡½æ•°&quot;&gt;&lt;a href=&quot;#å‡½æ•°&quot; class=&quot;headerlink&quot; title=&quot;å‡½æ•°&quot;&gt;&lt;/a&gt;å‡½æ•°&lt;/h1&gt;&lt;p&gt;C++ é‡Œç±»çš„å››å¤§å‡½æ•°ï¼šæ„é€ å‡½æ•°ã€ææ„å‡½æ•°ã€æ‹·è´æ„é€ å‡½æ•°ã€æ‹·è´èµ‹å€¼å‡½æ•°ã€‚C++11 å› ä¸ºå¼•å…¥äº†å³å€¼ï¼ˆRvalueï¼‰å’Œè½¬ç§»ï¼ˆMoveï¼‰ï¼Œåˆå¤šå‡º</summary>
      
    
    
    
    <category term="c++" scheme="https://www.willshirley.top/categories/c/"/>
    
    
    <category term="tools" scheme="https://www.willshirley.top/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>c++ tools</title>
    <link href="https://www.willshirley.top/2025/06/06/c++%20tools/"/>
    <id>https://www.willshirley.top/2025/06/06/c++%20tools/</id>
    <published>2025-06-06T02:46:06.000Z</published>
    <updated>2025-06-06T02:46:15.552Z</updated>
    
    <content type="html"><![CDATA[<h1 id="daignose-debug"><a href="#daignose-debug" class="headerlink" title="daignose/debug"></a>daignose/debug</h1><h2 id="GDB"><a href="#GDB" class="headerlink" title="GDB"></a>GDB</h2><h2 id="Valgrind"><a href="#Valgrind" class="headerlink" title="Valgrind"></a>Valgrind</h2><h2 id="Systemtap"><a href="#Systemtap" class="headerlink" title="Systemtap"></a>Systemtap</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;daignose-debug&quot;&gt;&lt;a href=&quot;#daignose-debug&quot; class=&quot;headerlink&quot; title=&quot;daignose/debug&quot;&gt;&lt;/a&gt;daignose/debug&lt;/h1&gt;&lt;h2 id=&quot;GDB&quot;&gt;&lt;a href=&quot;#GD</summary>
      
    
    
    
    <category term="c++" scheme="https://www.willshirley.top/categories/c/"/>
    
    
    <category term="tools" scheme="https://www.willshirley.top/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>etcd snippet</title>
    <link href="https://www.willshirley.top/2025/04/24/etcd/"/>
    <id>https://www.willshirley.top/2025/04/24/etcd/</id>
    <published>2025-04-24T11:26:30.000Z</published>
    <updated>2025-05-07T02:13:27.958Z</updated>
    
    <content type="html"><![CDATA[<h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 etcdctl --endpoints=http://127.0.0.1:2379 endpoint health</span><br><span class="line">ETCDCTL_API=3 /dingofs/etcd/sbin/etcdctl   --endpoints=http://127.0.0.1:2379   member list</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;command&quot;&gt;&lt;a href=&quot;#command&quot; class=&quot;headerlink&quot; title=&quot;command&quot;&gt;&lt;/a&gt;command&lt;/h1&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=</summary>
      
    
    
    
    <category term="etcd" scheme="https://www.willshirley.top/categories/etcd/"/>
    
    
    <category term="snippet" scheme="https://www.willshirley.top/tags/snippet/"/>
    
  </entry>
  
  <entry>
    <title>containerd</title>
    <link href="https://www.willshirley.top/2025/03/28/containerd/"/>
    <id>https://www.willshirley.top/2025/03/28/containerd/</id>
    <published>2025-03-28T06:10:57.000Z</published>
    <updated>2025-06-04T12:36:48.204Z</updated>
    
    <content type="html"><![CDATA[<h2 id="best-practise"><a href="#best-practise" class="headerlink" title="best practise"></a>best practise</h2><p><strong>change containerdâ€™s default data path</strong></p><ol><li><p>Identify the Current Data Path</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">containerd config default | grep &quot;root&quot; # Expected output: root = &quot;/var/lib/containerd&quot;</span><br></pre></td></tr></table></figure></li><li><p>Modify the following lines in /etc/containerd/config.toml:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root = &quot;/path/to/new/data/path&quot; # the location where container data (images, volumes) is stored</span><br></pre></td></tr></table></figure></li><li><p>Move Existing Data (if required)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop containerd  # optional</span><br><span class="line">sudo mv /var/lib/containerd /data/containerd</span><br><span class="line">sudo systemctl start containerd</span><br></pre></td></tr></table></figure></li></ol><h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><h2 id="image"><a href="#image" class="headerlink" title="image"></a>image</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> list k8s image</span></span><br><span class="line">sudo ctr -n k8s.io images ls</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> pull k8s image</span></span><br><span class="line">sudo ctr -n k8s.io images pull xxx</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> load tar file</span> </span><br><span class="line">sudo ctr -n k8s.io images import /tmp/my-image.tar</span><br><span class="line"><span class="meta">#</span><span class="bash"> combine load tar file to specify tag image</span></span><br><span class="line">sudo ctr -n k8s.io images import --base-name my.registry.com/myproject/my-image:v1.2.3 /path/to/image.tar</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> rename tag</span></span><br><span class="line">sudo ctr -n k8s.io images tag &lt;old-image-name&gt; &lt;new-image-name&gt;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> remove image</span></span><br><span class="line">sudo ctr -n k8s.io images remove &lt;name&gt;:&lt;tag&gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;best-practise&quot;&gt;&lt;a href=&quot;#best-practise&quot; class=&quot;headerlink&quot; title=&quot;best practise&quot;&gt;&lt;/a&gt;best practise&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;change containerdâ€™</summary>
      
    
    
    
    <category term="containerd" scheme="https://www.willshirley.top/categories/containerd/"/>
    
    
    <category term="container" scheme="https://www.willshirley.top/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>ceph fs</title>
    <link href="https://www.willshirley.top/2025/03/26/ceph%20FS/"/>
    <id>https://www.willshirley.top/2025/03/26/ceph%20FS/</id>
    <published>2025-03-26T08:45:16.000Z</published>
    <updated>2025-03-26T09:53:14.154Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h1><p>Before mounting CephFS, ensure that</p><ol><li>the client host (where CephFS has to be mounted and used) has a copy of the Ceph configuration file (i.e. ceph.conf)</li><li>a keyring of the CephX user that has permission to access the MDS.<br>both of these files must already be present on the host where the Ceph MON resides.</li></ol><ul><li><p>Generate a minimal conf file for the client host and place it at a standard location:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> on client host</span></span><br><span class="line">mkdir -p -m 755 /etc/ceph</span><br><span class="line">ssh &#123;user&#125;@&#123;mon-host&#125; &quot;sudo ceph config generate-minimal-conf&quot; | sudo tee /etc/ceph/ceph.conf</span><br><span class="line">chmod 644 /etc/ceph/ceph.conf</span><br></pre></td></tr></table></figure></li><li><p>Create a CephX user and get its secret key:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh &#123;user&#125;@&#123;mon-host&#125; &quot;sudo ceph fs authorize cephfs-1 client.dongwei / rw&quot; | sudo tee /etc/ceph/ceph.client.dongwei.keyring</span><br></pre></td></tr></table></figure><blockquote><p>In above command, replace cephfs with the name of your CephFS, foo by the name you want for your CephX user and / by the path within your CephFS for which you want to allow access to the client host and rw stands for both read and write permissions.</p></blockquote></li><li><p>Ensure that the keyring has appropriate permissions:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 600 /etc/ceph/ceph.client.dongwei.keyring</span><br></pre></td></tr></table></figure></li></ul><h1 id="Create-Pool-FS"><a href="#Create-Pool-FS" class="headerlink" title="Create Pool/FS"></a>Create Pool/FS</h1><ul><li><p>Creating pools</p><blockquote><p>A Ceph file system requires at least two RADOS pools, one for data and one for metadata.</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create cephfs_data</span><br><span class="line">ceph osd pool create cephfs_metadata</span><br></pre></td></tr></table></figure></li><li><p>Creating the file system</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph fs new cephfs-1 cephfs_metadata cephfs_data</span><br></pre></td></tr></table></figure></li><li><p>Check the status of the file system</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph fs status</span><br></pre></td></tr></table></figure></li><li><p>check mds status</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph mds stat</span><br></pre></td></tr></table></figure></li><li><p>Using Erasure Coded pools with CephFSï¼ˆoptionalï¼‰</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool set my_ec_pool allow_ec_overwrites true</span><br></pre></td></tr></table></figure></li></ul><h1 id="Mount-CephFS-using-Kernel-Driver"><a href="#Mount-CephFS-using-Kernel-Driver" class="headerlink" title="Mount CephFS using Kernel Driver"></a>Mount CephFS using Kernel Driver</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> mount -t ceph &#123;device-string&#125;=&#123;path-to-mounted&#125; &#123;mount-point&#125; -o &#123;key-value-args&#125; &#123;other-args&#125;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> mount -t ceph &lt;name&gt;@&lt;fsid&gt;.&lt;fs_name&gt;=/ /mnt/mycephfs</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> fsid is the FSID of the Ceph cluster, <span class="built_in">which</span> can be found using the `ceph fsid` <span class="built_in">command</span>.</span></span><br><span class="line"></span><br><span class="line">mkdir /mnt/mycephfs</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> not use mount.helper</span></span><br><span class="line">mount -t ceph dongwei@b3acfc0d-575f-41d3-9c91-0e7ed3dbb3fa.cephfs-1=/ -o mon_addr=192.168.0.1:6789,secret=AQATSKdNGBnwLhAAnNDKnH65FmVKpXZJVasUeQ==</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> use mount.helper</span></span><br><span class="line">mount -t ceph dongwei@.cephfs-1=/ /mnt/cephfs -o secret=AQATSKdNGBnwLhAAnNDKnH65FmVKpXZJVasUeQ==</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> use secret file and Multiple monitor hosts</span></span><br><span class="line">mount -t ceph cephuser@.cephfs=/ /mnt/mycephfs -o</span><br><span class="line">mon_addr=192.168.0.1:6789/192.168.0.2:6789,secretfile=/etc/ceph/cephuser.secret</span><br></pre></td></tr></table></figure><ul><li><p>check</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dongwei@6a65c746-e532-11ef-8ac2-fa7c097efb00.cephfs-1=/  190G     0  190G   0% /mnt/cephfs</span><br></pre></td></tr></table></figure></li></ul><h1 id="Mount-CephFS-using-FUSE"><a href="#Mount-CephFS-using-FUSE" class="headerlink" title="Mount CephFS using FUSE"></a>Mount CephFS using FUSE</h1><ul><li><p>install ceph-fuse</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Install the Ceph release RPM (adjust <span class="string">&#x27;reef&#x27;</span> as needed)</span></span><br><span class="line">sudo rpm -Uvh https://download.ceph.com/rpm-reef/el9/noarch/ceph-release-1-1.el9.noarch.rpm</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Import the Ceph GPG key</span></span><br><span class="line">sudo rpm --import &#x27;https://download.ceph.com/keys/release.asc&#x27;</span><br><span class="line"></span><br><span class="line">sudo dnf install -y ceph-fuse</span><br></pre></td></tr></table></figure></li><li><p>mount</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ceph-fuse &#123;mount point&#125; &#123;options&#125;</span></span><br><span class="line">mkdir /mnt/mycephfs</span><br><span class="line">ceph-fuse --id dongwei /mnt/mycephfs  # mount default fs</span><br><span class="line"></span><br><span class="line">ceph-fuse --id dongwei --client_fs cephfs-1 /mnt/mycephfs # mount specify fs</span><br></pre></td></tr></table></figure></li><li><p>check</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-fuse190G     0  190G   0% /mnt/cephfs2</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Prerequisites&quot;&gt;&lt;a href=&quot;#Prerequisites&quot; class=&quot;headerlink&quot; title=&quot;Prerequisites&quot;&gt;&lt;/a&gt;Prerequisites&lt;/h1&gt;&lt;p&gt;Before mounting CephFS, en</summary>
      
    
    
    
    <category term="ceph" scheme="https://www.willshirley.top/categories/ceph/"/>
    
    
    <category term="fs" scheme="https://www.willshirley.top/tags/fs/"/>
    
  </entry>
  
  <entry>
    <title>ceph csi</title>
    <link href="https://www.willshirley.top/2025/03/26/ceph%20csi/"/>
    <id>https://www.willshirley.top/2025/03/26/ceph%20csi/</id>
    <published>2025-03-26T06:14:17.000Z</published>
    <updated>2025-03-27T08:34:02.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="image"><a href="#image" class="headerlink" title="image"></a>image</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> v3.13</span></span><br><span class="line">quay.io/cephcsi/cephcsi:canary</span><br><span class="line"></span><br><span class="line">registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.13.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-provisioner:v5.1.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-resizer:v1.13.1</span><br><span class="line">registry.k8s.io/sig-storage/csi-snapshotter:v8.2.0</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> v3.10</span></span><br><span class="line">quay.io/cephcsi/cephcsi:v3.10-canary</span><br><span class="line"></span><br><span class="line">registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.9.1</span><br><span class="line">registry.k8s.io/sig-storage/csi-provisioner:v3.6.2</span><br><span class="line">registry.k8s.io/sig-storage/csi-resizer:v1.9.2</span><br><span class="line">registry.k8s.io/sig-storage/csi-snapshotter:v6.3.2</span><br></pre></td></tr></table></figure><h1 id="resource"><a href="#resource" class="headerlink" title="resource"></a>resource</h1><h2 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h2><ul><li>step1</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csidriver.yaml</span><br><span class="line">kubectl create -f csi-provisioner-rbac.yaml</span><br><span class="line">kubectl create -f csi-nodeplugin-rbac.yaml</span><br></pre></td></tr></table></figure><ul><li><p>step2</p><p><code>kubectl create -f csi-config-map.yaml</code></p><blockquote><p>check by <code>ceph mon dump</code></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ceph-csi-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ceph</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config.json:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    [</span></span><br><span class="line"><span class="string">      &#123;</span></span><br><span class="line"><span class="string">        &quot;clusterID&quot;: &quot;xxx&quot;, </span></span><br><span class="line"><span class="string">        &quot;monitors&quot;: [</span></span><br><span class="line"><span class="string">          &quot;172.20.7.xxx:6789&quot;,</span></span><br><span class="line"><span class="string">          &quot;172.20.7.xxx:6789&quot;,</span></span><br><span class="line"><span class="string">          &quot;172.20.7.xxx:6789&quot;</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br></pre></td></tr></table></figure></li><li><p>step3</p><p><code>kubectl create -f ceph-conf.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">ceph.conf:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    [global]</span></span><br><span class="line"><span class="string">    auth_cluster_required = cephx</span></span><br><span class="line"><span class="string">    auth_service_required = cephx</span></span><br><span class="line"><span class="string">    auth_client_required = cephx</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">  <span class="comment"># keyring is a required key and its value should be empty</span></span><br><span class="line">  <span class="attr">keyring:</span> <span class="string">|</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ceph-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ceph</span></span><br></pre></td></tr></table></figure></li><li><p>step4</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f kms-config.yaml</span><br><span class="line">kubectl create -f csi-cephfsplugin-provisioner.yaml</span><br><span class="line">kubectl create -f csi-cephfsplugin.yaml</span><br></pre></td></tr></table></figure></li></ul><h2 id="provision"><a href="#provision" class="headerlink" title="provision"></a>provision</h2><h3 id="dynamic-provision"><a href="#dynamic-provision" class="headerlink" title="dynamic provision"></a>dynamic provision</h3><ul><li><p>step1 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph fs subvolumegroup create &lt;fsName&gt; csi</span><br></pre></td></tr></table></figure></li><li><p>step2</p><p><code>kubectl create -f secret.yaml</code></p><blockquote><p>check by <code>ceph auth get client.dongwei</code> and <code>ceph auth get client.admin</code></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">csi-cephfs-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ceph</span></span><br><span class="line"><span class="attr">stringData:</span></span><br><span class="line">  <span class="comment"># Required for statically provisioned volumes, ğŸš¨ this use user</span></span><br><span class="line">  <span class="attr">user:</span> <span class="string">dongwei</span></span><br><span class="line">  <span class="attr">userKey:</span> <span class="string">&lt;&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Required for dynamically provisioned volumes, ğŸš¨ this use admin</span></span><br><span class="line">  <span class="attr">admin:</span> <span class="string">admin</span></span><br><span class="line">  <span class="attr">adminKey:</span> <span class="string">&lt;&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Encryption passphrase</span></span><br><span class="line">  <span class="attr">encryptionPassphrase:</span> <span class="string">test_passphrase</span></span><br></pre></td></tr></table></figure></li><li><p>step3</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f storageclass.yaml</span><br><span class="line">kubectl create -f pvc.yaml</span><br><span class="line">kubectl create -f pod.yaml</span><br></pre></td></tr></table></figure></li></ul><h3 id="static-provision"><a href="#static-provision" class="headerlink" title="static provision"></a>static provision</h3><ul><li><p>step1 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ceph fs subvolumegroup create &lt;fsName&gt; testGroup</span><br><span class="line">ceph fs subvolume create &lt;fsName&gt; testSubVolume testGroup --size=1073741824  # byte 1073741824/1024/1024=1024MB</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> check</span></span><br><span class="line">ceph fs subvolume getpath &lt;fsName&gt; testSubVolume testGroup</span><br></pre></td></tr></table></figure></li><li><p>step2</p><p><code>kubectl create -f secret.yaml</code></p><blockquote><p>check by <code>ceph auth get client.dongwei</code> </p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">csi-cephfs-secret-static</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ceph</span></span><br><span class="line"><span class="attr">stringData:</span></span><br><span class="line">  <span class="comment"># Required for statically provisioned volumes, ğŸš¨ this use userID</span></span><br><span class="line">  <span class="attr">userID:</span> <span class="string">dongwei</span></span><br><span class="line">  <span class="attr">userKey:</span> <span class="string">&lt;&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Encryption passphrase</span></span><br><span class="line">  <span class="attr">encryptionPassphrase:</span> <span class="string">test_passphrase</span></span><br></pre></td></tr></table></figure></li><li><p>step3</p><p><code>kubectl create -f pv.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-static-pv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">csi:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">cephfs.csi.ceph.com</span></span><br><span class="line">    <span class="attr">nodeStageSecretRef:</span></span><br><span class="line">      <span class="comment"># node stage secret name</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">csi-cephfs-secret</span></span><br><span class="line">      <span class="comment"># node stage secret namespace where above secret is created</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">ceph</span></span><br><span class="line">    <span class="attr">volumeAttributes:</span></span><br><span class="line">      <span class="comment"># optional file system to be mounted</span></span><br><span class="line">      <span class="attr">&quot;fsName&quot;:</span> <span class="string">&quot;cephfs-1&quot;</span></span><br><span class="line">      <span class="comment"># Required options from storageclass parameters need to be added in volumeAttributes</span></span><br><span class="line">      <span class="attr">&quot;clusterID&quot;:</span> <span class="string">&quot;ba68226a-672f-4ba5-97bc-22840318b2ec&quot;</span></span><br><span class="line">      <span class="attr">&quot;staticVolume&quot;:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">      <span class="attr">&quot;rootPath&quot;:</span> <span class="string">/volumes/testGroup/testSubVolume</span></span><br><span class="line">    <span class="comment"># volumeHandle can be anything, need not to be same</span></span><br><span class="line">    <span class="comment"># as PV name or volume name. keeping same for brevity</span></span><br><span class="line">    <span class="attr">volumeHandle:</span> <span class="string">cephfs-static-pv</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br></pre></td></tr></table></figure><blockquote><p>rootPath ä¹Ÿå¯ä»¥æŒ‡å®šä¸º  /volumes/csi</p></blockquote></li><li><p>step4</p><p><code>kubectl create -f pvc.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-static-pvc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="comment"># volumeName should be same as PV name</span></span><br><span class="line">  <span class="attr">volumeName:</span> <span class="string">cephfs-static-pv</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;image&quot;&gt;&lt;a href=&quot;#image&quot; class=&quot;headerlink&quot; title=&quot;image&quot;&gt;&lt;/a&gt;image&lt;/h1&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;</summary>
      
    
    
    
    <category term="ceph" scheme="https://www.willshirley.top/categories/ceph/"/>
    
    
    <category term="csi" scheme="https://www.willshirley.top/tags/csi/"/>
    
  </entry>
  
  <entry>
    <title>kubelet snippet</title>
    <link href="https://www.willshirley.top/2025/03/25/kubelet%20snippet/"/>
    <id>https://www.willshirley.top/2025/03/25/kubelet%20snippet/</id>
    <published>2025-03-25T06:58:19.000Z</published>
    <updated>2025-03-25T06:59:59.187Z</updated>
    
    <content type="html"><![CDATA[<h1 id="troubleshooting"><a href="#troubleshooting" class="headerlink" title="troubleshooting"></a>troubleshooting</h1><h2 id="Version-from-runtime-service-failed"><a href="#Version-from-runtime-service-failed" class="headerlink" title="Version from runtime service failed"></a>Version from runtime service failed</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">E0325 12:15:10.889620 3185179 remote_runtime.go:189] &quot;Version from runtime service failed&quot; err=&quot;rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&quot;</span><br><span class="line">E0325 12:15:10.889663 3185179 kuberuntime_manager.go:226] &quot;Get runtime version failed&quot; err=&quot;get remote runtime typed version failed: rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&quot;</span><br><span class="line">E0325 12:15:10.889683 3185179 run.go:74] &quot;command failed&quot; err=&quot;failed to run Kubelet: failed to create kubelet: get remote runtime typed version failed: rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&quot;</span><br></pre></td></tr></table></figure><ul><li><p>resolve</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">å¤åˆ¶æ­£å¸¸èŠ‚ç‚¹ /etc/containerd/config.toml é…ç½®æ–‡ä»¶ï¼Œç„¶åé‡å¯ containerd</span><br><span class="line">sudo systemctl restart containerd</span><br><span class="line"></span><br><span class="line">kubeletæœåŠ¡ä¼šè‡ªåŠ¨æ‹‰èµ·</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;troubleshooting&quot;&gt;&lt;a href=&quot;#troubleshooting&quot; class=&quot;headerlink&quot; title=&quot;troubleshooting&quot;&gt;&lt;/a&gt;troubleshooting&lt;/h1&gt;&lt;h2 id=&quot;Version-from-</summary>
      
    
    
    
    <category term="kubernetes" scheme="https://www.willshirley.top/categories/kubernetes/"/>
    
    
    <category term="kubelet" scheme="https://www.willshirley.top/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>clang-uml</title>
    <link href="https://www.willshirley.top/2025/03/20/clang-uml/"/>
    <id>https://www.willshirley.top/2025/03/20/clang-uml/</id>
    <published>2025-03-20T11:27:14.000Z</published>
    <updated>2025-03-24T07:46:54.780Z</updated>
    
    <content type="html"><![CDATA[<h1 id="clang-uml"><a href="#clang-uml" class="headerlink" title="clang-uml"></a>clang-uml</h1><h2 id="init"><a href="#init" class="headerlink" title="init"></a>init</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> init .clang-uml file</span></span><br><span class="line">clang-uml --init</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> use specify config file</span></span><br><span class="line">clang-uml -c /path/to/configFile</span><br></pre></td></tr></table></figure><h2 id="generate-PlantUML"><a href="#generate-PlantUML" class="headerlink" title="generate PlantUML"></a>generate PlantUML</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> generate xxx.puml base on default config</span></span><br><span class="line">clang-uml # --progress</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> draw svg picture base on above puml file</span></span><br><span class="line">plantuml -tsvg xxx.puml</span><br></pre></td></tr></table></figure><h2 id="generate-mermaid"><a href="#generate-mermaid" class="headerlink" title="generate  mermaid"></a>generate  mermaid</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> genrate xxx.mmd</span></span><br><span class="line">clang-uml -g mermaid</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> draw svg</span></span><br><span class="line">mmdc -i xxx.mmd # -o &lt;name&gt;.svg</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> draw big svg</span></span><br><span class="line">vim config.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;maxTextSize&quot;: 1000000</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mmdc -i diagram.mmd -c config.json</span><br></pre></td></tr></table></figure><h2 id="other"><a href="#other" class="headerlink" title="other"></a>other</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> To find the exact <span class="keyword">function</span> signature</span></span><br><span class="line"> clang-uml --print-from -n client_class_diagram -c .clang-uml-sequence | grep main</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;clang-uml&quot;&gt;&lt;a href=&quot;#clang-uml&quot; class=&quot;headerlink&quot; title=&quot;clang-uml&quot;&gt;&lt;/a&gt;clang-uml&lt;/h1&gt;&lt;h2 id=&quot;init&quot;&gt;&lt;a href=&quot;#init&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="clang-uml" scheme="https://www.willshirley.top/categories/clang-uml/"/>
    
    
    <category term="tool" scheme="https://www.willshirley.top/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>nvidia cuda</title>
    <link href="https://www.willshirley.top/2025/03/12/cuda/"/>
    <id>https://www.willshirley.top/2025/03/12/cuda/</id>
    <published>2025-03-12T07:59:26.000Z</published>
    <updated>2025-04-16T07:56:35.975Z</updated>
    
    <content type="html"><![CDATA[<h1 id="version"><a href="#version" class="headerlink" title="version"></a>version</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GPU  drivercuda|vllm torch</span><br><span class="line">h10055012.4  |</span><br><span class="line">h20056512.7|0.7.32.5.1+cu124</span><br><span class="line">h20057012.8|0.7.32.5.1+cu124</span><br></pre></td></tr></table></figure><h1 id="install"><a href="#install" class="headerlink" title="install"></a>install</h1><h2 id="CUDA-Toolkit"><a href="#CUDA-Toolkit" class="headerlink" title="CUDA Toolkit"></a>CUDA Toolkit</h2><blockquote><p><a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p></blockquote><ul><li><p>local</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin</span><br><span class="line"></span><br><span class="line">sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600</span><br><span class="line"></span><br><span class="line">wget https://developer.download.nvidia.com/compute/cuda/12.8.1/local_installers/cuda-repo-ubuntu2204-12-8-local_12.8.1-570.124.06-1_amd64.deb</span><br><span class="line"></span><br><span class="line">sudo dpkg -i cuda-repo-ubuntu2204-12-8-local_12.8.1-570.124.06-1_amd64.deb</span><br><span class="line"></span><br><span class="line">sudo cp /var/cuda-repo-ubuntu2204-12-8-local/cuda-*-keyring.gpg /usr/share/keyrings/</span><br><span class="line"></span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">sudo apt-get -y install cuda-toolkit-12-8</span><br></pre></td></tr></table></figure></li><li><p>online</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb</span><br><span class="line">sudo dpkg -i cuda-keyring_1.1-1_all.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y install cuda-toolkit-12-8</span><br></pre></td></tr></table></figure></li></ul><h3 id="post-operate"><a href="#post-operate" class="headerlink" title="post operate"></a>post operate</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> config env</span></span><br><span class="line">export PATH=/usr/local/cuda/bin:$PATH</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> NVIDIA persistence daemon</span></span><br><span class="line">sudo systemctl start nvidia-persistenced</span><br></pre></td></tr></table></figure><h2 id="driver"><a href="#driver" class="headerlink" title="driver"></a>driver</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y cuda-drivers</span><br></pre></td></tr></table></figure><h2 id="nvidia-fabricmanager"><a href="#nvidia-fabricmanager" class="headerlink" title="nvidia-fabricmanager"></a>nvidia-fabricmanager</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y nvidia-fabricmanager-570</span><br><span class="line"></span><br><span class="line">sudo systemctl start nvidia-fabricmanager</span><br></pre></td></tr></table></figure><h1 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h1><blockquote><p>resolve issues: Error 802: system not yet initialized</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> sort GPUs, by ordering their IDs with IDs on the PCIe bus.</span></span><br><span class="line">export CUDA_DEVICE_ORDER=&quot;PCI_BUS_ID&quot; </span><br><span class="line"><span class="meta">#</span><span class="bash"> perform an availability check using NVML (NVIDIA Management Library). NVML is an API layer <span class="keyword">for</span> obtaining data directly from the NVIDIA-smi utility.</span></span><br><span class="line">export PYTORCH_NVML_BASED_CUDA_CHECK=1 </span><br><span class="line"><span class="meta">#</span><span class="bash"> force show the system the IDs of available GPUs.</span></span><br><span class="line">export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7</span><br></pre></td></tr></table></figure><h1 id="cuda-kernel-model"><a href="#cuda-kernel-model" class="headerlink" title="cuda kernel model"></a>cuda kernel model</h1><ul><li>check by <code>lsmod | grep nvidia</code></li></ul><table><thead><tr><th><strong>Module</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>nvidia_uvm</td><td>NVIDIAâ€™s Unified Memory driver</td></tr><tr><td>nvidia_drm</td><td>Direct Rendering Manager support</td></tr><tr><td>nvidia_modeset</td><td>Kernel mode-setting support</td></tr><tr><td>nvidia</td><td>Main NVIDIA driver module</td></tr></tbody></table><h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><h2 id="nvidia-smi"><a href="#nvidia-smi" class="headerlink" title="nvidia-smi"></a>nvidia-smi</h2><ul><li><p>Enable Persistence Mode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi -pm 1</span><br></pre></td></tr></table></figure></li><li><p>check state</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi conf-compute -grs</span><br><span class="line"><span class="meta">#</span><span class="bash"> Confidential Compute GPUs Ready state: not-ready</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Confidential Compute GPUs Ready state: ready</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">if</span> above state is not-ready, execute below cmd</span></span><br><span class="line">nvidia-smi conf-compute -srs 1</span><br></pre></td></tr></table></figure></li><li><p>cuda 12.8</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA H200                    On  |   00000000:19:00.0 Off |                    0 |</span><br><span class="line">| N/A   23C    P0             76W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   1  NVIDIA H200                    On  |   00000000:3B:00.0 Off |                    0 |</span><br><span class="line">| N/A   21C    P0             75W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   2  NVIDIA H200                    On  |   00000000:4C:00.0 Off |                    0 |</span><br><span class="line">| N/A   23C    P0             76W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   3  NVIDIA H200                    On  |   00000000:5D:00.0 Off |                    0 |</span><br><span class="line">| N/A   24C    P0             77W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   4  NVIDIA H200                    On  |   00000000:9B:00.0 Off |                    0 |</span><br><span class="line">| N/A   24C    P0             75W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   5  NVIDIA H200                    On  |   00000000:BB:00.0 Off |                    0 |</span><br><span class="line">| N/A   23C    P0             77W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   6  NVIDIA H200                    On  |   00000000:CB:00.0 Off |                    0 |</span><br><span class="line">| N/A   24C    P0             76W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   7  NVIDIA H200                    On  |   00000000:DB:00.0 Off |                    0 |</span><br><span class="line">| N/A   24C    P0             76W /  700W |       1MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">                                                                                         </span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                              |</span><br><span class="line">|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |</span><br><span class="line">|        ID   ID                                                               Usage      |</span><br><span class="line">|=========================================================================================|</span><br><span class="line">|  No running processes found                                                             |</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure></li><li><p>cuda 12.7</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">Fri Mar 14 10:23:56 2025       </span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA H200                    On  |   00000000:19:00.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0            111W /  700W |  134402MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   1  NVIDIA H200                    On  |   00000000:3B:00.0 Off |                    0 |</span><br><span class="line">| N/A   25C    P0            116W /  700W |  132320MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   2  NVIDIA H200                    On  |   00000000:4C:00.0 Off |                    0 |</span><br><span class="line">| N/A   25C    P0            112W /  700W |  132320MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   3  NVIDIA H200                    On  |   00000000:5D:00.0 Off |                    0 |</span><br><span class="line">| N/A   27C    P0            115W /  700W |  132320MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   4  NVIDIA H200                    On  |   00000000:9B:00.0 Off |                    0 |</span><br><span class="line">| N/A   27C    P0            115W /  700W |  132320MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   5  NVIDIA H200                    On  |   00000000:BB:00.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0            114W /  700W |  132320MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   6  NVIDIA H200                    On  |   00000000:CB:00.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0            113W /  700W |  132320MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   7  NVIDIA H200                    On  |   00000000:DB:00.0 Off |                    0 |</span><br><span class="line">| N/A   24C    P0            114W /  700W |  131840MiB / 143771MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">                                                                                         </span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                              |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |</span><br><span class="line">|        ID   ID                                                               Usage      |</span><br><span class="line">|=========================================================================================|</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h1 id="vllm"><a href="#vllm" class="headerlink" title="vllm"></a>vllm</h1><h2 id="install-offline"><a href="#install-offline" class="headerlink" title="install offline"></a>install offline</h2><p>On your local machine, create a virtual environment:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 -m venv vllm_env</span><br><span class="line">source vllm_env/bin/activate</span><br></pre></td></tr></table></figure><p>1ï¸âƒ£ <strong>On your local machine:</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip download --dest=./vllm_deps vllm</span><br></pre></td></tr></table></figure><p>2ï¸âƒ£ <strong>Transfer dependencies to the remote server:</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r vllm_deps user@remote_server:/path/to/destination/</span><br></pre></td></tr></table></figure><p>3ï¸âƒ£ <strong>On the remote server:</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /path/to/destination/vllm_deps</span><br><span class="line">pip install --no-index --find-links=. vllm*</span><br><span class="line">â€¢--no-index tells pip not to use the internet.</span><br><span class="line">â€¢--find-links=./vllm_deps tells pip to look for packages in this directory.</span><br><span class="line">â€¢vllm* ensures pip finds the correct package in that folder.</span><br></pre></td></tr></table></figure><h2 id="running-time"><a href="#running-time" class="headerlink" title="running time"></a>running time</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve /mnt/dingofs-test/DeepSeek-R1 --host 0.0.0.0 --port 8000 --served-model-name deepseek-r1 --tensor-parallel-size 8 --gpu-memory-utilization 0.85 --max-model-len 128000 --max-num-batched-tokens 32000 --max-num-seqs 1024 --trust-remote-code --enable-reasoning --reasoning-parser deepseek_r1</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">Sat Mar 15 20:33:04 2025       </span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA H200                    On  |   00000000:19:00.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0            115W /  700W |   84474MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   1  NVIDIA H200                    On  |   00000000:3B:00.0 Off |                    0 |</span><br><span class="line">| N/A   24C    P0            113W /  700W |   84522MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   2  NVIDIA H200                    On  |   00000000:4C:00.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0            114W /  700W |   84522MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   3  NVIDIA H200                    On  |   00000000:5D:00.0 Off |                    0 |</span><br><span class="line">| N/A   27C    P0            117W /  700W |   84522MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   4  NVIDIA H200                    On  |   00000000:9B:00.0 Off |                    0 |</span><br><span class="line">| N/A   27C    P0            114W /  700W |   84522MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   5  NVIDIA H200                    On  |   00000000:BB:00.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0            116W /  700W |   84522MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   6  NVIDIA H200                    On  |   00000000:CB:00.0 Off |                    0 |</span><br><span class="line">| N/A   27C    P0            115W /  700W |   84522MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">|   7  NVIDIA H200                    On  |   00000000:DB:00.0 Off |                    0 |</span><br><span class="line">| N/A   26C    P0            114W /  700W |   84282MiB / 143771MiB |      1%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line">+-----------------------------------------+------------------------+----------------------+</span><br><span class="line">                                                                                         </span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                              |</span><br><span class="line">|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |</span><br><span class="line">|        ID   ID                                                               Usage      |</span><br><span class="line">|=========================================================================================|</span><br><span class="line">|    0   N/A  N/A          915920      C   ...niconda3/envs/vllm/bin/python      84464MiB |</span><br><span class="line">|    1   N/A  N/A          916338      C   ...niconda3/envs/vllm/bin/python      84512MiB |</span><br><span class="line">|    2   N/A  N/A          916339      C   ...niconda3/envs/vllm/bin/python      84512MiB |</span><br><span class="line">|    3   N/A  N/A          916340      C   ...niconda3/envs/vllm/bin/python      84512MiB |</span><br><span class="line">|    4   N/A  N/A          916341      C   ...niconda3/envs/vllm/bin/python      84512MiB |</span><br><span class="line">|    5   N/A  N/A          916342      C   ...niconda3/envs/vllm/bin/python      84512MiB |</span><br><span class="line">|    6   N/A  N/A          916343      C   ...niconda3/envs/vllm/bin/python      84512MiB |</span><br><span class="line">|    7   N/A  N/A          916344      C   ...niconda3/envs/vllm/bin/python      84272MiB |</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><ul><li><p>log</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">INFO 03-15 20:36:48 worker.py:267] Memory profiling takes 7.63 seconds</span><br><span class="line">INFO 03-15 20:36:48 worker.py:267] the current vLLM instance can use total_gpu_memory (139.81GiB) x gpu_memory_utilization (0.85) = 118.84GiB</span><br><span class="line">INFO 03-15 20:36:48 worker.py:267] model weights take 83.88GiB; non_torch_memory takes 7.16GiB; PyTorch activation peak memory takes 6.37GiB; the rest of the memory reserved </span><br><span class="line">for KV Cache is 21.43GiB.</span><br><span class="line">INFO 03-15 20:36:48 executor_base.py:111] # cuda blocks: 18418, # CPU blocks: 3437</span><br><span class="line">INFO 03-15 20:36:48 executor_base.py:116] Maximum concurrency for 128000 tokens per request: 2.30x</span><br></pre></td></tr></table></figure></li><li><p>chat</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions \</span><br><span class="line">    -H &quot;Content-Type: application/json&quot; \</span><br><span class="line">    -d &#x27;&#123;</span><br><span class="line">        &quot;model&quot;: &quot;deepseek-r1&quot;,</span><br><span class="line">        &quot;messages&quot;: [</span><br><span class="line">            &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;&#125;,</span><br><span class="line">            &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;introduce yourself&quot;&#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;&#x27;</span><br></pre></td></tr></table></figure></li></ul><h1 id="sglang"><a href="#sglang" class="headerlink" title="sglang"></a>sglang</h1><h2 id="install-offline-1"><a href="#install-offline-1" class="headerlink" title="install offline"></a>install offline</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> prepare env</span></span><br><span class="line">python3 -m venv sglang_env</span><br><span class="line">source sglang_env/bin/activate</span><br><span class="line"><span class="meta">#</span><span class="bash"> optional use uv</span></span><br><span class="line">pip install --upgrade pip</span><br><span class="line"><span class="meta">#</span><span class="bash">pip install uv</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> download deps</span></span><br><span class="line">mkdir -p ./sglang_deps</span><br><span class="line">pip download &quot;sglang[all]&gt;=0.4.4.post1&quot; --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python -d ./sglang_deps</span><br><span class="line"><span class="meta">#</span><span class="bash"> scp deps to remote</span></span><br><span class="line">scp -r sglang_deps user@remote_server:/path/to/destination/</span><br><span class="line"><span class="meta">#</span><span class="bash"> install sglang on remote</span></span><br><span class="line">cd /path/to/remote/sglang_deps</span><br><span class="line">pip install --no-index --find-links=. &quot;sglang[all]&gt;=0.4.4.post1&quot;</span><br></pre></td></tr></table></figure><h2 id="runtime"><a href="#runtime" class="headerlink" title="runtime"></a>runtime</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m sglang.launch_server --model /mnt/3fs/DeepSeek-R1 --tp 8 --trust-remote-code --port 30000</span><br></pre></td></tr></table></figure><ul><li><p>chat</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:30000/v1/chat/completions \</span><br><span class="line">    -H &quot;Content-Type: application/json&quot; \</span><br><span class="line">    -d &#x27;&#123;</span><br><span class="line">        &quot;model&quot;: &quot;deepseek-r1&quot;,</span><br><span class="line">        &quot;messages&quot;: [</span><br><span class="line">            &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;&#125;,</span><br><span class="line">            &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;introduce yourself&quot;&#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;&#x27;</span><br></pre></td></tr></table></figure></li></ul><h1 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h1><h2 id="install-offline-2"><a href="#install-offline-2" class="headerlink" title="install offline"></a>install offline</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/torch_deps</span><br><span class="line">pip download --dest=~/torch_deps torch==2.5.1 --extra-index-url https://download.pytorch.org/whl/nightly/cu128</span><br><span class="line"></span><br><span class="line">scp -r ~/torch_deps user@remote_server:/path/to/remote/directory</span><br><span class="line">cd /path/to/remote/directory</span><br><span class="line">pip install --no-index --find-links=./ torch</span><br></pre></td></tr></table></figure><ul><li><p>check</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -c &quot;import torch; print(torch.cuda.is_available()); print(torch.cuda.device_count())&quot;</span><br></pre></td></tr></table></figure><p>or</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())  <span class="comment"># print false</span></span><br><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())  <span class="comment"># print 8</span></span><br><span class="line"><span class="built_in">print</span>(torch.__version__)  <span class="comment"># print 2.5.1+cu124</span></span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda) <span class="comment"># print 12.4</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="best-practices"><a href="#best-practices" class="headerlink" title="best practices"></a>best practices</h1><h2 id="CUDA-LAUNCH-BLOCKING-1"><a href="#CUDA-LAUNCH-BLOCKING-1" class="headerlink" title="CUDA_LAUNCH_BLOCKING=1"></a><code>CUDA_LAUNCH_BLOCKING=1</code></h2><blockquote><p>CUDA_LAUNCH_BLOCKING=1 will tell CUDA: â€œWait (block) for each GPU kernel to finish before moving to the next line of Python code.â€</p></blockquote><p>Normally, CUDA operations are <strong>asynchronous</strong>â€”errors may not happen exactly where the code looks wrong, because the kernel may fail later. This can make debugging frustrating.</p><p>should never use it in production or performance benchmarkingâ€”just for debugging.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;version&quot;&gt;&lt;a href=&quot;#version&quot; class=&quot;headerlink&quot; title=&quot;version&quot;&gt;&lt;/a&gt;version&lt;/h1&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=</summary>
      
    
    
    
    <category term="cuda" scheme="https://www.willshirley.top/categories/cuda/"/>
    
    
    <category term="nvidia" scheme="https://www.willshirley.top/tags/nvidia/"/>
    
  </entry>
  
  <entry>
    <title>k8s ctr</title>
    <link href="https://www.willshirley.top/2025/03/12/k8s%20ctr/"/>
    <id>https://www.willshirley.top/2025/03/12/k8s%20ctr/</id>
    <published>2025-03-12T07:59:26.000Z</published>
    <updated>2025-03-20T16:22:21.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> check k8s image</span></span><br><span class="line">ctr --namespace k8s.io images list</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;command&quot;&gt;&lt;a href=&quot;#command&quot; class=&quot;headerlink&quot; title=&quot;command&quot;&gt;&lt;/a&gt;command&lt;/h1&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=</summary>
      
    
    
    
    <category term="k8s" scheme="https://www.willshirley.top/categories/k8s/"/>
    
    
    <category term="ctr" scheme="https://www.willshirley.top/tags/ctr/"/>
    
  </entry>
  
  <entry>
    <title>network solution</title>
    <link href="https://www.willshirley.top/2025/03/10/network%20solution/"/>
    <id>https://www.willshirley.top/2025/03/10/network%20solution/</id>
    <published>2025-03-10T02:04:37.000Z</published>
    <updated>2025-04-30T10:09:30.819Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h1><h2 id="add-new-dns"><a href="#add-new-dns" class="headerlink" title="add new dns"></a>add new dns</h2><ul><li><p>method 1:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step1: vim /etc/systemd/resolved.conf</span></span><br><span class="line">[<span class="string">Resolve</span>]</span><br><span class="line"><span class="string">DNS=10.201.44.51</span> <span class="number">223.5</span><span class="number">.5</span><span class="number">.5</span>  <span class="comment"># new DNS</span></span><br><span class="line"><span class="string">FallbackDNS=127.0.0.53</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># step2: restart service</span></span><br><span class="line"><span class="string">sudo</span> <span class="string">systemctl</span> <span class="string">restart</span> <span class="string">systemd-resolved</span></span><br></pre></td></tr></table></figure></li><li><p>method2: (æœ‰æ—¶å€™ä¸èµ·æ•ˆ)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">/etc/resolv.conf</span></span><br><span class="line"><span class="comment"># æ³¨æ„ï¼šæ·»åŠ çš„dnsè§£æåœ°å€ï¼Œéœ€è¦æ”¾åœ¨å‰é¢ï¼Œä¼šæœ‰é¡ºåºå½±å“</span></span><br><span class="line"></span><br><span class="line"><span class="string">nameserver</span> <span class="number">10.201</span><span class="number">.44</span><span class="number">.51</span>  <span class="comment"># new DNS</span></span><br><span class="line"><span class="string">nameserver</span> <span class="number">223.5</span><span class="number">.5</span><span class="number">.5</span><span class="comment"># new DNS</span></span><br><span class="line"><span class="string">nameserver</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.53</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="network"><a href="#network" class="headerlink" title="network"></a>network</h1><h2 id="create-new-network"><a href="#create-new-network" class="headerlink" title="create new network"></a>create new network</h2><p>step1: vim <code>/etc/netplan/ib.yaml</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    ibp27s0:</span><br><span class="line">      dhcp4: no</span><br><span class="line">      addresses:</span><br><span class="line">        - 192.168.2.52/21</span><br></pre></td></tr></table></figure><p>step2: <code>netplan apply</code></p><h1 id="bond"><a href="#bond" class="headerlink" title="bond"></a>bond</h1><h2 id="create-bond"><a href="#create-bond" class="headerlink" title="create bond"></a>create bond</h2><p>Bonding Mode</p><table><thead><tr><th>Mode</th><th>Max Speed (Single Flow)</th><th>Max Speed (Multiple Flows)</th><th>Key Feature</th></tr></thead><tbody><tr><td>mode=0 (round-robin)</td><td>Sum of all slaves</td><td>Sum of all slaves</td><td>Best for maximizing bandwidth, may cause out-of-order packets.</td></tr><tr><td>mode=1 (active-backup)</td><td>One interfaceâ€™s speed</td><td>One interfaceâ€™s speed</td><td>Best for redundancy, no speed gain.</td></tr><tr><td>mode=2 (balance-xor)</td><td>One interfaceâ€™s speed</td><td>Sum of all slaves</td><td>Good for performance; switch support required.</td></tr><tr><td>mode=4 (802.3ad - LACP)</td><td>One interfaceâ€™s speed</td><td>Sum of all slaves</td><td>Efficient load balancing for multiple flows; requires switch support.</td></tr><tr><td>mode=5 (balance-tlb)</td><td>One interfaceâ€™s speed</td><td>Sum of all slaves (outgoing only)</td><td>Adaptive transmit load balancing.</td></tr><tr><td>mode=6 (balance-alb)</td><td>One interfaceâ€™s speed</td><td>Sum of all slaves</td><td>Adaptive load balancing without switch support.</td></tr></tbody></table><blockquote><p> assume make ib7s400p0 to bond1, which have assigned  ip 172.30.12.46 with ib7s400p0</p></blockquote><p><strong>optional</strong>: Load the Bonding Kernel Module</p><p>Ensure the bonding driver is loaded:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo modprobe bonding</span><br></pre></td></tr></table></figure><p>To persist this across reboots:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;bonding&quot; | sudo tee /etc/modules-load.d/bonding.conf</span><br></pre></td></tr></table></figure><p><strong>optional</strong>: Remove the IP Address from ib7s400p0</p><p>Since the bond interface will carry the IP, you must remove the IP from ib7s400p0 first:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip addr del 172.30.12.61/24 dev ib7s400p0</span><br></pre></td></tr></table></figure><p><strong>Step 2: Create the Bond Interface (bond1)</strong></p><p>Create the bond interface:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip link add bond1 type bond</span><br></pre></td></tr></table></figure><p><strong>Step 3: Configure Bonding Mode</strong></p><p>For your use case, you can set mode=active-backup (best for redundancy with one NIC now) or mode=802.3ad (if planning for LACP in the future).</p><p><strong>Set Active-Backup Mode (Recommended for 1 NIC Now)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;active-backup&quot; | sudo tee /sys/class/net/bond1/bonding/mode</span><br></pre></td></tr></table></figure><p><strong>OR Set 802.3ad Mode (If Future Expansion is Planned)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;802.3ad&quot; | sudo tee /sys/class/net/bond1/bonding/mode</span><br></pre></td></tr></table></figure><p><strong>Step 4: Add ib7s400p0 as a Slave</strong></p><ol><li>Remove any IP address from ib7s400p0 (if it has one):</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip addr flush dev ib7s400p0</span><br></pre></td></tr></table></figure><ol start="2"><li>Add ib7s400p0 to bond1:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo ip link set ib7s400p0 down</span><br><span class="line">sudo ip link set ib7s400p0 master bond1</span><br><span class="line">sudo ip link set ib7s400p0 up</span><br></pre></td></tr></table></figure><blockquote><p>check: ethtool ib7s400p0</p></blockquote><ol start="3"><li>Bring bond1 up:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip link set bond1 up</span><br></pre></td></tr></table></figure><blockquote><p>check: cat /proc/net/bonding/bond1</p></blockquote><p><strong>Step 5: Assign an IP Address</strong></p><p>If using a <strong>static IP</strong>:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip addr add 172.30.12.61/24 dev bond1</span><br></pre></td></tr></table></figure><p>Or if using <strong>DHCP</strong>:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dhclient bond1</span><br></pre></td></tr></table></figure><p>Try to force traffic through bond1 by removing the direct route through ib7s400p0</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip route del 172.30.12.0/24 dev ib7s400p0</span><br></pre></td></tr></table></figure><p><strong>Step 6: Persistent Configuration (Rocky 9 / RHEL 9) (optional)</strong></p><p>To ensure the bond configuration persists after reboot:</p><ol><li>Create <code>/etc/sysconfig/network-scripts/ifcfg-bond1</code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=bond1</span><br><span class="line">TYPE=Bond</span><br><span class="line">BONDING_MASTER=yes</span><br><span class="line">BOOTPROTO=dhcp      # Or use &#x27;static&#x27; if assigning a static IP</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BONDING_OPTS=&quot;mode=active-backup miimon=100&quot;</span><br></pre></td></tr></table></figure><ol start="2"><li>Create <code>/etc/sysconfig/network-scripts/ifcfg-ib7s400p0</code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=ib7s400p0</span><br><span class="line">MASTER=bond1</span><br><span class="line">SLAVE=yes</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">ONBOOT=yes</span><br></pre></td></tr></table></figure><ol start="3"><li>Restart NetworkManager to apply changes:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart NetworkManager</span><br></pre></td></tr></table></figure><p><strong>Step 7: Verify Configuration</strong></p><ol><li>Check bond details:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/net/bonding/bond1</span><br></pre></td></tr></table></figure><p>ib7s400p0 should now appear as a <strong>Slave Interface</strong>.</p><ol start="2"><li>Confirm IP address and route:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip a</span><br><span class="line">ip route</span><br></pre></td></tr></table></figure><ol start="3"><li>Test connectivity:</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping 172.30.12.47 # other same bond addr</span><br></pre></td></tr></table></figure><p><strong>Step 8: Optional - Test Failover (For active-backup Mode)</strong></p><p>â€‹    1.    Temporarily bring down ib7s400p0:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ip link set ib7s400p0 down</span><br></pre></td></tr></table></figure><p>â€‹    2.    Check bond1 status:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/net/bonding/bond1</span><br></pre></td></tr></table></figure><p>In active-backup mode, bond1 should remain active (even though ib7s400p0 is down).</p><p>In 802.3ad mode, bond1 would go down since no alternate NIC exists yet.</p><p><strong>Summary</strong></p><p>Use <strong>active-backup</strong> mode if ib7s400p0 is the only slave (recommended now).</p><p>Use <strong>802.3ad</strong> if planning to add more NICs for higher throughput in the future.</p><p>Ensure <code>/etc/sysconfig/network-scripts/</code> configs are properly set for persistence.</p><h1 id="ibtables"><a href="#ibtables" class="headerlink" title="ibtables"></a>ibtables</h1><h2 id="remove-specify-rule"><a href="#remove-specify-rule" class="headerlink" title="remove specify rule"></a>remove specify rule</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> check iptables</span></span><br><span class="line">sudo iptables -L -n -v</span><br><span class="line"><span class="meta">#</span><span class="bash"> check nftables</span></span><br><span class="line">sudo nft list ruleset</span><br></pre></td></tr></table></figure><p>To remove the <code>reject-with icmp-host-prohibited</code> rule and allow <strong>all incoming traffic</strong> from external servers, follow these steps. This will disable the firewallâ€™s default rejection of unmatched traffic.</p><p><strong>Step 1: Remove the <code>REJECT</code> Rule in <code>iptables</code></strong></p><p>First, identify and delete the explicit <code>REJECT</code> rule in the <code>INPUT</code> chain.</p><p>Check current <code>iptables</code> rules (look for the <code>REJECT</code> line):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -L INPUT -n --line-numbers</span><br></pre></td></tr></table></figure><p>Example output:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">num  target     prot opt source               destination</span><br><span class="line">...</span><br><span class="line">5    REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with icmp-host-prohibited</span><br></pre></td></tr></table></figure><p>Delete the rule by its line number (e.g., line <code>5</code>):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -D INPUT 5</span><br></pre></td></tr></table></figure><p><strong>Step 2: Set Default Policy to <code>ACCEPT</code> (Optional)</strong></p><p>If you want to <strong>allow all traffic by default</strong> (not recommended for security), set the <code>INPUT</code> chain policy to <code>ACCEPT</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -P INPUT ACCEPT</span><br></pre></td></tr></table></figure><p><strong>Step 3: Save the Rules (Persist Across Reboots)</strong></p><p>Save the changes to ensure they survive a reboot.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># On CentOS/RHEL 7 or systems using iptables-service:</span></span><br><span class="line">sudo service iptables save</span><br><span class="line"><span class="comment"># On Debian/Ubuntu with iptables-persistent:</span></span><br><span class="line">sudo netfilter-persistent save</span><br></pre></td></tr></table></figure><h1 id="nftables"><a href="#nftables" class="headerlink" title="nftables"></a>nftables</h1><h2 id="Accept-ALL-INPUT"><a href="#Accept-ALL-INPUT" class="headerlink" title="Accept ALL INPUT"></a>Accept ALL INPUT</h2><p>For systems using <code>nftables</code> (modern Linux):</p><p>If your system uses <code>nftables</code> , flush all rules and set a default <code>ACCEPT</code> policy:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Flush existing rules</span></span><br><span class="line">sudo nft flush ruleset</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set default policies to ACCEPT</span></span><br><span class="line">sudo nft add table ip filter</span><br><span class="line">sudo nft add chain ip filter INPUT &#123; <span class="built_in">type</span> filter hook input priority 0 \; policy accept \; &#125;</span><br><span class="line">sudo nft add chain ip filter FORWARD &#123; <span class="built_in">type</span> filter hook forward priority 0 \; policy accept \; &#125;</span><br><span class="line">sudo nft add chain ip filter OUTPUT &#123; <span class="built_in">type</span> filter hook output priority 0 \; policy accept \; &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save rules</span></span><br><span class="line">sudo nft list ruleset &gt; /etc/nftables.conf</span><br></pre></td></tr></table></figure><p><strong>Step 4: Verify the Rules</strong></p><p>Confirm the <code>REJECT</code> rule is gone and traffic is allowed:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -L INPUT -n</span><br><span class="line"><span class="comment"># OR for nftables:</span></span><br><span class="line">sudo nft list ruleset</span><br></pre></td></tr></table></figure><p><strong>Important Notes</strong></p><ul><li><strong>Security Warning</strong>: Disabling firewall rules entirely (<code>ACCEPT</code> policy) exposes your server to all traffic. Only do this in trusted environments.</li><li>If you only want to allow specific ports (e.g., <code>6800</code>), use targeted rules instead of disabling the firewall:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -I INPUT -p tcp --dport 6800 -j ACCEPT</span><br><span class="line">sudo netfilter-persistent save</span><br></pre></td></tr></table></figure></li><li>The <code>icmp-host-prohibited</code> rejection is part of the <code>iptables</code> rules, not a separate service. Deleting the rule (Step 1) is sufficient to stop the blocking.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DNS&quot;&gt;&lt;a href=&quot;#DNS&quot; class=&quot;headerlink&quot; title=&quot;DNS&quot;&gt;&lt;/a&gt;DNS&lt;/h1&gt;&lt;h2 id=&quot;add-new-dns&quot;&gt;&lt;a href=&quot;#add-new-dns&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="network" scheme="https://www.willshirley.top/categories/network/"/>
    
    
    <category term="solution" scheme="https://www.willshirley.top/tags/solution/"/>
    
  </entry>
  
  <entry>
    <title>llm vllm</title>
    <link href="https://www.willshirley.top/2025/03/06/llm%20vllm/"/>
    <id>https://www.willshirley.top/2025/03/06/llm%20vllm/</id>
    <published>2025-03-06T07:25:11.000Z</published>
    <updated>2025-03-06T07:28:51.215Z</updated>
    
    <content type="html"><![CDATA[<h1 id="route"><a href="#route" class="headerlink" title="route"></a>route</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">INFO llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 135.23 seconds</span><br><span class="line">INFO api_server.py:958] Starting vLLM API server on http://0.0.0.0:8000</span><br><span class="line">Available routes are:</span><br><span class="line"> Route: /openapi.json, Methods: GET, HEAD</span><br><span class="line"> Route: /docs, Methods: GET, HEAD</span><br><span class="line"> Route: /docs/oauth2-redirect, Methods: GET, HEAD</span><br><span class="line"> Route: /redoc, Methods: GET, HEAD</span><br><span class="line"> Route: /health, Methods: GET</span><br><span class="line"> Route: /ping, Methods: GET, POST</span><br><span class="line"> Route: /tokenize, Methods: POST</span><br><span class="line"> Route: /detokenize, Methods: POST</span><br><span class="line"> Route: /v1/models, Methods: GET</span><br><span class="line"> Route: /version, Methods: GET</span><br><span class="line"> Route: /v1/chat/completions, Methods: POST</span><br><span class="line"> Route: /v1/completions, Methods: POST</span><br><span class="line"> Route: /v1/embeddings, Methods: POST</span><br><span class="line"> Route: /pooling, Methods: POST</span><br><span class="line"> Route: /score, Methods: POST</span><br><span class="line"> Route: /v1/score, Methods: POST</span><br><span class="line"> Route: /v1/audio/transcriptions, Methods: POST</span><br><span class="line"> Route: /rerank, Methods: POST</span><br><span class="line"> Route: /v1/rerank, Methods: POST</span><br><span class="line"> Route: /v2/rerank, Methods: POST</span><br><span class="line"> Route: /invocations, Methods: POST</span><br><span class="line">INFO:     Started server process [1]</span><br><span class="line">INFO:     Waiting for application startup.</span><br><span class="line">INFO:     Application startup complete.</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;route&quot;&gt;&lt;a href=&quot;#route&quot; class=&quot;headerlink&quot; title=&quot;route&quot;&gt;&lt;/a&gt;route&lt;/h1&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;</summary>
      
    
    
    
    <category term="llm" scheme="https://www.willshirley.top/categories/llm/"/>
    
    
    <category term="sinppet" scheme="https://www.willshirley.top/tags/sinppet/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes RBAC</title>
    <link href="https://www.willshirley.top/2025/03/01/kubernetes%20RBAC/"/>
    <id>https://www.willshirley.top/2025/03/01/kubernetes%20RBAC/</id>
    <published>2025-03-01T11:48:15.000Z</published>
    <updated>2025-03-01T12:20:55.733Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>RBAC (Role-Based Access Control) in Kubernetes is a security model that controls who can access and perform actions on resources (like Pods, Deployments, Services, etc.) within a cluster.</p></blockquote><h1 id="Component"><a href="#Component" class="headerlink" title="Component"></a>Component</h1><p>Kubernetes RBAC consists of four main components:</p><table><thead><tr><th>Component</th><th>Description</th></tr></thead><tbody><tr><td>Role / ClusterRole</td><td>Defines what actions (verbs) can be performed on which resources.</td></tr><tr><td>RoleBinding / ClusterRoleBinding</td><td>Grants a Role or ClusterRole to a User, Group, or ServiceAccount.</td></tr><tr><td>Subjects (Users, Groups, ServiceAccounts)</td><td>Who is allowed to perform actions (User, Group, or ServiceAccount).</td></tr><tr><td>Resources &amp; API Groups</td><td>The objects that can be controlled (e.g., pods, deployments, services, etc.).</td></tr></tbody></table><h2 id="Role-amp-ClusterRole"><a href="#Role-amp-ClusterRole" class="headerlink" title="Role &amp; ClusterRole"></a>Role &amp; ClusterRole</h2><blockquote><p>RBAC defines what actions can be performed on which resources using Roles and ClusterRoles.</p></blockquote><h3 id="Role"><a href="#Role" class="headerlink" title="Role"></a>Role</h3><blockquote><p>A Role is used for namespace-scoped access control.</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">my-namespace</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br></pre></td></tr></table></figure><p>âœ… This Role allows a user to view (get, list, watch) Pods only in the namespace my-namespace.</p><p>âŒ This does not grant access to other namespaces.</p><h3 id="ClusterRole"><a href="#ClusterRole" class="headerlink" title="ClusterRole"></a>ClusterRole</h3><blockquote><p> A ClusterRole is used for cluster-wide permissions or permissions across all namespaces.</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-pod-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br></pre></td></tr></table></figure><p>âœ… This allows viewing (get, list, watch) Pods in all namespaces.</p><h2 id="RoleBinding-amp-ClusterRoleBinding"><a href="#RoleBinding-amp-ClusterRoleBinding" class="headerlink" title="RoleBinding &amp; ClusterRoleBinding"></a>RoleBinding &amp; ClusterRoleBinding</h2><blockquote><p>Who Gets These Permissions?</p></blockquote><h3 id="RoleBinding"><a href="#RoleBinding" class="headerlink" title="RoleBinding"></a>RoleBinding</h3><blockquote><p>A RoleBinding assigns a Role to a specific user, group, or ServiceAccount in a namespace.</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">my-namespace</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-user</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><p>âœ… This binds the pod-reader Role to my-user in the my-namespace namespace.</p><p>âŒ It does not grant permissions outside my-namespace.</p><h3 id="ClusterRoleBinding"><a href="#ClusterRoleBinding" class="headerlink" title="ClusterRoleBinding"></a>ClusterRoleBinding</h3><blockquote><p>A ClusterRoleBinding assigns a ClusterRole to a User, Group, or ServiceAccount across all namespaces.</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-pod-reader-binding</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-user</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-pod-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><p>âœ… This grants my-user access to Pods across all namespaces.</p><h2 id="Subjects"><a href="#Subjects" class="headerlink" title="Subjects"></a>Subjects</h2><blockquote><p>A RoleBinding or ClusterRoleBinding grants permissions to a subject, which can be:</p></blockquote><table><thead><tr><th>Subject Type</th><th>Description</th></tr></thead><tbody><tr><td>User</td><td>A real human user (external identity).</td></tr><tr><td>Group</td><td>A group of users (e.g., dev-team).</td></tr><tr><td>ServiceAccount</td><td>An internal Kubernetes identity for a Pod or Controller.</td></tr></tbody></table><p>Example: Binding a ServiceAccount (my-sa) to a Role</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-sa</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">my-namespace</span></span><br></pre></td></tr></table></figure><h2 id="API-Groups-amp-Resources"><a href="#API-Groups-amp-Resources" class="headerlink" title="API Groups &amp; Resources"></a>API Groups &amp; Resources</h2><p>Each RBAC rule specifies which resources in which API groups can be accessed.</p><table><thead><tr><th>API Group</th><th>Resources Example</th></tr></thead><tbody><tr><td>â€œâ€ (core)</td><td>pods, services, nodes</td></tr><tr><td>apps</td><td>deployments, daemonsets</td></tr><tr><td>batch</td><td>jobs, cronjobs</td></tr><tr><td>rbac.authorization.k8s.io</td><td>roles, rolebindings, clusterroles, clusterrolebindings</td></tr></tbody></table><p>Example: Allow Access to Pods, Deployments, and Nodes</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>, <span class="string">&quot;services&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;apps&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;deployments&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>]</span><br></pre></td></tr></table></figure><p>âœ… Allows reading Pods and Services (core API group).</p><p>âœ… Allows reading Deployments (apps API group).</p><p>âœ… Allows reading Nodes (core API group).</p><h1 id="Works-Scenario"><a href="#Works-Scenario" class="headerlink" title="Works Scenario"></a>Works Scenario</h1><h2 id="Scenario-1"><a href="#Scenario-1" class="headerlink" title="Scenario 1"></a>Scenario 1</h2><p>Use Case:</p><ul><li><p>A user (dev-user) needs read-only access to Pods in the dev namespace.</p></li><li><p>The ServiceAccount (cicd-runner-sa) needs to create Deployments in the cicd namespace.</p></li></ul><p>Solution: Define the RBAC Rules</p><ol><li>Create a Role for Read-Only Pod Access in dev Namespace</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br></pre></td></tr></table></figure><ol start="2"><li>Bind the Role to dev-user in dev Namespace</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev-user</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><ol start="3"><li>Create a Role for cicd-runner-sa to Deploy Apps in cicd Namespace</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deployment-creator</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cicd</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;apps&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;deployments&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;delete&quot;</span>]</span><br></pre></td></tr></table></figure><ol start="4"><li>Bind the Role to the cicd-runner-sa ServiceAccount</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cicd-runner-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cicd</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cicd-runner-sa</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cicd</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deployment-creator</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><h2 id="Scenario-2"><a href="#Scenario-2" class="headerlink" title="Scenario 2"></a>Scenario 2</h2><p>Scenario: Grant Read-Only Access to Pods Across Multiple Namespaces</p><p>Use Case:</p><ul><li><p>A developer team needs read-only access to Pods in multiple namespaces (dev, staging, prod).</p></li><li><p>Instead of creating separate Roles in each namespace, we use one ClusterRole.</p></li><li><p>We then create RoleBindings in each namespace to assign the ClusterRole.</p></li></ul><ol><li>Create a ClusterRole to Read Pods Across Namespaces</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">multi-namespace-pod-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br></pre></td></tr></table></figure><ol start="2"><li>Bind the ClusterRole to a User for Multiple Namespaces</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">multi-namespace-pod-reader-binding</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">developer-user</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">multi-namespace-pod-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><h1 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h1><p>Key Takeaways from Kubernetes RBAC Architecture</p><ol><li><p>Role / ClusterRole â†’ Defines permissions (what actions are allowed?).</p></li><li><p>RoleBinding / ClusterRoleBinding â†’ Assigns permissions (who gets access?).</p></li><li><p>Subjects â†’ Users, Groups, ServiceAccounts (who is authorized?).</p></li><li><p>API Groups â†’ Determines resources that can be controlled.</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;RBAC (Role-Based Access Control) in Kubernetes is a security model that controls who can access and perform actions on resou</summary>
      
    
    
    
    <category term="Kubernetes" scheme="https://www.willshirley.top/categories/Kubernetes/"/>
    
    
    <category term="RBAC" scheme="https://www.willshirley.top/tags/RBAC/"/>
    
  </entry>
  
  <entry>
    <title>podman snippet</title>
    <link href="https://www.willshirley.top/2025/02/10/podman%20snippet/"/>
    <id>https://www.willshirley.top/2025/02/10/podman%20snippet/</id>
    <published>2025-02-10T08:06:03.000Z</published>
    <updated>2025-06-03T08:54:37.610Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ä¸åŒç”¨æˆ·ä¸‹æ‰§è¡Œ <code>podman ps</code>ï¼Œåªèƒ½æŸ¥çœ‹å½“å‰ç”¨æˆ·çš„è¿è¡Œå®¹å™¨ï¼ˆå³ä½¿æ˜¯rootç”¨æˆ·ï¼Œä¹Ÿä¸èƒ½æŸ¥çœ‹å…¶ä»–æ™®é€šç”¨æˆ·å¯ç”¨çš„å®¹å™¨ä¿¡æ¯ï¼‰</p></blockquote><h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><h2 id="image"><a href="#image" class="headerlink" title="image"></a>image</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> load tar file to image</span></span><br><span class="line">podman load -i &lt;image-tar-file&gt;</span><br></pre></td></tr></table></figure><h1 id="best-practices"><a href="#best-practices" class="headerlink" title="best practices"></a>best practices</h1><h2 id="change-default-data-dir"><a href="#change-default-data-dir" class="headerlink" title="change default data dir"></a>change default data dir</h2><ul><li><p><strong>rootful mode</strong> </p><blockquote><p>Default graphroot: /var/lib/containers/storage.</p></blockquote></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> check</span></span><br><span class="line">podman info | grep &#x27;GraphRoot&#x27;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Edit Podmanâ€™s Storage Configuration</span></span><br><span class="line">sudo mkdir -p /etc/containers</span><br><span class="line">sudo vim /etc/containers/storage.conf # rootç”¨æˆ·é»˜è®¤é‡‡ç”¨çš„é…ç½®</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> edit storage.conf</span></span><br><span class="line">[storage]</span><br><span class="line">driver = &quot;overlay&quot;</span><br><span class="line">graphroot = &quot;/mnt/podman-root-data&quot;</span><br></pre></td></tr></table></figure><ul><li><p><strong>rootless mode</strong></p><blockquote><p>Default graphroot: ~/.local/share/containers/storage.</p></blockquote></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> check</span></span><br><span class="line">podman info | grep &#x27;GraphRoot&#x27;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Edit Podmanâ€™s Storage Configuration</span></span><br><span class="line">sudo mkdir -p ~/.config/containers</span><br><span class="line">sudo vim ~/.config/containers/storage.conf   # æ™®é€šç”¨æˆ·é»˜è®¤é‡‡ç”¨çš„é…ç½®</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> edit storge.conf</span></span><br><span class="line">[storage]</span><br><span class="line">driver = &quot;overlay&quot;</span><br><span class="line">graphroot = &quot;/mnt/podman-&lt;userName&gt;-data&quot; # æ™®é€šç”¨æˆ·å’Œrootç”¨æˆ·çš„æ•°æ®å¿…é¡»è¦åŒºåˆ†å¼€ï¼Œä¸ç„¶ä¼šæœ‰ç›®å½•æƒé™æ“ä½œçš„é—®é¢˜</span><br></pre></td></tr></table></figure><h1 id="troubleshooting"><a href="#troubleshooting" class="headerlink" title="troubleshooting"></a>troubleshooting</h1><h2 id="potentially-insufficient-UIDs-or-GIDs-available-in-user-namespace"><a href="#potentially-insufficient-UIDs-or-GIDs-available-in-user-namespace" class="headerlink" title="potentially insufficient UIDs or GIDs available in user namespace"></a>potentially insufficient UIDs or GIDs available in user namespace</h2><blockquote><p> If the requested UID/GID still falls outside or Podman needs more mappings, you can edit /etc/subuid and /etc/subgid (as root) to increase the range</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Increase UID/GID Range (Optional):</span></span><br><span class="line">sudo vim /etc/subuid  # dingofs:60000:131072</span><br><span class="line">sudo vim /etc/subgid  # dingofs:60000:131072</span><br><span class="line"></span><br><span class="line">podman system migrate</span><br></pre></td></tr></table></figure><h2 id="error-while-loading-shared-libraries"><a href="#error-while-loading-shared-libraries" class="headerlink" title="error while loading shared libraries"></a>error while loading shared libraries</h2><blockquote><p>when execute â€˜podman run -it â€“entrypoint bash xxxâ€™, occur â€˜bash: error while loading shared libraries: /usr/lib64/libc.so.6: cannot apply additional memory protection after relocation: Permission deniedâ€™</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo setenforce 0</span><br></pre></td></tr></table></figure><h2 id="ulimit-open-files-cannot-modify-limit-Operation-not-permitted"><a href="#ulimit-open-files-cannot-modify-limit-Operation-not-permitted" class="headerlink" title="ulimit: open files: cannot modify limit: Operation not permitted"></a>ulimit: open files: cannot modify limit: Operation not permitted</h2><blockquote><p>use regular use could not operate ulimit command</p></blockquote><ol><li><p>Set ulimit when starting the container</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">podman run -it --ulimit nofile=1048576:1048576 your_image</span><br></pre></td></tr></table></figure></li><li><p>Adjust host user limits (Edit <code>/etc/security/limits.conf</code> as root)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">your_username soft nofile 1048576</span><br><span class="line">your_username hard nofile 1048576</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ä¸åŒç”¨æˆ·ä¸‹æ‰§è¡Œ &lt;code&gt;podman ps&lt;/code&gt;ï¼Œåªèƒ½æŸ¥çœ‹å½“å‰ç”¨æˆ·çš„è¿è¡Œå®¹å™¨ï¼ˆå³ä½¿æ˜¯rootç”¨æˆ·ï¼Œä¹Ÿä¸èƒ½æŸ¥çœ‹å…¶ä»–æ™®é€šç”¨æˆ·å¯ç”¨çš„å®¹å™¨ä¿¡æ¯ï¼‰&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;command&quot;&gt;&lt;a href=&quot;#comm</summary>
      
    
    
    
    <category term="podman" scheme="https://www.willshirley.top/categories/podman/"/>
    
    
    <category term="tool" scheme="https://www.willshirley.top/tags/tool/"/>
    
  </entry>
  
  <entry>
    <title>ceph rados</title>
    <link href="https://www.willshirley.top/2025/02/08/ceph%20rados/"/>
    <id>https://www.willshirley.top/2025/02/08/ceph%20rados/</id>
    <published>2025-02-08T03:40:20.000Z</published>
    <updated>2025-02-08T10:12:34.786Z</updated>
    
    <content type="html"><![CDATA[<p>The <a href="https://docs.ceph.com/en/reef/glossary/#term-Ceph-Storage-Cluster">Ceph Storage Cluster</a> provides the basic storage service that allows <a href="https://docs.ceph.com/en/reef/glossary/#term-Ceph">Ceph</a> to uniquely deliver <strong>object, block, and file storage</strong> in one unified system. However, you are not limited to using the RESTful, block, or POSIX interfaces. Based upon RADOS, the <code>librados</code> API enables you to create your own interface to the Ceph Storage Cluster.</p><h1 id="command"><a href="#command" class="headerlink" title="command"></a>command</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> list objects by specify pool</span></span><br><span class="line">rados -p &lt;pool-name&gt; ls</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">read</span> object</span></span><br><span class="line">rados -p &lt;pool-name&gt; get &lt;object-name&gt; output.txt</span><br><span class="line">cat output.txt</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Check xattr value</span></span><br><span class="line">rados -p &lt;pool-name&gt; getxattr &lt;object-name&gt; &lt;xattr-key&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The &lt;a href=&quot;https://docs.ceph.com/en/reef/glossary/#term-Ceph-Storage-Cluster&quot;&gt;Ceph Storage Cluster&lt;/a&gt; provides the basic storage servi</summary>
      
    
    
    
    <category term="ceph" scheme="https://www.willshirley.top/categories/ceph/"/>
    
    
    <category term="storage" scheme="https://www.willshirley.top/tags/storage/"/>
    
  </entry>
  
  <entry>
    <title>ceph deploy</title>
    <link href="https://www.willshirley.top/2025/02/07/ceph%20deploy/"/>
    <id>https://www.willshirley.top/2025/02/07/ceph%20deploy/</id>
    <published>2025-02-07T09:40:41.000Z</published>
    <updated>2025-06-13T07:33:12.125Z</updated>
    
    <content type="html"><![CDATA[<h1 id="deploy"><a href="#deploy" class="headerlink" title="deploy"></a>deploy</h1><h2 id="install-cephadm"><a href="#install-cephadm" class="headerlink" title="install cephadm"></a>install cephadm</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dnf search release-ceph</span><br><span class="line">dnf install --assumeyes centos-release-ceph-reef</span><br><span class="line">dnf install --assumeyes cephadm</span><br></pre></td></tr></table></figure><ul><li><p>enable ceph cli</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cephadm add-repo --release reef</span><br><span class="line">cephadm install ceph-common</span><br></pre></td></tr></table></figure></li></ul><h2 id="booststrap"><a href="#booststrap" class="headerlink" title="booststrap"></a>booststrap</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cephadm bootstrap --mon-ip 172.20.7.232</span><br></pre></td></tr></table></figure><ul><li>log<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Ceph Dashboard is now available at:</span><br><span class="line">        URL: https://dingo7232.com:8443/</span><br><span class="line">        User: admin</span><br><span class="line">    Password: &lt;password&gt;</span><br><span class="line">Enabling client.admin keyring and conf on hosts with &quot;admin&quot; label</span><br><span class="line">Saving cluster configuration to /var/lib/ceph/6a65c746-e532-11ef-8ac2-fa7c097efb00/config directory</span><br><span class="line">Enabling autotune for osd_memory_target</span><br><span class="line">You can access the Ceph CLI as following in case of multi-cluster or non-default config:</span><br><span class="line">        sudo /sbin/cephadm shell --fsid 6a65c746-e532-11ef-8ac2-fa7c097efb00 -c /etc/ceph/ceph.conf -k /etc/ceph/ceph.client.admin.keyring</span><br><span class="line">Or, if you are only running a single cluster on this host:</span><br><span class="line">        sudo /sbin/cephadm shell</span><br><span class="line">Please consider enabling telemetry to help improve Ceph:</span><br><span class="line">        ceph telemetry on</span><br><span class="line">For more information see:</span><br><span class="line">        https://docs.ceph.com/en/latest/mgr/telemetry/</span><br><span class="line">Bootstrap complete.</span><br></pre></td></tr></table></figure></li></ul><h2 id="add-hosts"><a href="#add-hosts" class="headerlink" title="add hosts"></a>add hosts</h2><ul><li><p>Install the clusterâ€™s public SSH key in the new hostâ€™s root userâ€™s authorized_keys file:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -f -i /etc/ceph/ceph.pub root@dingo7233</span><br><span class="line">ssh-copy-id -f -i /etc/ceph/ceph.pub root@dingo7234</span><br></pre></td></tr></table></figure></li><li><p>Tell Ceph that the new node is part of the cluster</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ceph orch host add *&lt;newhost&gt;* [*&lt;ip&gt;*] [*&lt;label1&gt; ...*]</span></span><br><span class="line">ceph orch host add dingo7233 172.20.7.233</span><br><span class="line">ceph orch host add dingo7234 172.20.7.234</span><br><span class="line">or</span><br><span class="line">ceph orch host add dingo7233 172.20.7.233 --labels _admin</span><br><span class="line">ceph orch host add dingo7234 172.20.7.234 --labels _admin</span><br></pre></td></tr></table></figure></li><li><p>add label (optional)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph orch host label add dingo7233 _admin</span><br><span class="line">ceph orch host label add dingo7234 _admin</span><br></pre></td></tr></table></figure></li><li><p>list hosts</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph orch host ls --detail</span><br></pre></td></tr></table></figure></li></ul><h2 id="add-storage"><a href="#add-storage" class="headerlink" title="add storage"></a>add storage</h2><ul><li><p>check available devices</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph orch device ls</span><br></pre></td></tr></table></figure></li><li><p>apply osd</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph orch apply osd --all-available-devices</span><br></pre></td></tr></table></figure></li></ul><h1 id="check"><a href="#check" class="headerlink" title="check"></a>check</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ceph status</span></span><br><span class="line">cluster:</span><br><span class="line">    id:     6a65c746-e532-11ef-8ac2-fa7c097efb00</span><br><span class="line">    health: HEALTH_WARN</span><br><span class="line">            1 mgr modules have recently crashed</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum dingo7232,dingo7234,dingo7233 (age 16m)</span><br><span class="line">    mgr: dingo7232.znvodw(active, since 24m), standbys: dingo7234.yenqrt</span><br><span class="line">    osd: 3 osds: 3 up (since 15m), 3 in (since 15m)</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 2 objects, 449 KiB</span><br><span class="line">    usage:   81 MiB used, 600 GiB / 600 GiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure><h1 id="thouble-shooting"><a href="#thouble-shooting" class="headerlink" title="thouble shooting"></a>thouble shooting</h1><h2 id="redeploy-cluster"><a href="#redeploy-cluster" class="headerlink" title="redeploy cluster"></a>redeploy cluster</h2><p>To remove an existing Ceph cluster deployed using <code>cephadm</code> and redeploy a new one, follow these steps:</p><ul><li>Step 1: Stop All Ceph Services</li></ul><p>First, stop all Ceph services on each host in the cluster.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop ceph.target</span><br></pre></td></tr></table></figure><ul><li>Step 2: Remove Ceph Configuration and Data</li></ul><p>Remove the Ceph configuration and data directories.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -rf /etc/ceph</span><br><span class="line">sudo rm -rf /var/lib/ceph</span><br><span class="line">sudo rm -rf /var/<span class="built_in">log</span>/ceph</span><br></pre></td></tr></table></figure><ul><li><p>Step 3: deploy as below words</p></li><li><p>Step 4: Verify Cluster Health</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph -s</span><br></pre></td></tr></table></figure></li></ul><p>If you encounter any issues during the redeployment, check the logs:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo journalctl -u ceph-* -f</span><br></pre></td></tr></table></figure><p>Or check the Ceph logs directly:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo less /var/<span class="built_in">log</span>/ceph/ceph.log</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;deploy&quot;&gt;&lt;a href=&quot;#deploy&quot; class=&quot;headerlink&quot; title=&quot;deploy&quot;&gt;&lt;/a&gt;deploy&lt;/h1&gt;&lt;h2 id=&quot;install-cephadm&quot;&gt;&lt;a href=&quot;#install-cephadm&quot; class</summary>
      
    
    
    
    <category term="ceph" scheme="https://www.willshirley.top/categories/ceph/"/>
    
    
    <category term="deploy" scheme="https://www.willshirley.top/tags/deploy/"/>
    
  </entry>
  
  <entry>
    <title>linux A vs B</title>
    <link href="https://www.willshirley.top/2025/01/22/linux%20A%20vs%20B/"/>
    <id>https://www.willshirley.top/2025/01/22/linux%20A%20vs%20B/</id>
    <published>2025-01-22T06:11:11.000Z</published>
    <updated>2025-01-22T06:20:04.986Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Systemd-limits-vs-PAM-limits"><a href="#Systemd-limits-vs-PAM-limits" class="headerlink" title="Systemd limits vs PAM limits"></a>Systemd limits vs PAM limits</h1><p><strong>Systemd limits</strong> and <strong>PAM limits</strong> are two different ways of configuring resource limits in Linux. They control aspects like <strong>open file limits (<strong>nofile</strong>)</strong>, <strong>memory</strong>, and <strong>CPU usage</strong>, but they work at different levels of the system.</p><h2 id="PAM-Limits"><a href="#PAM-Limits" class="headerlink" title="PAM Limits"></a>PAM Limits</h2><p>PAM (Pluggable Authentication Module) sets limits when <strong>a user logs in</strong> via <strong>SSH, TTY, or GUI login</strong>. It does <strong>not</strong> apply to system services. </p><p><strong>Configuration:</strong></p><ul><li><p>/etc/security/limits.conf</p></li><li><p>/etc/security/limits.d/*.conf</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Example (/etc/security/limits.conf or /etc/security/limits.d/custom.conf):**</span></span><br><span class="line">dongw soft nofile 65535</span><br><span class="line">dongw hard nofile 65535</span><br></pre></td></tr></table></figure><p><strong>Limitations of PAM:</strong></p><ul><li><p>Only affects interactive logins (TTY, SSH, GUI).</p></li><li><p>Does <strong>not</strong> apply to systemd-managed services.</p></li></ul><h2 id="Systemd-Limits"><a href="#Systemd-Limits" class="headerlink" title="Systemd Limits"></a>Systemd Limits</h2><p>Systemd sets limits <strong>for system services and user sessions</strong>. It applies to <strong>both login sessions and system services</strong>, making it more powerful than PAM.</p><p><strong>Configuration:</strong></p><ul><li><p><strong>Global (for all services and users)</strong>:</p></li><li><p>/etc/systemd/system.conf (system-wide limits)</p></li><li><p>/etc/systemd/user.conf (per-user session limits)</p></li><li><p><strong>Per-service limits</strong> (for specific services):</p></li><li><p>/etc/systemd/system/<service>.service</p></li></ul><h3 id="Global-Limits"><a href="#Global-Limits" class="headerlink" title="Global Limits"></a>Global Limits</h3><p>Applies to <strong>all</strong> processes managed by systemd. (/etc/systemd/system.conf or /etc/systemd/user.conf)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DefaultLimitNOFILE=65535</span><br></pre></td></tr></table></figure><h3 id="Per-Service-Limits"><a href="#Per-Service-Limits" class="headerlink" title="Per-Service Limits"></a>Per-Service Limits</h3><p> This applies to only on specify service. (e.g. /etc/systemd/system/myservice.service)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">LimitNOFILE=65535</span><br></pre></td></tr></table></figure><p><strong>Advantages of Systemd Limits:</strong></p><ul><li><p>Affects <strong>both user logins and system services</strong>.</p></li><li><p>Ensures limits persist across <strong>system reboots</strong>.</p></li><li><p>More reliable for applications like Ceph, Docker, and databases.</p></li></ul><h2 id="Comparison-Table"><a href="#Comparison-Table" class="headerlink" title="Comparison Table"></a><strong>Comparison Table</strong></h2><table><thead><tr><th align="left"><strong>Feature</strong></th><th><strong>PAM Limits (<code>limits.conf</code>)</strong></th><th><strong>Systemd Limits (<code>system.conf</code>/<code>.service</code>)</strong></th></tr></thead><tbody><tr><td align="left">Applies to interactive users</td><td>âœ… Yes (SSH, TTY, GUI)</td><td>âœ… Yes</td></tr><tr><td align="left">Applies to system services</td><td>âŒ No</td><td>âœ… Yes</td></tr><tr><td align="left">Persists across reboots</td><td>âœ… Yes</td><td>âœ… Yes</td></tr><tr><td align="left">Easy to configure</td><td>âœ… Yes</td><td>âœ… Yes</td></tr><tr><td align="left">Best for tuning servers</td><td>âš ï¸  Partial</td><td>âœ… Yes</td></tr></tbody></table><ul><li><p><strong>For interactive user sessions</strong> â†’ Use <strong>PAM (<strong>limits.conf</strong>)</strong>.</p></li><li><p><strong>For system services and all users</strong> â†’ Use <strong>Systemd (<strong>system.conf</strong>,</strong> .service**)**.</p></li><li><p><strong>For the best persistence and reliability</strong>, configure <strong>both</strong>.</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Systemd-limits-vs-PAM-limits&quot;&gt;&lt;a href=&quot;#Systemd-limits-vs-PAM-limits&quot; class=&quot;headerlink&quot; title=&quot;Systemd limits vs PAM limits&quot;&gt;&lt;/a&gt;Sy</summary>
      
    
    
    
    <category term="linux" scheme="https://www.willshirley.top/categories/linux/"/>
    
    
    <category term="A vs B" scheme="https://www.willshirley.top/tags/A-vs-B/"/>
    
  </entry>
  
  <entry>
    <title>linux tune</title>
    <link href="https://www.willshirley.top/2025/01/21/linux%20tune/"/>
    <id>https://www.willshirley.top/2025/01/21/linux%20tune/</id>
    <published>2025-01-21T02:43:04.000Z</published>
    <updated>2025-02-24T06:50:54.511Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h1><h2 id="governor-strategy"><a href="#governor-strategy" class="headerlink" title="governor strategy"></a>governor strategy</h2><ul><li><p>Check Available CPU Governors</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Run the following <span class="built_in">command</span> to check available CPU governors:</span></span><br><span class="line">cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You should see something like below info:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> conservative ondemand userspace powersave performance schedutil</span></span><br></pre></td></tr></table></figure></li><li><p>Check Current CPU Governor</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><br><span class="line">or</span><br><span class="line">cpupower frequency-info --policy # should install cpupower command by &#x27;sudo dnf install kernel-tools -y&#x27;</span><br></pre></td></tr></table></figure></li><li><p>Set CPU Governor to Performance temporarily</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> To temporarily <span class="built_in">set</span> the CPU governor to performance (until reboot):</span></span><br><span class="line">for cpu in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do</span><br><span class="line">  echo performance | sudo tee $cpu</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li><li><p>Set CPU Governor Persistent</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> First, install cpupower:</span></span><br><span class="line">sudo dnf install kernel-tools -y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Then, <span class="built_in">set</span> the governor:</span></span><br><span class="line">sudo cpupower frequency-set -g performance</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> To apply this setting at boot, <span class="built_in">enable</span> the service:</span></span><br><span class="line">sudo systemctl enable --now cpupower.service</span><br></pre></td></tr></table></figure></li></ul><h1 id="nvme"><a href="#nvme" class="headerlink" title="nvme"></a>nvme</h1><h2 id="I-O-scheduler"><a href="#I-O-scheduler" class="headerlink" title="I/O scheduler"></a>I/O scheduler</h2><ul><li><p>check current scheduler pattern</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/block/nvme[01]\*/queue/scheduler</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> console <span class="built_in">print</span> below info</span></span><br><span class="line">none [mq-deadline] kyber bfq</span><br></pre></td></tr></table></figure><p>The <strong>scheduler currently in use</strong> is indicated by the square brackets [ ].</p><p><strong>Common NVMe I/O Schedulers</strong></p><ol><li><p><strong>none</strong> â€“ Default for NVMe, provides minimal latency.</p></li><li><p><strong>mq-deadline</strong> â€“ Multi-queue deadline scheduler, balances fairness and performance.</p></li><li><p><strong>kyber</strong> â€“ Optimized for high-performance SSDs.</p></li><li><p><strong>bfq</strong> â€“ Budget Fair Queueing, useful for low-latency workloads.</p></li></ol></li><li><p>Change the I/O Scheduler</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> To <span class="built_in">set</span> the none scheduler <span class="keyword">for</span> nvme0n1, use:</span></span><br><span class="line">echo none | sudo tee /sys/block/nvme0n1/queue/scheduler</span><br></pre></td></tr></table></figure><p><strong>When to Change the Scheduler?</strong></p><ul><li><p>Use none <strong>(default)</strong> if latency is the priority (most NVMe drives handle queuing internally).</p></li><li><p>Use mq-deadline if fairness in I/O operations is needed.</p></li><li><p>Use kyber for workloads requiring fast response time.</p></li><li><p>Use bfq for interactive desktop workloads.</p></li></ul></li></ul><h1 id="ulimit"><a href="#ulimit" class="headerlink" title="ulimit"></a>ulimit</h1><h2 id="open-file-size"><a href="#open-file-size" class="headerlink" title="open file size"></a>open file size</h2><blockquote><p>To configure the <strong>maximum open file size</strong> (ulimit) for a specific user </p></blockquote><ul><li><p>Check Current Limits</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> To see the current limits <span class="keyword">for</span> a user:</span></span><br><span class="line">ulimit -n # Check open file limit</span><br><span class="line">ulimit -a # Check all limits</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> To check system-wide limits:</span></span><br><span class="line">cat /proc/sys/fs/file-max</span><br></pre></td></tr></table></figure></li><li><p>Set Open File Limits for a Specific User</p><blockquote><p>The changes in limits.conf are only applied to new login sessions</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/security/limits.conf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Add the following lines (replace username with the actual user):</span></span><br><span class="line">username soft nofile 65535</span><br><span class="line">username hard nofile 65535</span><br></pre></td></tr></table></figure></li></ul><p>â€‹    <strong>soft</strong>: The default limit the user gets.</p><p>â€‹    <strong>hard</strong>: The maximum limit a user can set.</p><table><thead><tr><th>Feature</th><th>/etc/security/limits.conf</th><th>/etc/security/limits.d/*.conf</th></tr></thead><tbody><tr><td><strong>Default File</strong></td><td>Yes</td><td>No (Custom files in limits.d directory)</td></tr><tr><td><strong>Priority</strong></td><td>Read first</td><td>Read after limits.conf</td></tr><tr><td><strong>Organization</strong></td><td>All rules in one file</td><td>Modular approach, one file per service or user</td></tr><tr><td><strong>Example</strong></td><td><code>* soft nofile 65536</code></td><td><code>dongw soft nofile 65536</code> (in <code>/etc/security/limits.d/dongw.conf</code>)</td></tr><tr><td><strong>Syntax</strong></td><td>Same syntax for both files</td><td>Same syntax as limits.conf</td></tr></tbody></table><h1 id="HP-and-THP"><a href="#HP-and-THP" class="headerlink" title="HP and THP"></a>HP and THP</h1><blockquote><p>Huge Pages (HP) and Transparent Huge Pages (THP)</p></blockquote><p>Understanding Huge Pages (HP) and Transparent Huge Pages (THP)</p><p><strong>Huge Pages (HP)</strong>: A manually configured fixed-size memory allocation system, beneficial for workloads that require large contiguous memory allocations.</p><p><strong>Transparent Huge Pages (THP)</strong>: An automated memory management feature that dynamically allocates large memory pages based on usage patterns.</p><p>for performance-sensitive applications, THP can sometimes cause performance issues due to fragmentation and unexpected latency spikes. Thus, itâ€™s often recommended to <strong>disable THP</strong> and manually configure HP.</p><ul><li><p>Checking Current Huge Pages Configuration</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/meminfo | grep HugePages</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example output:</span></span><br><span class="line">AnonHugePages:  16850944 kB # Memory allocated via THP.</span><br><span class="line">ShmemHugePages:        0 kB</span><br><span class="line">FileHugePages:         0 kB</span><br><span class="line">HugePages_Total:       0 # Number of configured huge pages.</span><br><span class="line">HugePages_Free:        0 # Available huge pages.</span><br><span class="line">HugePages_Rsvd:        0</span><br><span class="line">HugePages_Surp:        0</span><br></pre></td></tr></table></figure></li><li><p>Configuring Static Huge Pages</p><p><strong>Step 1: Set the Number of Huge Pages</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> To allocate a specific number of 2MB huge pages, calculate based on your memory requirements. Example:</span></span><br><span class="line">echo 1024 | sudo tee /proc/sys/vm/nr_hugepages</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Make it persistent:</span></span><br><span class="line">echo &quot;vm.nr_hugepages=1024&quot; | sudo tee -a /etc/sysctl.conf</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p><strong>Step 2: Allocate Huge Pages at Boot (Recommended)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/default/grub</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Add hugepages kernel parameter:</span></span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;default_hugepagesz=2M hugepagesz=2M hugepages=1024&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Update GRUB:</span></span><br><span class="line">sudo grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Reboot the system:</span></span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><p><strong>Step 3: Mount Huge Pages File System (Optional)</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> To <span class="built_in">enable</span> shared access to huge pages:</span></span><br><span class="line">mkdir -p /mnt/huge</span><br><span class="line">mount -t hugetlbfs nodev /mnt/huge</span><br><span class="line"><span class="meta">#</span><span class="bash"> To make this persistent, add to /etc/fstab:</span></span><br><span class="line">nodev /mnt/huge hugetlbfs defaults 0 0</span><br></pre></td></tr></table></figure></li><li><p>Disabling Transparent Huge Pages (THP)</p><p>THP should be <strong>disabled</strong> for performance-sensitive applications</p><p><strong>Step 1: Disable THP at Runtime</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo never | sudo tee /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure><p><strong>Step 2: Make THP Disabled at Boot</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/default/grub</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Add:</span></span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;transparent_hugepage=never&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Update GRUB:</span></span><br><span class="line">sudo grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Reboot:</span></span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure></li><li><p>Verification After Reboot</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Check Huge Pages Allocation</span></span><br><span class="line">cat /proc/meminfo | grep HugePages</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Check THP Status</span></span><br><span class="line">cat /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"><span class="meta">#</span><span class="bash"> Expected output:</span></span><br><span class="line">[always] madvise never</span><br></pre></td></tr></table></figure></li></ul><p>Summary: Should You Configure HP &amp; THP Together?</p><p>For performance-sensitive applications, itâ€™s recommended to <strong>disable THP</strong> and <strong>manually configure Huge Pages (HP)</strong> for better performance.</p><p>THP can cause latency spikes and memory fragmentation, making it less ideal for high-performance file systems.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;cpu&quot;&gt;&lt;a href=&quot;#cpu&quot; class=&quot;headerlink&quot; title=&quot;cpu&quot;&gt;&lt;/a&gt;cpu&lt;/h1&gt;&lt;h2 id=&quot;governor-strategy&quot;&gt;&lt;a href=&quot;#governor-strategy&quot; class=&quot;header</summary>
      
    
    
    
    <category term="linux" scheme="https://www.willshirley.top/categories/linux/"/>
    
    
    <category term="tune" scheme="https://www.willshirley.top/tags/tune/"/>
    
  </entry>
  
</feed>
